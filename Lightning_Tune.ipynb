{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lightning_Tune.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WK9GeW6miiXr",
        "ASOiXXn-36Wf",
        "FbXpnU7Y4Cr9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravraha/galaxy/blob/experimental/Lightning_Tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDzU0Yty6Qsw"
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI_RfiMRk5j_"
      },
      "source": [
        "## Install/uninstall packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMwknUIDcTW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "403b97b0-d78e-498f-92cf-34180fc7c017"
      },
      "source": [
        "# If you are running on Google Colab, uncomment below to install the necessary dependencies \n",
        "# before beginning the exercise.\n",
        "\n",
        "print('Setting up colab environment')\n",
        "# !pip uninstall -y -q pyarrow\n",
        "!pip install -q lightning-bolts GPy\n",
        "!pip install -q ray[debug] ray[default]\n",
        "!pip install -U -q ray[tune]\n",
        "# !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "# # A hack to force the runtime to restart, needed to include the above dependencies.\n",
        "# print('Done installing! Restarting via forced crash (this is not an issue).')\n",
        "# import os\n",
        "# os._exit(0)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting up colab environment\n",
            "\u001b[K     |████████████████████████████████| 253 kB 13.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 959 kB 27.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 272 kB 45.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 916 kB 39.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 118 kB 18.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 44.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 41.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 42.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 71 kB 8.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 142 kB 51.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 294 kB 47.8 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 51.0 MB 36 kB/s \n",
            "\u001b[33mWARNING: ray 1.5.2 does not provide the extra 'debug'\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 53.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 38.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 498 kB/s \n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 39.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 201 kB 45.4 MB/s \n",
            "\u001b[?25h  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 124 kB 12.7 MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNMd9sh02fG9"
      },
      "source": [
        "# If you are running on Google Colab, please install TensorFlow 2.0 by uncommenting below..\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB3f7W9_kazP"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR6G_K6bWVqd"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "from matplotlib import pyplot as plt\n",
        "# ------------------------------------\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "# ------------------------------------\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.utils import save_image\n",
        "from torchvision import transforms, datasets\n",
        "# ------------------------------------\n",
        "import torchmetrics as tm\n",
        "# ------------------------------------\n",
        "import pytorch_lightning as pl\n",
        "from pl_bolts.models.gans import DCGAN\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pl_bolts.models.self_supervised.resnets import BasicBlock  \n",
        "from pytorch_lightning.utilities.cloud_io import load as pl_load\n",
        "# ------------------------------------\n",
        "from ray import tune\n",
        "from ray.tune.stopper import TrialPlateauStopper\n",
        "from ray.tune import CLIReporter, JupyterNotebookReporter\n",
        "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
        "from ray.tune.schedulers.pb2 import PB2\n",
        "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
        "# ------------------------------------"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK9GeW6miiXr"
      },
      "source": [
        "# Download and extract data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGZRwWHbXqLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca99e56c-0952-4e67-96bb-5591a5f644e6"
      },
      "source": [
        "from google.colab import drive\n",
        "# drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', True, 600000)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdfevhA2fGYr"
      },
      "source": [
        "Here choose the model you wish to use for training/testing. Don't forget to make modifications in the following sections:\n",
        "\n",
        "1.   GLOBAL in class definition of npyImageData.\n",
        "2.   correct assignment of metric keys while defining the training wrapper for Tune.\n",
        "3.   name of the experiment initiated/resumed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZUIrgOfbwPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f488912-eeb2-4f59-8014-135a9bec6e9f"
      },
      "source": [
        "# 'a': 1Cjcw2EWorhdhJSGoWOdxsEUDxvl943dt, 'b': 15yXXC4h5VsytP3Ak1jfUSjQhdgP2s23K, 'c': 1vuQ-pLzoKT4Hd_V7949r9eND9E2fB_u_,\n",
        "# 'd': , 'e': 1wFuasvb7PthxXtMUlsD13uzYHWlWt06H, 'f': 17l6H61tLAu26zGuei38r_T5ssjbYUeaJ, \n",
        "# 'g': 1SxQVosWeEjY3Pyn8LRXA11rLnZ9HK_7B, 'h': 1Atau0RH4oyLAiYReW-G9a8l9pUNltglF, 'i': 15lEgsR1p00KSHieaT9a1nkbJ86pDxwgp, \n",
        "# 'j': 1m0EQUbqZZeyl76XsQIKWU5Qd7jGmmWhB, 'k': , 'l': 1meTDi4aeWfdChOiXeLtUOGhjVDVu000e\n",
        "\n",
        "# !rm -rf images\n",
        "!gdown --id 17l6H61tLAu26zGuei38r_T5ssjbYUeaJ\n",
        "!tar zxf ./model_f.tgz\n",
        "!rm ./model_f.tgz\n",
        "\n",
        "# def prepare_data(data_dir: str = '/content'):\n",
        "#     gdown.download('https://drive.google.com/uc?id=17l6H61tLAu26zGuei38r_T5ssjbYUeaJ', data_dir+'/model_f.tgz', quiet=True)\n",
        "    \n",
        "#     temp = tarfile.open(data_dir+'/model_f.tgz', 'r|gz')\n",
        "#     temp.extractall()\n",
        "#     temp.close()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17l6H61tLAu26zGuei38r_T5ssjbYUeaJ\n",
            "To: /content/model_f.tgz\n",
            "2.34GB [00:27, 84.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hczXOvdE54S"
      },
      "source": [
        "# Class definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snbv_zoNiWfW"
      },
      "source": [
        "## DataModule\n",
        "This creates dataloaders which need to be supplied to train, validate or test the module we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yItuGxXmXzGr"
      },
      "source": [
        "class npyImageData(pl.LightningDataModule):\n",
        "    def __init__(self, config, img_width: int = 150, data_dir: str = '/content/images/'):\n",
        "        super().__init__()\n",
        "        # This method is not implemented\n",
        "        # self.save_hyperparameters()\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.data_dir = os.path.expanduser(data_dir)\n",
        "        \n",
        "        # Change the source file containing mean and stdv when changing dataset ------------------------------------------------------\n",
        "        GLOBAL = np.load('/content/drive/MyDrive/git_repos/forging_new_worlds/GLOBAL_VALS_F.npz')\n",
        "        self.transform = transforms.Compose([\n",
        "            # transforms.ConvertImageDtype(torch.float32),\n",
        "            # Can't use this, divides values by dtype.max, use float() in npyloader instead\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            transforms.Normalize(mean=(GLOBAL['VALS'][2],), std=(GLOBAL['VALS'][3],)),\n",
        "            transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "            # this shift-scales the pixel values, N(mu, sigma) -> N(0, 1)\n",
        "            transforms.Resize(img_width, transforms.InterpolationMode.NEAREST),\n",
        "        ])\n",
        "    \n",
        "    @staticmethod\n",
        "    def npy_loader(path):\n",
        "        # s=np.load(path).astype('float',copy=False)\n",
        "        return torch.from_numpy(np.load(path)).unsqueeze(0).float()\n",
        "        # Convert to tenssor first, and then to float, otherwise final dtype \n",
        "        # would be float64, which would raise errors in conv layers      ###### type as\n",
        "\n",
        "    def setup(self, stage: str = None):\n",
        "        if stage in ('fit', None):\n",
        "            self.train_set = datasets.DatasetFolder(os.path.join(self.data_dir,'train'),\n",
        "                                                   self.npy_loader, \n",
        "                                                   ('.npy'), \n",
        "                                                   self.transform,\n",
        "                                                   )\n",
        "            # self.train_set, self.val_set = random_split(self.full_set, [60000, 15000])            \n",
        "            self.val_set = datasets.DatasetFolder(os.path.join(self.data_dir,'val'), \n",
        "                                                   self.npy_loader, \n",
        "                                                   ('.npy'), \n",
        "                                                   self.transform,\n",
        "                                                   )\n",
        "            self.dims = tuple(self.train_set[0][0].shape)\n",
        "\n",
        "        if stage in ('test', None):\n",
        "            self.test_set = datasets.DatasetFolder(os.path.join(self.data_dir,'val'), \n",
        "                                                   self.npy_loader, \n",
        "                                                   ('.npy'), \n",
        "                                                   self.transform,\n",
        "                                                   )\n",
        "            self.dims = getattr(self, 'dims', self.test_set[0][0].shape)\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_set, self.batch_size, shuffle=True, num_workers=os.cpu_count())\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_set, self.batch_size, shuffle=True, num_workers=os.cpu_count())\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_set, self.batch_size, shuffle=True, num_workers=os.cpu_count())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0bm1afc11hN"
      },
      "source": [
        "## ResNet\n",
        "We modify a ResNet slightly for our purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojZ0yT4z168p"
      },
      "source": [
        "class LensResnet(pl.LightningModule):\n",
        "    def __init__(self, config, image_channels: int = 1, num_classes: int = 3, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "        self.learning_rate = config['learning_rate']\n",
        "\n",
        "        # init a pretrained resnet\n",
        "        self.backbone = resnet18(num_classes=self.hparams.num_classes)\n",
        "        self.backbone.conv1 = nn.Conv2d(self.hparams.image_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        #  can't merely change the in_channels since weights have to changed as well\n",
        "        self.backbone.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            self.backbone.fc\n",
        "        )\n",
        "\n",
        "        self.train_metrics = tm.MetricCollection(\n",
        "            [\n",
        "             tm.AUROC(num_classes=self.hparams.num_classes, average='weighted'),\n",
        "            ],\n",
        "            prefix='LensResnet/train/',\n",
        "        )\n",
        "        self.val_metrics = tm.MetricCollection(\n",
        "            [\n",
        "             tm.AUROC(num_classes=self.hparams.num_classes, average=None),\n",
        "            #  tm.ROC(num_classes=self.hparams.num_classes),\n",
        "            #  tm.PrecisionRecallCurve(self.hparams.num_classes),\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.backbone.parameters(), self.learning_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.softmax(self.backbone(x), 1)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        try:\n",
        "            Dict = self.train_metrics(self(imgs),labels)\n",
        "        except RuntimeError:\n",
        "            print('Batch no. : '+str(batch_idx))\n",
        "            print(self(imgs))\n",
        "            print(labels)\n",
        "            print(tm.AUROC(num_classes=self.hparams.num_classes, average='weighted')(self(imgs), labels))\n",
        "\n",
        "        Dict['LensResnet/train/Loss'] = F.cross_entropy(self.backbone(imgs), labels)\n",
        "        self.log_dict(Dict)\n",
        "        #  keep only scalars here, for no errors\n",
        "        return Dict['LensResnet/train/Loss']\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        self.log('LensResnet/val/Loss', F.cross_entropy(self.backbone(imgs), labels))\n",
        "        #  keep only scalars here, for no errors\n",
        "        self.val_metrics.update(self(imgs),labels)\n",
        "\n",
        "    def validation_epoch_end(self, Listofdicts):\n",
        "        # prediction, target = torch.cat([x['pred'] for x in Listofdicts]), torch.cat([x['target'] for x in Listofdicts])\n",
        "        Dict = self.val_metrics.compute()\n",
        "        # aurocTensor = self.train_metrics(prediction, target, num_classes=self.hparams.num_classes, average=None)\n",
        "        self.log('LensResnet/val/AUROC', Dict['AUROC'].min())\n",
        "        # fprList, tprList, _ = Dict['ROC']\n",
        "        \n",
        "        # fig = plt.figure()\n",
        "        # colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "        # for i, color in zip(range(self.hparams.num_classes), colors):\n",
        "        #     plt.plot(fprList[i].cpu(), tprList[i].cpu(), color=color,\n",
        "        #             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "        #             ''.format(i, Dict['AUROC'][i]))\n",
        "        # plt.plot([0, 1], [0, 1], 'k--')\n",
        "        # plt.xlim([0.0, 1.0])\n",
        "        # plt.ylim([0.0, 1.05])\n",
        "        # plt.xlabel('False Positive Rate')\n",
        "        # plt.ylabel('True Positive Rate')\n",
        "        # plt.title('Multi-class ROC (F)')\n",
        "        # plt.legend(loc='lower right')\n",
        "\n",
        "        # self.logger.experiment.add_figure('LensResnet/val/ROC', fig)\n",
        "        # fig.savefig(str(self.trainer.log_dir)+'/ROC_epoch_{:02d}.pdf'.format(self.current_epoch))\n",
        "\n",
        "    def on_fit_end(self):\n",
        "        delattr(self, 'train_metrics')\n",
        "        delattr(self, 'val_metrics')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc0oRARcKBv3"
      },
      "source": [
        "## Stage 1\n",
        "Here we subclass a DCGAN to create our low resolution GAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr6AVixKRMeO"
      },
      "source": [
        "BEST_RESNET_F = '/content/drive/MyDrive/Logs/LensResnet_F/train_LensResnet_tune_checkpoint_efb38_00000_0_2021-07-09_04-20-04/checkpoint_epoch=9-step=16407'\n",
        "BEST_RESNET_J = '/content/drive/MyDrive/Logs/LensResnet_J/train_LensResnet_tune_checkpoint_21355_00000_0_2021-07-09_16-17-17/checkpoint_epoch=27-step=4687'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kclAeom914wK"
      },
      "source": [
        "class Stage1(DCGAN):\n",
        "    def __init__(self, config, num_classes: int = 3, **kwargs):\n",
        "        super().__init__(feature_maps_gen=config['n_fmaps'], feature_maps_disc=config['n_fmaps'], learning_rate=config['learning_rate'])\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "\n",
        "        self.generator.add_module('emb', nn.Embedding(self.hparams.num_classes, self.hparams.latent_dim))\n",
        "\n",
        "        # These are better as attributes, instead of being returned by a method\n",
        "        self.modelF = getattr(self, 'modelF', LensResnet.load_from_checkpoint(os.path.join(BEST_RESNET_F, 'checkpoint')).eval())\n",
        "        self.modelF.backbone.fc = nn.Identity()\n",
        "\n",
        "        self.modelJ = getattr(self, 'modelJ', LensResnet.load_from_checkpoint(os.path.join(BEST_RESNET_J, 'checkpoint')).eval())\n",
        "        self.modelJ.backbone.fc = nn.Identity()\n",
        "\n",
        "        self.val_metrics = tm.MetricCollection(\n",
        "            {\n",
        "                'ResNet(F)' : tm.FID(self.modelF.backbone),\n",
        "                'ResNet(J)' : tm.FID(self.modelJ.backbone),\n",
        "            },\n",
        "            prefix='Stage1/',\n",
        "            postfix='/val/FID',\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels = None):\n",
        "        if labels is None:\n",
        "            labels = getattr(self, 'labels', \n",
        "                             torch.randint(self.hparams.num_classes, noise.shape[:-1], device=self.device))  # last dimension is the hidden dimension\n",
        "        inp = noise.mul(self.generator.emb(labels))\n",
        "        return self.generator(inp.view(-1, inp.shape[-1], 1, 1))\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        real, self.labels = batch\n",
        "\n",
        "        # Train discriminator\n",
        "        result = None\n",
        "        if optimizer_idx == 0:\n",
        "            result = self._disc_step(real)\n",
        "\n",
        "        # Train generator\n",
        "        if optimizer_idx == 1:\n",
        "            result = self._gen_step(real)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _disc_step(self, real):\n",
        "        disc_loss = self._get_disc_loss(real)\n",
        "        self.log('Stage1/D/train/loss', disc_loss, on_epoch=True)\n",
        "        return disc_loss\n",
        "\n",
        "    def _gen_step(self, real):\n",
        "        gen_loss = self._get_gen_loss(real)\n",
        "        self.log('Stage1/G/train/loss', gen_loss, on_epoch=True)\n",
        "        return gen_loss\n",
        "\n",
        "    # def _get_disc_loss(self, real: torch.Tensor) -> torch.Tensor:\n",
        "    #     # Train with real\n",
        "    #     real_pred = self.discriminator(real)\n",
        "\n",
        "    #     # Train with fake\n",
        "    #     fake_pred = self._get_fake_pred(real)\n",
        "\n",
        "    #     return - torch.mean(real_pred) + torch.mean(fake_pred)\n",
        "\n",
        "    # def _get_gen_loss(self, real: torch.Tensor) -> torch.Tensor:\n",
        "    #     # Train with fake\n",
        "    #     fake_pred = self._get_fake_pred(real)\n",
        "    #     return -torch.mean(fake_pred)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        self.val_metrics.update(imgs, real=True)\n",
        "        out = F.interpolate(self(self._get_noise(labels.shape[0], self.hparams.latent_dim), labels), 150)\n",
        "        self.val_metrics.update(out, real=False)\n",
        "        # return {'predF': self.modelF(out), 'predJ': self.modelJ(out), 'target': labels}\n",
        "\n",
        "    def validation_epoch_end(self, listofDicts):\n",
        "        # target = torch.cat([x['target'] for x in listofDicts])\n",
        "        # f, ax = plt.subplots(1,2, subplot_kw={'xlim': [0,1], 'xlabel': 'False Positive Rate', \n",
        "        #                                       'ylim': [0,1.05], 'ylabel': 'True Positive Rate'},\n",
        "        #                      figsize=[11, 5])\n",
        "        # letters = ['F', 'J']\n",
        "        # for l in range(2):\n",
        "        #     prediction = torch.cat([x['pred' + str(letters[l])] for x in listofDicts])\n",
        "        #     aurocTensor = tm.functional.auroc(prediction, target, num_classes=self.hparams.num_classes, average=None)\n",
        "        #     self.log('Stage1/ResNet(' + str(letters[l]) + ')/val/auroc', aurocTensor.min())\n",
        "        #     fprList, tprList, _ = tm.functional.roc(prediction, target, num_classes=self.hparams.num_classes)\n",
        "            \n",
        "        #     colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "        #     for i, color in zip(range(self.hparams.num_classes), colors):\n",
        "        #         ax[l].plot(fprList[i].cpu(), tprList[i].cpu(), color=color,\n",
        "        #                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "        #                 ''.format(i, aurocTensor[i].cpu()))\n",
        "        #     post_plotting(ax[l])\n",
        "        #     ax[l].set_title('Multi-class ROC (' + str(letters[l]) + ')')\n",
        "        \n",
        "        # f.tight_layout()\n",
        "        # self.logger.experiment.add_figure('Stage1/ResNet/val/ROC', f)\n",
        "        # f.savefig(str(self.trainer.log_dir) + '/ROC_epoch_{:02d}.pdf'.format(self.current_epoch))\n",
        "        self.log_dict(self.val_metrics.compute())\n",
        "\n",
        "        labels = torch.arange(self.hparams.num_classes, device=self.device)\n",
        "        save_image(F.interpolate(self(self._get_noise(labels.shape[0], self.hparams.latent_dim), labels), 150), \n",
        "                   str(self.trainer.log_dir) + '/Fake_epoch_{:02d}.pdf'.format(self.current_epoch), \n",
        "                  #  kwargs for make_grid\n",
        "                   normalize=True, value_range=(-1,1))\n",
        "\n",
        "    def on_fit_end(self):\n",
        "        delattr(self, 'modelF')\n",
        "        delattr(self, 'modelJ')\n",
        "        delattr(self, 'labels')\n",
        "        delattr(self, 'val_metrics')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u1b8lr2puNw"
      },
      "source": [
        "## Stage 2\n",
        "Here we subclass a DCGAN to create our high resolution GAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKxksXYFFXC5"
      },
      "source": [
        "def post_plotting(ax):\n",
        "    ax.plot([0, 1], [0, 1], 'k--')\n",
        "    ax.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMwzBib_zulo"
      },
      "source": [
        "class Generator2(nn.Module):\n",
        "    def __init__(self, ngf: int = 128, image_channels: int = 1, res_depth: int = 6):\n",
        "        super().__init__()\n",
        "\n",
        "        ker, strd = 4, 2\n",
        "        pad = int((ker - 2)/2)\n",
        "        res_ker, res_strd, res_pad = 3, 1, 1\n",
        "        \n",
        "        # 64 -> 32\n",
        "        self.preprocessing = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, ngf, ker, strd, pad, bias=False),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        # residuals\n",
        "        layer = []\n",
        "        for _ in range(res_depth):\n",
        "            layer.append(BasicBlock(ngf, ngf))\n",
        "        self.residual = nn.Sequential(*layer)\n",
        "        \n",
        "        self.ending_residual = nn.Sequential(\n",
        "            nn.Conv2d(ngf, ngf, res_ker, res_strd, res_pad, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        # at this part, add the residual inputs from after the preprocessing\n",
        "\n",
        "        image_width = 150 # upscaling should be factor of 2 increase\n",
        "        mode = 'nearest' # upscaling method is nearest-neighbour\n",
        "        self.main = nn.Sequential(\n",
        "            # 32 -> 75\n",
        "            nn.Upsample(image_width//2, mode=mode),\n",
        "            nn.Conv2d(ngf, ngf*4, res_ker, res_strd, res_pad, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(True),\n",
        "            # 75 -> 150\n",
        "            nn.Upsample(image_width, mode=mode),\n",
        "            nn.Conv2d(ngf*4, image_channels, res_ker, res_strd, res_pad, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, in_x):\n",
        "        x_p = self.preprocessing(in_x)\n",
        "        x_r = x_p\n",
        "        x_r = self.residual(x_r)\n",
        "        x_r = self.ending_residual(x_r)\n",
        "        # large residual connections\n",
        "        x_f = x_r + x_p\n",
        "        return self.main(x_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSyCvJaq1v02"
      },
      "source": [
        "BEST_STAGE1_F = '/content/drive/MyDrive/Logs/Stage1/pbt/F/train_Stage1_0711f_00000_0_n_fmaps=8_2021-08-08_18-54-15/checkpoint_epoch=9-step=3362/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snK9DNDARgi7"
      },
      "source": [
        "class Stage2(DCGAN):\n",
        "    def __init__(self, config, num_classes: int = 3, **kwargs):\n",
        "        super().__init__(feature_maps_gen=config['n_fmaps'], feature_maps_disc=config['n_fmaps'], learning_rate=config['learning_rate'])\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "\n",
        "        self.generator = Generator2(self.hparams.feature_maps_gen, self.hparams.image_channels, config['res_depth'])\n",
        "\n",
        "        # These are better as attributes, instead of being returned by a method\n",
        "        self.modelF = getattr(self, 'modelF', LensResnet.load_from_checkpoint(os.path.join(BEST_RESNET_F, 'checkpoint')).eval())\n",
        "        self.modelJ = getattr(self, 'modelJ', LensResnet.load_from_checkpoint(os.path.join(BEST_RESNET_J, 'checkpoint')).eval())\n",
        "        # Workaround:\n",
        "        self.lowres = getattr(self, 'lowres', Stage1.load_from_checkpoint(os.path.join(BEST_STAGE1_F, 'checkpoint')).eval())\n",
        "        \n",
        "        metrics = tm.MetricCollection(\n",
        "            [\n",
        "             tm.AUROC(num_classes=self.hparams.num_classes, compute_on_step=False, average=None), \n",
        "             tm.ROC(num_classes=self.hparams.num_classes, compute_on_step=False),\n",
        "            ]\n",
        "        )\n",
        "        self.metricsF = metrics.clone()\n",
        "        self.metricsJ = metrics.clone()\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.generator(noise)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        real, self.labels = batch\n",
        "\n",
        "        # Train discriminator\n",
        "        result = None\n",
        "        if optimizer_idx == 0:\n",
        "            result = self._disc_step(real)\n",
        "\n",
        "        # Train generator\n",
        "        if optimizer_idx == 1:\n",
        "            result = self._gen_step(real)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _disc_step(self, real):\n",
        "        disc_loss = self._get_disc_loss(real)\n",
        "        self.log('Stage2/D/train/loss', disc_loss, on_epoch=True)\n",
        "        return disc_loss\n",
        "\n",
        "    def _gen_step(self, real):\n",
        "        gen_loss = self._get_gen_loss(real)\n",
        "        self.log('Stage2/G/train/loss', gen_loss, on_epoch=True)\n",
        "        return gen_loss\n",
        "\n",
        "    def _get_gen_loss(self, real: torch.Tensor) -> torch.Tensor:\n",
        "        # Train with fake\n",
        "        fake_pred = self._get_fake_pred(real)\n",
        "        fake_gt = torch.ones_like(fake_pred)\n",
        "        gen_loss = self.criterion(fake_pred, fake_gt)\n",
        "\n",
        "        class_pred =  self._get_class_pred(len(real))\n",
        "        gen_loss += F.cross_entropy(class_pred, self.labels)\n",
        "\n",
        "        return gen_loss\n",
        "\n",
        "    def _get_class_pred(self, batch_size) -> torch.Tensor:\n",
        "        # ----------------------------------------------------------------------------------------------------------------\n",
        "        return self.modelF.backbone(self(self._get_noise(batch_size, self.hparams.latent_dim)))\n",
        "\n",
        "    def _get_noise(self, n_samples: int, latent_dim: int, labels = None):\n",
        "        # can't use self in function definition\n",
        "        if labels is None:\n",
        "            labels = self.labels\n",
        "            # getattr(self, 'labels', torch.randint(self.hparams.num_classes, (n_samples,), device=self.device))  # last dimension is the hidden dimension\n",
        "        return self.lowres(super()._get_noise(n_samples, latent_dim), labels)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        out = self(self._get_noise(labels.shape[0], self.hparams.latent_dim, labels))\n",
        "        self.metricsF.update(self.modelF(out), labels)\n",
        "        self.metricsJ.update(self.modelJ(out), labels)\n",
        "        # out = Fig.interpolate(out_64, 150)\n",
        "\n",
        "    def validation_epoch_end(self, listofDicts):\n",
        "        fig, ax = plt.subplots(1,2, subplot_kw={'xlim': [0,1], 'xlabel': 'False Positive Rate', \n",
        "                                              'ylim': [0,1.05], 'ylabel': 'True Positive Rate'},\n",
        "                             figsize=[11, 5])\n",
        "        for j, letter in enumerate(['F', 'J']):\n",
        "            output = getattr(self, 'metrics' + letter).compute()\n",
        "            self.log('Stage2/ResNet(' + letter + ')/val/auroc', output['AUROC'].min())\n",
        "            fprList, tprList, _ = output['ROC']\n",
        "            \n",
        "            colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "            for i, color in zip(range(self.hparams.num_classes), colors):\n",
        "                ax[j].plot(fprList[i].cpu(), tprList[i].cpu(), color=color,\n",
        "                        label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                        ''.format(i, output['AUROC'][i]))\n",
        "            post_plotting(ax[j])\n",
        "            ax[j].set_title('Multi-class ROC (' + letter + ')')\n",
        "        \n",
        "        fig.tight_layout()\n",
        "        self.logger.experiment.add_figure('Stage2/ResNet/val/ROC', fig)\n",
        "        fig.savefig(str(self.trainer.log_dir) + '/ROC_epoch_{:02d}.pdf'.format(self.current_epoch))\n",
        "\n",
        "        labels = torch.arange(self.hparams.num_classes, device=self.device)\n",
        "        save_image(self(self._get_noise(labels.shape[0], self.hparams.latent_dim, labels)), \n",
        "                   str(self.trainer.log_dir) + '/Fake_epoch_{:02d}.pdf'.format(self.current_epoch), \n",
        "                  #  kwargs for make_grid\n",
        "                   normalize=True, value_range=(-1,1))\n",
        "\n",
        "    def on_fit_end(self):\n",
        "        delattr(self, 'modelF')\n",
        "        delattr(self, 'modelJ')\n",
        "        delattr(self, 'labels')\n",
        "        delattr(self, 'lowres')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM91irMo1uUR"
      },
      "source": [
        "## StackGAN:\n",
        "Here we define the full GAN module, that we shall use to generate representative images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abXKx0xitvoK"
      },
      "source": [
        "class StackGAN(pl.LightningModule):\n",
        "    def __init__(self, config, noise_size: int = 100, image_width = 64,\n",
        "                    num_classes: int = 3, image_channels: int = 1, b1: float = 0.5, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(ignore = config)\n",
        "        self.feature_maps = config['feature_maps']\n",
        "        self.lr = config['learning_rate']\n",
        "        # -------------------------------------\n",
        "        # Need to create a subclass because we couldn't simply add/remove a layer;\n",
        "        # there are two inputs of the superclas' forward method.\n",
        "        self.G1 = DCGANGenerator(self.hparams.noise_size, self.feature_maps, self.hparams.image_channels).apply(self._weights_init)\n",
        "        l = list(self.G1.gen[0])\n",
        "        del l[1]\n",
        "        self.G1.gen[0] = nn.Sequential(*l)\n",
        "        self.G1.add_module('label_emb', nn.Embedding(self.hparams.num_classes, self.hparams.noise_size))\n",
        "        # ------------------------------------\n",
        "        self.D1 = DCGANDiscriminator(self.feature_maps, self.hparams.image_channels).apply(self._weights_init)\n",
        "        # -------------------------------------\n",
        "        self.G2 = Generator2(self.hparams.image_channels, self.feature_maps).apply(self._weights_init)\n",
        "        # -------------------------------------\n",
        "        self.D2 = DCGANDiscriminator(self.feature_maps, self.hparams.image_channels)\n",
        "        #  steps to mutate the instance, not the class definition\n",
        "        extra = self.D2._make_disc_block(self.feature_maps * 2, self.feature_maps * 2)\n",
        "        l = list(self.D2.disc)\n",
        "        l.insert(2, extra)\n",
        "        self.D2.disc = nn.Sequential(*l)\n",
        "        self.D2.apply(self._weights_init)\n",
        "        # No need for subclassing as the forward method need not be modified.\n",
        "        # -------------------------------------\n",
        "        self.R = LensResnet(config, num_classes = 4).apply(self._weights_init)\n",
        "        # -------------------------------------\n",
        "        self.pretrained = LensResnet(config)\n",
        "        ckpt = pl_load(os.path.join(\n",
        "            '/content/drive/MyDrive/Logs/tune_LensResnet_asha_model_j/train_LensResnet_tune_checkpoint_e38cb_00000_0_batch_size=128,learning_rate=0.001_2021-07-06_17-52-11/checkpoint_epoch=17-step=1406',\n",
        "            # '/content/drive/MyDrive/Logs/tune_LensResnet_asha_model_f/train_LensResnet_tune_checkpoint_e32ba_00000_0_batch_size=64,learning_rate=0.0001_2021-07-06_03-33-10/checkpoint_epoch=14-step=4689',\n",
        "            'checkpoint'),\n",
        "            map_location=lambda storage, loc: storage)\n",
        "        self.pretrained._load_model_state(ckpt)\n",
        "        # -------------------------------------\n",
        "        self.criterion1 = nn.BCELoss()\n",
        "        self.criterion2 = nn.CrossEntropyLoss()\n",
        "\n",
        "    @staticmethod\n",
        "    def _weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv') != -1:\n",
        "            torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        elif classname.find('BatchNorm') != -1:\n",
        "            torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "            torch.nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, noise, labels = None):\n",
        "        if labels is None:\n",
        "            labels = torch.randint(self.hparams.num_classes, noise.shape[:-1])                           # last dimension is the hidden dimension\n",
        "        inp = torch.mul(noise, self.G1.label_emb(labels))\n",
        "        out1 = self.G1(inp.view(-1, inp.shape[-1], 1, 1))\n",
        "        out2 = self.G2(out1.detach())\n",
        "        return out2, out1\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        imgs, labels = batch\n",
        "        temp2, temp1 = self(torch.randn(labels.shape[0], self.hparams.noise_size).type_as(imgs), labels)\n",
        "\n",
        "        if optimizer_idx == 0:\n",
        "            loss = self.criterion1(self.D1(temp1), torch.ones_like(labels, dtype=torch.float32))\n",
        "            self.log('G1/train/loss/disc', loss)\n",
        "            loss.add_(self.criterion2(self.R.backbone(self.G2(temp1)), labels))\n",
        "            self.log('G1/train/loss/full', loss)\n",
        "\n",
        "        elif optimizer_idx == 1:\n",
        "            real, fake = self.D1(F.interpolate(imgs, self.hparams.image_width, mode='nearest')), self.D1(temp1.detach())\n",
        "            prediction, target = torch.cat((real, fake)), torch.cat((torch.ones_like(real),torch.zeros_like(fake)))\n",
        "            loss = self.criterion1(prediction, target)\n",
        "            self.log('D1/train/loss', loss)\n",
        "\n",
        "        elif optimizer_idx == 2:\n",
        "            loss = self.criterion1(self.D2(temp2), torch.ones_like(labels, dtype=torch.float32))\n",
        "            self.log('G2/train/loss/disc', loss)\n",
        "            loss.add_(self.criterion2(self.R.backbone(temp2), labels))\n",
        "            self.log('G2/train/loss/full', loss)\n",
        "\n",
        "        elif optimizer_idx == 3:\n",
        "            real, fake = self.D2(imgs), self.D2(temp2.detach())\n",
        "            prediction, target = torch.cat((real, fake)), torch.cat((torch.ones_like(real),torch.zeros_like(fake)))\n",
        "            loss = self.criterion1(prediction, target)\n",
        "            self.log('D2/train/loss', loss)\n",
        "\n",
        "        elif optimizer_idx == 4:\n",
        "            real, fake = self.R.backbone(imgs), self.R.backbone(temp2.detach())\n",
        "            prediction, target = torch.cat((real, fake)), torch.cat((labels, self.hparams.num_classes * torch.ones_like(labels)))\n",
        "            loss = self.criterion2(prediction, target)\n",
        "            self.log('R/train/loss', loss)\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt_g1 = torch.optim.Adam(self.G1.parameters(), self.lr, (self.hparams.b1, 0.999))\n",
        "        opt_d1 = torch.optim.Adam(self.D1.parameters(), self.lr, (self.hparams.b1, 0.999))\n",
        "        opt_g2 = torch.optim.Adam(self.G2.parameters(), self.lr, (self.hparams.b1, 0.999))\n",
        "        opt_d2 = torch.optim.Adam(self.D2.parameters(), self.lr, (self.hparams.b1, 0.999))\n",
        "        opt_r = torch.optim.Adam(self.R.parameters(), self.lr, (self.hparams.b1, 0.999))\n",
        "        return opt_g1, opt_d1, opt_g2, opt_d2, opt_r\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        temp2, _ = self(torch.randn(labels.shape[0], self.hparams.noise_size).type_as(imgs), labels)\n",
        "        return {'pred': self.pretrained(temp2.detach()), 'target': labels}\n",
        "\n",
        "    def validation_epoch_end(self, listofDicts):\n",
        "        prediction, target = torch.cat([x['pred'] for x in listofDicts]), torch.cat([x['target'] for x in listofDicts])\n",
        "        aurocTensor = tm.functional.auroc(prediction, target, num_classes=self.hparams.num_classes, average=None)\n",
        "        self.log('Pre/val/auroc', aurocTensor.min())\n",
        "        fprList, tprList, _ = tm.functional.roc(prediction, target, num_classes=self.hparams.num_classes)\n",
        "        \n",
        "        f = plt.figure()\n",
        "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "        for i, color in zip(range(self.hparams.num_classes), colors):\n",
        "            plt.plot(fprList[i].cpu(), tprList[i].cpu(), color=color,\n",
        "                    label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                    ''.format(i, aurocTensor[i].cpu()))\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Multi-class ROC')\n",
        "        plt.legend(loc='lower right')\n",
        "\n",
        "        self.logger.experiment.add_figure('StackGAN/val/ROC', f)\n",
        "        f.savefig(str(tune.get_trial_dir())+'ROC_epoch_'+str(self.current_epoch)+'.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0XraYESGws1"
      },
      "source": [
        "# Tune Hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbXpnU7Y4Cr9"
      },
      "source": [
        "## ResNet\n",
        "Here we tune hyperparameters as we train our modified ResNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otF0QlxlGsZs"
      },
      "source": [
        "%rm -rf ./drive/MyDrive/Logs/F/LensResnet/asha_tanh/"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TOMd0E5Q9mkw",
        "outputId": "bf7991a1-90c6-41cd-bd19-050319dbc823"
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_LensResnet(config, checkpoint_dir=None, num_epochs=10, num_gpus=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    kwargs = {\n",
        "        'limit_train_batches' : 0.05,\n",
        "        'limit_val_batches' : 0.05,\n",
        "        'progress_bar_refresh_rate' : math.ceil(8250*0.05//config['batch_size']),\n",
        "        'max_epochs' : num_epochs,\n",
        "        'prepare_data_per_node' : False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        'gpus' : math.ceil(num_gpus),\n",
        "        'logger' : TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        'callbacks' : [\n",
        "            TuneReportCheckpointCallback(\n",
        "                {\n",
        "                    'loss': 'LensResnet/val/Loss', \n",
        "                    # 'loss_D': 'LensResnet/D/train/loss', \n",
        "                    # Switch up the auroc vlues when training on different dataset -----------------------------------------------\n",
        "                    'auroc': 'LensResnet/val/AUROC', \n",
        "                    # 'auroc_cross': 'LensResnet/ResNet(J)/val/auroc',\n",
        "                },\n",
        "            ),\n",
        "        ],\n",
        "        'stochastic_weight_avg' : True,\n",
        "        # works with only one optimizer\n",
        "        # 'benchmark' : True,\n",
        "        # 'gradient_clip_val' : 0.5, \n",
        "        # 'gradient_clip_algorithm' : 'value',\n",
        "    }\n",
        "    \n",
        "    dm = npyImageData(config, 64)                                              # Specify image width here    \n",
        "    if checkpoint_dir is not None:\n",
        "        kwargs['resume_from_checkpoint'] = os.path.join(checkpoint_dir, 'checkpoint')\n",
        "        # model = LensResnet.load_from_checkpoint(kwargs['resume_from_checkpoint'], config=config)\n",
        "    # else:\n",
        "\n",
        "    model = LensResnet(config)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "\n",
        "# # __tune_asha_begin__\n",
        "def tune_LensResnet_asha(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_LensResnet,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial\n",
        "        ),\n",
        "        # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "        name='F/LensResnet/asha_tanh',\n",
        "        metric='auroc',\n",
        "        mode='max',\n",
        "        config={'learning_rate': tune.grid_search([1e-4, 1e-3, 1e-5, 1e-2, 1e-6, 1e-1, 1e-7]),\n",
        "                'batch_size': tune.grid_search([8, 16, 32, 64, 128])\n",
        "                },\n",
        "        # config={'learning_rate': 0.01,\n",
        "        #         'n_fmaps': 32,\n",
        "        #         'batch_size': 32,\n",
        "        #         },\n",
        "        stop=TrialPlateauStopper('auroc'),\n",
        "        resources_per_trial={'cpu': os.cpu_count(),\n",
        "                             'gpu': gpus_per_trial,\n",
        "                            },\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        scheduler = ASHAScheduler(max_t=num_epochs, grace_period=2,  reduction_factor=2),\n",
        "        progress_reporter=JupyterNotebookReporter(\n",
        "            overwrite=False,\n",
        "            parameter_columns=['learning_rate', 'batch_size'],\n",
        "            metric_columns=['loss', 'auroc', 'training_iteration'],\n",
        "            sort_by_metric=True,\n",
        "        ),\n",
        "        fail_fast = True,\n",
        "        # reuse_actors=True,\n",
        "        # num_samples=num_samples,\n",
        "        # resume='PROMPT',\n",
        "        # restore='/content/drive/MyDrive/Logs/delete/train_LensResnet_e42ac_00025_25_batch_size=8,learning_rate=0.01,n_fmaps=8_2021-07-28_21-16-18/checkpoint_epoch=4-step=2339',\n",
        "    )\n",
        "\n",
        "    print('Best checkpoint path found is: ', analysis.best_checkpoint)\n",
        "\n",
        "# __tune_asha_end__\n",
        "\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "# def tune_LensResnet_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "#     # print(os.cpu_count(), torch.cuda.device_count())\n",
        "#     analysis = tune.run(\n",
        "#         tune.with_parameters(\n",
        "#             train_LensResnet,\n",
        "#             num_epochs=num_epochs,\n",
        "#             num_gpus=gpus_per_trial\n",
        "#         ),\n",
        "#         # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "#         name='F/LensResnet/pbt_tanh',\n",
        "#         metric='auroc',\n",
        "#         mode='max',\n",
        "#         config={'learning_rate': 1e-4,\n",
        "#                 'batch_size': 8,\n",
        "#                 },\n",
        "#         # config={'learning_rate': 0.01,\n",
        "#         #         'n_fmaps': 32,\n",
        "#         #         'batch_size': 32,\n",
        "#         #         },\n",
        "#         # stop=TrialPlateauStopper('loss_G'),\n",
        "#         resources_per_trial={'cpu': os.cpu_count(),\n",
        "#                              'gpu': gpus_per_trial,\n",
        "#                             },\n",
        "#         local_dir='./drive/MyDrive/Logs',\n",
        "#         # Can't use RB2 as it requires mutations to be continuous\n",
        "#         scheduler = PopulationBasedTraining(\n",
        "#             time_attr='training_iteration',\n",
        "#             quantile_fraction=0.4,\n",
        "#             resample_probability=0.8,\n",
        "#             perturbation_interval=4,\n",
        "#             hyperparam_mutations={\n",
        "#                 'learning_rate': tune.loguniform(1e-7, 1e-1),\n",
        "#                 'batch_size': [8, 16, 32, 64, 128],\n",
        "#             },\n",
        "#         ),\n",
        "#         progress_reporter=JupyterNotebookReporter(\n",
        "#             overwrite=False,\n",
        "#             parameter_columns=['learning_rate', 'batch_size'],\n",
        "#             metric_columns=['loss', 'auroc', 'training_iteration'],\n",
        "#             # sort_by_metric=True,\n",
        "#         ),\n",
        "#         fail_fast = True,\n",
        "#         # reuse_actors=True,\n",
        "#         # num_samples=num_samples,\n",
        "#         resume='PROMPT',\n",
        "#         # restore='/content/drive/MyDrive/Logs/delete/train_LensResnet_e42ac_00027_27_batch_size=32,learning_rate=0.01,n_fmaps=8_2021-07-28_21-27-00/checkpoint_epoch=6-step=818',\n",
        "#         # restore='/content/drive/MyDrive/Logs/delete/train_LensResnet_e42ac_00056_56_batch_size=16,learning_rate=0.001,n_fmaps=16_2021-07-29_00-13-37/checkpoint_epoch=3-step=935',\n",
        "#         # restore='/content/drive/MyDrive/Logs/delete/train_LensResnet_e42ac_00060_60_batch_size=8,learning_rate=0.01,n_fmaps=16_2021-07-29_06-58-44/checkpoint_epoch=3-step=1871',\n",
        "#         # restore='/content/drive/MyDrive/Logs/delete/train_LensResnet_e42ac_00061_61_batch_size=16,learning_rate=0.01,n_fmaps=16_2021-07-29_02-41-53/checkpoint_epoch=4-step=1169',\n",
        "#         # restore='/content/drive/MyDrive/Logs/delete/train_LensResnet_e42ac_00061_61_batch_size=16,learning_rate=0.01,n_fmaps=16_2021-07-29_06-58-44/checkpoint_epoch=4-step=1169',\n",
        "#         # restore='/content/drive/MyDrive/Logs/delete/train_LensResnet_e42ac_00062_62_batch_size=32,learning_rate=0.01,n_fmaps=16_2021-07-29_06-58-44/checkpoint_epoch=4-step=584',\n",
        "#         # restore='/content/drive/MyDrive/Logs/delete/train_LensResnet_e42ac_00091_91_batch_size=16,learning_rate=0.001,n_fmaps=32_2021-07-29_15-46-04/checkpoint_epoch=2-step=701',\n",
        "#         # restore='/content/drive/MyDrive/Logs/delete/train_LensResnet_e42ac_00094_94_batch_size=128,learning_rate=0.001,n_fmaps=32_2021-07-29_18-06-24/checkpoint_epoch=2-step=86',\n",
        "#         # restore='/content/drive/MyDrive/Logs/delete/train_LensResnet_e42ac_00096_96_batch_size=16,learning_rate=0.01,n_fmaps=32_2021-07-29_18-06-24/checkpoint_epoch=2-step=701',\n",
        "#         # restore='/content/drive/MyDrive/Logs/delete/train_LensResnet_e42ac_00097_97_batch_size=32,learning_rate=0.01,n_fmaps=32_2021-07-29_18-06-24/checkpoint_epoch=2-step=350',\n",
        "#     )\n",
        "\n",
        "#     print('Best checkpoint path found is: ', analysis.best_checkpoint)\n",
        "\n",
        "# # __tune_pbt_end__\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_LensResnet_asha(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "        tune_LensResnet_pbt(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # ASHA scheduler\n",
        "        tune_LensResnet_asha(num_samples=1, num_epochs=10, gpus_per_trial=torch.cuda.device_count())\n",
        "        # Population based training\n",
        "        # tune_LensResnet_pbt(num_samples=1, num_epochs=30, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 1.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.48 GiB heap, 0.0/3.74 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /content/drive/MyDrive/Logs/F/LensResnet/asha_tanh<br>Number of trials: 16/35 (15 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensResnet_6ca12_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">          16</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">          32</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">          64</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">         128</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">          16</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">          32</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">          64</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">         128</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">          16</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">          32</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">          64</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">         128</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.01  </td><td style=\"text-align: right;\">           8</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m GPU available: True, used: True\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.48 GiB heap, 0.0/3.74 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /content/drive/MyDrive/Logs/F/LensResnet/asha_tanh<br>Number of trials: 17/35 (16 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensResnet_6ca12_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">          16</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">          32</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">          64</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">         128</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">          16</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">          32</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">          64</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">         128</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">          16</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">          32</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">          64</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">         128</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.01  </td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         0.01  </td><td style=\"text-align: right;\">          16</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   | Name          | Type             | Params\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m ---------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m 0 | backbone      | ResNet           | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m 1 | train_metrics | MetricCollection | 0     \n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m 2 | val_metrics   | MetricCollection | 0     \n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m ---------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m 11.2 M    Trainable params\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m 0         Non-trainable params\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m 11.2 M    Total params\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m 44.687    Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:373: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   f\"Your {mode}_dataloader has `shuffle=True`, it is best practice to turn\"\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m \r                                                              \r\rTraining: -1it [00:00, ?it/s]\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m \rTraining:   0%|          | 0/514 [00:00<00:00, 17623.13it/s]\rEpoch 0:   0%|          | 0/514 [00:00<00:00, 3483.64it/s]  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/auroc.py:143: UserWarning: Class 2 had 0 observations, omitted from AUROC calculation\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   warnings.warn(f\"Class {c} had 0 observations, omitted from AUROC calculation\", UserWarning)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m Batch no. : 4\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m tensor([[0.7117, 0.1174, 0.1708],\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m         [0.4030, 0.1628, 0.4342],\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m         [0.1231, 0.6888, 0.1881],\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m         [0.3086, 0.3950, 0.2965],\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m         [0.4426, 0.3525, 0.2049],\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m         [0.1477, 0.0725, 0.7798],\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m         [0.1265, 0.3542, 0.5193],\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m         [0.1184, 0.7528, 0.1288]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m tensor([0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-22 04:57:26,755\tERROR trial_runner.py:773 -- Trial train_LensResnet_6ca12_00000: Error processing event.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py\", line 739, in _process_trial\n",
            "    results = self.trial_executor.fetch_result(trial)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py\", line 729, in fetch_result\n",
            "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/worker.py\", line 1564, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=1504, ip=172.28.0.2)\n",
            "  File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 178, in train_buffered\n",
            "    result = self.train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 237, in train\n",
            "    result = self.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 366, in step\n",
            "    self._report_thread_runner_error(block=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
            "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
            "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
            "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=1504, ip=172.28.0.2)\n",
            "  File \"<ipython-input-33-180836173841>\", line 39, in training_step\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/collections.py\", line 110, in forward\n",
            "    return {k: m(*args, **m._filter_kwargs(**kwargs)) for k, m in self.items()}\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/collections.py\", line 110, in <dictcomp>\n",
            "    return {k: m(*args, **m._filter_kwargs(**kwargs)) for k, m in self.items()}\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\", line 203, in forward\n",
            "    self._forward_cache = self.compute()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\", line 365, in wrapped_func\n",
            "    self._computed = compute(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/classification/auroc.py\", line 184, in compute\n",
            "    self.max_fpr,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/auroc.py\", line 150, in _auroc_compute\n",
            "    fpr, tpr, _ = roc(preds, target, num_classes, pos_label, sample_weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 273, in roc\n",
            "    return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 186, in _roc_compute\n",
            "    return _roc_compute_multi_class(preds, target, num_classes, sample_weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 118, in _roc_compute_multi_class\n",
            "    sample_weights=sample_weights,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 273, in roc\n",
            "    return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 185, in _roc_compute\n",
            "    return _roc_compute_single_class(preds, target, pos_label, sample_weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 68, in _roc_compute_single_class\n",
            "    preds=preds, target=target, sample_weights=sample_weights, pos_label=pos_label\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/precision_recall_curve.py\", line 59, in _binary_clf_curve\n",
            "    fps = 1 + threshold_idxs - tps\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=1504, ip=172.28.0.2)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 248, in run\n",
            "    self._entrypoint()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
            "    self._status_reporter.get_checkpoint())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 339, in inner\n",
            "    trainable(config, **fn_kwargs)\n",
            "  File \"<ipython-input-35-b8bfbc05d3e0>\", line 40, in train_LensResnet\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 553, in fit\n",
            "    self._run(model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 918, in _run\n",
            "    self._dispatch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _dispatch\n",
            "    self.accelerator.start_training(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
            "    self.training_type_plugin.start_training(trainer)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in start_training\n",
            "    self._results = trainer.run_stage()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 996, in run_stage\n",
            "    return self._run_train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1045, in _run_train\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
            "    epoch_output = self.epoch_loop.run(train_dataloader)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 130, in advance\n",
            "    batch_output = self.batch_loop.run(batch, self.iteration_count, self._dataloader_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 101, in run\n",
            "    super().run(batch, batch_idx, dataloader_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 148, in advance\n",
            "    result = self._run_optimization(batch_idx, split_batch, opt_idx, optimizer)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 202, in _run_optimization\n",
            "    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 404, in _optimizer_step\n",
            "    using_lbfgs=is_lbfgs,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 1618, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 209, in step\n",
            "    self.__optimizer_step(*args, closure=closure, profiler_name=profiler_name, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 129, in __optimizer_step\n",
            "    trainer.accelerator.optimizer_step(optimizer, self._optimizer_idx, lambda_closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 296, in optimizer_step\n",
            "    self.run_optimizer_step(optimizer, opt_idx, lambda_closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 303, in run_optimizer_step\n",
            "    self.training_type_plugin.optimizer_step(optimizer, lambda_closure=lambda_closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 226, in optimizer_step\n",
            "    optimizer.step(closure=lambda_closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\", line 66, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 236, in _training_step_and_backward_closure\n",
            "    result = self.training_step_and_backward(split_batch, batch_idx, opt_idx, optimizer, hiddens)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 537, in training_step_and_backward\n",
            "    result = self._training_step(split_batch, batch_idx, opt_idx, hiddens)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 307, in _training_step\n",
            "    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 193, in training_step\n",
            "    return self.training_type_plugin.training_step(*step_kwargs.values())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 172, in training_step\n",
            "    return self.model.training_step(*args, **kwargs)\n",
            "  File \"<ipython-input-33-180836173841>\", line 44, in training_step\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\", line 203, in forward\n",
            "    self._forward_cache = self.compute()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\", line 365, in wrapped_func\n",
            "    self._computed = compute(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/classification/auroc.py\", line 184, in compute\n",
            "    self.max_fpr,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/auroc.py\", line 150, in _auroc_compute\n",
            "    fpr, tpr, _ = roc(preds, target, num_classes, pos_label, sample_weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 273, in roc\n",
            "    return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 186, in _roc_compute\n",
            "    return _roc_compute_multi_class(preds, target, num_classes, sample_weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 118, in _roc_compute_multi_class\n",
            "    sample_weights=sample_weights,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 273, in roc\n",
            "    return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 185, in _roc_compute\n",
            "    return _roc_compute_single_class(preds, target, pos_label, sample_weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 68, in _roc_compute_single_class\n",
            "    preds=preds, target=target, sample_weights=sample_weights, pos_label=pos_label\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/precision_recall_curve.py\", line 59, in _binary_clf_curve\n",
            "    fps = 1 + threshold_idxs - tps\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for train_LensResnet_6ca12_00000:\n",
            "  {}\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m 2021-08-22 04:57:26,711\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"<ipython-input-33-180836173841>\", line 39, in training_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return forward_call(*input, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/collections.py\", line 110, in forward\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return {k: m(*args, **m._filter_kwargs(**kwargs)) for k, m in self.items()}\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/collections.py\", line 110, in <dictcomp>\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return {k: m(*args, **m._filter_kwargs(**kwargs)) for k, m in self.items()}\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return forward_call(*input, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\", line 203, in forward\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._forward_cache = self.compute()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\", line 365, in wrapped_func\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._computed = compute(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/classification/auroc.py\", line 184, in compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.max_fpr,\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/auroc.py\", line 150, in _auroc_compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     fpr, tpr, _ = roc(preds, target, num_classes, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 273, in roc\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 186, in _roc_compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute_multi_class(preds, target, num_classes, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 118, in _roc_compute_multi_class\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     sample_weights=sample_weights,\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 273, in roc\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 185, in _roc_compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute_single_class(preds, target, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 68, in _roc_compute_single_class\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     preds=preds, target=target, sample_weights=sample_weights, pos_label=pos_label\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/precision_recall_curve.py\", line 59, in _binary_clf_curve\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     fps = 1 + threshold_idxs - tps\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 248, in run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 339, in inner\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"<ipython-input-35-b8bfbc05d3e0>\", line 40, in train_LensResnet\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 553, in fit\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._run(model)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 918, in _run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _dispatch\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.accelerator.start_training(self)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.training_type_plugin.start_training(trainer)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in start_training\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 996, in run_stage\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1045, in _run_train\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.fit_loop.run()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     epoch_output = self.epoch_loop.run(train_dataloader)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 130, in advance\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     batch_output = self.batch_loop.run(batch, self.iteration_count, self._dataloader_idx)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 101, in run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     super().run(batch, batch_idx, dataloader_idx)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 148, in advance\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     result = self._run_optimization(batch_idx, split_batch, opt_idx, optimizer)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 202, in _run_optimization\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 404, in _optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     using_lbfgs=is_lbfgs,\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 1618, in optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     optimizer.step(closure=optimizer_closure)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 209, in step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.__optimizer_step(*args, closure=closure, profiler_name=profiler_name, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 129, in __optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     trainer.accelerator.optimizer_step(optimizer, self._optimizer_idx, lambda_closure=closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 296, in optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.run_optimizer_step(optimizer, opt_idx, lambda_closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 303, in run_optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.training_type_plugin.optimizer_step(optimizer, lambda_closure=lambda_closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 226, in optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     optimizer.step(closure=lambda_closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return func(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return func(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\", line 66, in step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     loss = closure()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 236, in _training_step_and_backward_closure\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     result = self.training_step_and_backward(split_batch, batch_idx, opt_idx, optimizer, hiddens)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 537, in training_step_and_backward\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     result = self._training_step(split_batch, batch_idx, opt_idx, hiddens)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 307, in _training_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     training_step_output = self.trainer.accelerator.training_step(step_kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 193, in training_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return self.training_type_plugin.training_step(*step_kwargs.values())\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 172, in training_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return self.model.training_step(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"<ipython-input-33-180836173841>\", line 44, in training_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return forward_call(*input, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\", line 203, in forward\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._forward_cache = self.compute()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\", line 365, in wrapped_func\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._computed = compute(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/classification/auroc.py\", line 184, in compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.max_fpr,\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/auroc.py\", line 150, in _auroc_compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     fpr, tpr, _ = roc(preds, target, num_classes, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 273, in roc\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 186, in _roc_compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute_multi_class(preds, target, num_classes, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 118, in _roc_compute_multi_class\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     sample_weights=sample_weights,\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 273, in roc\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 185, in _roc_compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute_single_class(preds, target, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 68, in _roc_compute_single_class\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     preds=preds, target=target, sample_weights=sample_weights, pos_label=pos_label\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/precision_recall_curve.py\", line 59, in _binary_clf_curve\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     fps = 1 + threshold_idxs - tps\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m Exception in thread Thread-2:\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"<ipython-input-33-180836173841>\", line 39, in training_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return forward_call(*input, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/collections.py\", line 110, in forward\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return {k: m(*args, **m._filter_kwargs(**kwargs)) for k, m in self.items()}\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/collections.py\", line 110, in <dictcomp>\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return {k: m(*args, **m._filter_kwargs(**kwargs)) for k, m in self.items()}\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return forward_call(*input, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\", line 203, in forward\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._forward_cache = self.compute()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\", line 365, in wrapped_func\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._computed = compute(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/classification/auroc.py\", line 184, in compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.max_fpr,\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/auroc.py\", line 150, in _auroc_compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     fpr, tpr, _ = roc(preds, target, num_classes, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 273, in roc\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 186, in _roc_compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute_multi_class(preds, target, num_classes, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 118, in _roc_compute_multi_class\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     sample_weights=sample_weights,\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 273, in roc\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 185, in _roc_compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute_single_class(preds, target, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 68, in _roc_compute_single_class\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     preds=preds, target=target, sample_weights=sample_weights, pos_label=pos_label\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/precision_recall_curve.py\", line 59, in _binary_clf_curve\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     fps = 1 + threshold_idxs - tps\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m During handling of the above exception, another exception occurred:\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.run()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 267, in run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     raise e\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 248, in run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 339, in inner\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"<ipython-input-35-b8bfbc05d3e0>\", line 40, in train_LensResnet\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 553, in fit\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._run(model)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 918, in _run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _dispatch\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.accelerator.start_training(self)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.training_type_plugin.start_training(trainer)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in start_training\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 996, in run_stage\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1045, in _run_train\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.fit_loop.run()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     epoch_output = self.epoch_loop.run(train_dataloader)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 130, in advance\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     batch_output = self.batch_loop.run(batch, self.iteration_count, self._dataloader_idx)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 101, in run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     super().run(batch, batch_idx, dataloader_idx)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 148, in advance\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     result = self._run_optimization(batch_idx, split_batch, opt_idx, optimizer)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 202, in _run_optimization\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 404, in _optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     using_lbfgs=is_lbfgs,\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 1618, in optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     optimizer.step(closure=optimizer_closure)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 209, in step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.__optimizer_step(*args, closure=closure, profiler_name=profiler_name, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 129, in __optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     trainer.accelerator.optimizer_step(optimizer, self._optimizer_idx, lambda_closure=closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 296, in optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.run_optimizer_step(optimizer, opt_idx, lambda_closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 303, in run_optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.training_type_plugin.optimizer_step(optimizer, lambda_closure=lambda_closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 226, in optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     optimizer.step(closure=lambda_closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return func(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return func(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\", line 66, in step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     loss = closure()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 236, in _training_step_and_backward_closure\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     result = self.training_step_and_backward(split_batch, batch_idx, opt_idx, optimizer, hiddens)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 537, in training_step_and_backward\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     result = self._training_step(split_batch, batch_idx, opt_idx, hiddens)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 307, in _training_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     training_step_output = self.trainer.accelerator.training_step(step_kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 193, in training_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return self.training_type_plugin.training_step(*step_kwargs.values())\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 172, in training_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return self.model.training_step(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"<ipython-input-33-180836173841>\", line 44, in training_step\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return forward_call(*input, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\", line 203, in forward\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._forward_cache = self.compute()\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\", line 365, in wrapped_func\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self._computed = compute(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/classification/auroc.py\", line 184, in compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     self.max_fpr,\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/auroc.py\", line 150, in _auroc_compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     fpr, tpr, _ = roc(preds, target, num_classes, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 273, in roc\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 186, in _roc_compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute_multi_class(preds, target, num_classes, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 118, in _roc_compute_multi_class\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     sample_weights=sample_weights,\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 273, in roc\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 185, in _roc_compute\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     return _roc_compute_single_class(preds, target, pos_label, sample_weights)\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/roc.py\", line 68, in _roc_compute_single_class\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     preds=preds, target=target, sample_weights=sample_weights, pos_label=pos_label\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/precision_recall_curve.py\", line 59, in _binary_clf_curve\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m     fps = 1 + threshold_idxs - tps\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
            "\u001b[2m\u001b[36m(pid=1504)\u001b[0m \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.6/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.48 GiB heap, 0.0/3.74 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /content/drive/MyDrive/Logs/F/LensResnet/asha_tanh<br>Number of trials: 17/35 (1 ERROR, 16 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensResnet_6ca12_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">          16</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">          32</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">          64</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">         128</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00005</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00006</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">          16</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00007</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">          32</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00008</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">          64</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00009</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">         128</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00010</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00011</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">          16</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00012</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">          32</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00013</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">          64</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00014</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         1e-05 </td><td style=\"text-align: right;\">         128</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00015</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.01  </td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00016</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.01  </td><td style=\"text-align: right;\">          16</td></tr>\n",
              "<tr><td>train_LensResnet_6ca12_00000</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">           8</td></tr>\n",
              "</tbody>\n",
              "</table><br>Number of errored trials: 1<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                       </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensResnet_6ca12_00000</td><td style=\"text-align: right;\">           1</td><td>/content/drive/MyDrive/Logs/F/LensResnet/asha_tanh/train_LensResnet_6ca12_00000_0_batch_size=8,learning_rate=0.0001_2021-08-22_04-57-17/error.txt</td></tr>\n",
              "</tbody>\n",
              "</table><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TuneError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-b8bfbc05d3e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# ASHA scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mtune_LensResnet_asha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;31m# Population based training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# tune_LensResnet_pbt(num_samples=1, num_epochs=30, gpus_per_trial=torch.cuda.device_count())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-b8bfbc05d3e0>\u001b[0m in \u001b[0;36mtune_LensResnet_asha\u001b[0;34m(num_samples, num_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0msort_by_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         ),\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mfail_fast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;31m# reuse_actors=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# num_samples=num_samples,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_LensResnet_6ca12_00000])"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33OXrLjWn0II"
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_LensResnet_tune_checkpoint(config, checkpoint_dir=None,\n",
        "                                     num_epochs=10,\n",
        "                                     num_gpus=torch.cuda.device_count()\n",
        "                                     ):\n",
        "    # data_dir = os.path.expanduser('/content/images/')\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=num_epochs,\n",
        "        prepare_data_per_node = False,\n",
        "        num_sanity_val_steps=0,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        gpus=math.ceil(num_gpus),\n",
        "        # tpu_cores = 8,\n",
        "        logger=TensorBoardLogger(\n",
        "            save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        # progress_bar_refresh_rate=1,\n",
        "        callbacks=[\n",
        "            TuneReportCheckpointCallback(\n",
        "                metrics={\n",
        "                    'loss': 'ResNet/val/loss',\n",
        "                    'auroc': 'ResNet/val/auroc',\n",
        "                },\n",
        "            )\n",
        "        ],\n",
        "        stochastic_weight_avg=True,\n",
        "    )\n",
        "\n",
        "    dm = npyImageData(config, data_dir)\n",
        "    \n",
        "    if checkpoint_dir:\n",
        "        # Currently, this leads to errors:\n",
        "        # model = LensResnet.load_from_checkpoint(\n",
        "        #     os.path.join(checkpoint, 'checkpoint'))\n",
        "        # Workaround:\n",
        "        ckpt = pl_load(\n",
        "            os.path.join(checkpoint_dir, 'checkpoint'),\n",
        "            map_location=lambda storage, loc: storage)\n",
        "        model = LensResnet._load_model_state(\n",
        "            ckpt, config=config, \n",
        "            # data_dir=data_dir\n",
        "            )\n",
        "        trainer.current_epoch = ckpt['epoch']\n",
        "    else:\n",
        "        model = LensResnet(config, \n",
        "                        #  data_dir\n",
        "                         )\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "\n",
        "# __tune_asha_begin__\n",
        "def tune_LensResnet_asha(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    # config = {\n",
        "    #     'learning_rate': tune.choice([1e-5, 1e-4, 1e-3, 1e-2]),\n",
        "    #     'batch_size': tune.choice([128, 64, 32]),\n",
        "    # }\n",
        "\n",
        "    best = {'batch_size': 128, 'learning_rate': 0.0001}    \n",
        "\n",
        "    scheduler = ASHAScheduler(\n",
        "        max_t=num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "\n",
        "    reporter = CLIReporter(\n",
        "        # overwrite=True,\n",
        "        parameter_columns=['learning_rate', 'batch_size'],\n",
        "        metric_columns=['loss', 'auroc', 'training_iteration'])\n",
        "\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_LensResnet_tune_checkpoint,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial),\n",
        "        name='LensResnet_J',                                                    # Change with dataset change\n",
        "        metric='auroc',\n",
        "        mode='max',\n",
        "        config=best,\n",
        "        resources_per_trial={\n",
        "            'cpu': os.cpu_count(),\n",
        "            'gpu': gpus_per_trial,\n",
        "            # 'tpu': 8,\n",
        "        },\n",
        "        # num_samples=num_samples,\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter,\n",
        "        fail_fast = True,\n",
        "        restore = '/content/drive/MyDrive/Logs/LensResnet_J/train_LensResnet_tune_checkpoint_c74d9_00003_3_batch_size=128,learning_rate=0.0001_2021-07-08_01-03-43/checkpoint_epoch=2-step=1406',\n",
        "        # '/content/drive/MyDrive/Logs/tune_LensResnet_asha_model_f/train_LensResnet_tune_checkpoint_e32ba_00000_0_batch_size=64,learning_rate=0.0001_2021-07-06_03-33-10/checkpoint_epoch=14-step=4689',\n",
        "        # resume=True,\n",
        "        )\n",
        "\n",
        "    print('Best hyperparameters found were: ', analysis.best_config)\n",
        "# __tune_asha_end__\n",
        "\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_LensResnet_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    config = {\n",
        "        'learning_rate': 1e-3,\n",
        "        'batch_size': 64,\n",
        "    }\n",
        "\n",
        "    scheduler = PopulationBasedTraining(\n",
        "        perturbation_interval=4,\n",
        "        hyperparam_mutations={\n",
        "            'learning_rate': [1e-5, 1e-4, 1e-3, 1e-2],\n",
        "            'batch_size': [32, 64, 128]\n",
        "        })\n",
        "\n",
        "    reporter = CLIReporter(\n",
        "        # overwrite=True,\n",
        "        parameter_columns=['learning_rate', 'batch_size'],\n",
        "        metric_columns=['loss', 'auroc', 'training_iteration'])\n",
        "\n",
        "    analysis = tune.run(\n",
        "        # resume=True,\n",
        "        tune.with_parameters(\n",
        "            train_LensResnet_tune_checkpoint,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial),\n",
        "        metric='auroc',\n",
        "        mode='max',\n",
        "        resources_per_trial={\n",
        "            'cpu': os.cpu_count(),\n",
        "            'gpu': gpus_per_trial,\n",
        "            # 'tpu': 8,\n",
        "        },\n",
        "        fail_fast = True,\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter,\n",
        "        local_dir='./drive/MyDrive/Logs' ,\n",
        "        name='tune_LensResnet_pbt')\n",
        "\n",
        "    print('Best hyperparameters found were: ', analysis.best_config)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_LensResnet_asha(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "        tune_LensResnet_pbt(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # ASHA scheduler\n",
        "        tune_LensResnet_asha(num_samples=12, num_epochs=20, gpus_per_trial=torch.cuda.device_count())\n",
        "        # Population based training\n",
        "        # tune_LensResnet_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASOiXXn-36Wf"
      },
      "source": [
        "Trying out Auto Tuning of learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FtDpDdAADLi"
      },
      "source": [
        "# Can't work with multiple optimizers\n",
        "config = {\n",
        "    'learning_rate': 1e-4, 'batch_size': 128, 'feature_maps': 64,\n",
        "}\n",
        "dm = npyImageData(config)\n",
        "generator = StackGAN(config)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    # logger=,\n",
        "    # checkpoint_callback=,\n",
        "    default_root_dir='./drive/MyDrive/Logs/', \n",
        "    gpus=1,\n",
        "    auto_select_gpus=True, \n",
        "    # tpu_cores=\n",
        "    progress_bar_refresh_rate=1,\n",
        "    # fast_dev_run=,\n",
        "    max_epochs=5,\n",
        "    # max_time=,\n",
        "    # limit_train_batches=,\n",
        "    # flush_logs_every_n_steps=,\n",
        "    # log_every_n_steps=,\n",
        "    # resume_from_checkpoint='./drive/MyDrive/Logs/lr_find_temp_model.ckpt',\n",
        "    auto_lr_find = True,\n",
        "    # auto_scale_batch_size=True,\n",
        "    # prepare_data_per_node=,\n",
        "    )\n",
        "\n",
        "# Run learning rate finder\n",
        "lr_finder = trainer.tuner.lr_find(generator, dm)\n",
        "\n",
        "# # Results can be found in\n",
        "# # lr_finder.results\n",
        "\n",
        "# Plot with\n",
        "fig = lr_finder.plot(suggest=True)\n",
        "fig.show()\n",
        "\n",
        "# Pick point based on plot, or get suggestion\n",
        "new_lr = lr_finder.suggestion()\n",
        "\n",
        "# # update hparams of the model\n",
        "# model.hparams.lr = new_lr\n",
        "\n",
        "# # Fit model\n",
        "# trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPxU2-AggCrI"
      },
      "source": [
        "## Stage 1\n",
        "Here we tune hyperparameters as we train our modified DCGAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr0jbpHhgs79"
      },
      "source": [
        "%rm -rf ./drive/MyDrive/Logs/Stage1/pbt_cpu_wgan/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OOr5f_bgLoM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "8c8e0d73-6f5f-470d-85ab-3c23f9539ffa"
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_Stage1(config, checkpoint_dir=None, num_epochs=10, num_gpus=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    kwargs = {\n",
        "        'limit_train_batches' : 0.05,\n",
        "        'limit_val_batches' : 0.05,\n",
        "        'progress_bar_refresh_rate' : 0,    #math.ceil(8250*0.05//config['batch_size']),\n",
        "        'max_epochs' : num_epochs,\n",
        "        'prepare_data_per_node' : False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        'gpus' : math.ceil(num_gpus),\n",
        "        'logger' : TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        'callbacks' : [\n",
        "            TuneReportCheckpointCallback(\n",
        "                {\n",
        "                    'loss_G': 'Stage1/G/train/loss', \n",
        "                    'loss_D': 'Stage1/D/train/loss', \n",
        "                    # Switch up the FID vlues when training on different dataset -----------------------------------------------\n",
        "                    'FID': 'Stage1/ResNet(F)/val/FID', \n",
        "                    'FID_cross': 'Stage1/ResNet(J)/val/FID',\n",
        "                },\n",
        "            ),\n",
        "        ],\n",
        "        # 'stochastic_weight_avg' : True,\n",
        "        # works with only one optimizer\n",
        "        # 'benchmark' : True,\n",
        "        # 'gradient_clip_val' : 0.5, \n",
        "        # 'gradient_clip_algorithm' : 'value',\n",
        "    }\n",
        "    \n",
        "    dm = npyImageData(config, 64)                                              # Specify image width here    \n",
        "    if checkpoint_dir is not None:\n",
        "        kwargs['resume_from_checkpoint'] = os.path.join(checkpoint_dir, 'checkpoint')\n",
        "        # model = Stage1.load_from_checkpoint(kwargs['resume_from_checkpoint'], config=config)\n",
        "    # else:\n",
        "\n",
        "    model = Stage1(config)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "\n",
        "# # # __tune_asha_begin__\n",
        "# def tune_Stage1_asha(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "#     # print(os.cpu_count(), torch.cuda.device_count())\n",
        "#     analysis = tune.run(\n",
        "#         tune.with_parameters(\n",
        "#             train_Stage1,\n",
        "#             num_epochs=num_epochs,\n",
        "#             num_gpus=gpus_per_trial\n",
        "#         ),\n",
        "#         # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "#         name='Stage1/pbt/J',\n",
        "#         metric='FID',\n",
        "#         mode='min',\n",
        "#         config={'learning_rate': 1e-4,\n",
        "#                 'n_fmaps': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "#                 'batch_size': 8,\n",
        "#                 },\n",
        "#         # config={'learning_rate': 0.01,\n",
        "#         #         'n_fmaps': 32,\n",
        "#         #         'batch_size': 32,\n",
        "#         #         },\n",
        "#         # stop=TrialPlateauStopper('loss_G'),\n",
        "#         resources_per_trial={'cpu': os.cpu_count(),\n",
        "#                              'gpu': gpus_per_trial,\n",
        "#                             },\n",
        "#         local_dir='./drive/MyDrive/Logs',\n",
        "#         scheduler = ASHAScheduler(max_t=num_epochs, grace_period=2,  reduction_factor=2),\n",
        "#         progress_reporter=JupyterNotebookReporter(\n",
        "#             overwrite=True,\n",
        "#             parameter_columns=['learning_rate', 'n_fmaps', 'batch_size'],\n",
        "#             metric_columns=['loss_G', 'loss_D', 'FID', 'FID_cross', 'training_iteration'],\n",
        "#             sort_by_metric=True,\n",
        "#         ),\n",
        "#         fail_fast = True,\n",
        "#         # reuse_actors=True,\n",
        "#         # num_samples=num_samples,\n",
        "#         resume='PROMPT',\n",
        "# #         restore='/content/drive/MyDrive/Logs/delete/train_Stage1_e42ac_00025_25_batch_size=8,learning_rate=0.01,n_fmaps=8_2021-07-28_21-16-18/checkpoint_epoch=4-step=2339',\n",
        "#     )\n",
        "\n",
        "# #     print('Best hyperparameters found were: ', analysis.best_config)\n",
        "\n",
        "# # # __tune_asha_end__\n",
        "\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_Stage1_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_Stage1,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial\n",
        "        ),\n",
        "        # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "        name='F/Stage1/pbt_tanh',\n",
        "        metric='FID',\n",
        "        mode='min',\n",
        "        config={'learning_rate': 1e-4,\n",
        "                'n_fmaps': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "                'batch_size': 8,\n",
        "                },\n",
        "        # config={'learning_rate': 0.01,\n",
        "        #         'n_fmaps': 32,\n",
        "        #         'batch_size': 32,\n",
        "        #         },\n",
        "        # stop=TrialPlateauStopper('loss_G'),\n",
        "        resources_per_trial={'cpu': os.cpu_count(),\n",
        "                             'gpu': gpus_per_trial,\n",
        "                            },\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        # Can't use RB2 as it requires mutations to be continuous\n",
        "        scheduler = PopulationBasedTraining(\n",
        "            time_attr='training_iteration',\n",
        "            quantile_fraction=0.4,\n",
        "            resample_probability=0.8,\n",
        "            perturbation_interval=4,\n",
        "            hyperparam_mutations={\n",
        "                'learning_rate': tune.loguniform(1e-7, 1e-1),\n",
        "                'batch_size': [8, 16, 32, 64, 128],\n",
        "            },\n",
        "        ),\n",
        "        progress_reporter=JupyterNotebookReporter(\n",
        "            overwrite=True,\n",
        "            parameter_columns=['learning_rate', 'n_fmaps', 'batch_size'],\n",
        "            metric_columns=['loss_G', 'loss_D', 'FID', 'FID_cross', 'training_iteration'],\n",
        "            # sort_by_metric=True,\n",
        "        ),\n",
        "        fail_fast = True,\n",
        "        # reuse_actors=True,\n",
        "        # num_samples=num_samples,\n",
        "        resume='PROMPT',\n",
        "        # restore='/content/drive/MyDrive/Logs/delete/train_Stage1_e42ac_00027_27_batch_size=32,learning_rate=0.01,n_fmaps=8_2021-07-28_21-27-00/checkpoint_epoch=6-step=818',\n",
        "        # restore='/content/drive/MyDrive/Logs/delete/train_Stage1_e42ac_00056_56_batch_size=16,learning_rate=0.001,n_fmaps=16_2021-07-29_00-13-37/checkpoint_epoch=3-step=935',\n",
        "        # restore='/content/drive/MyDrive/Logs/delete/train_Stage1_e42ac_00060_60_batch_size=8,learning_rate=0.01,n_fmaps=16_2021-07-29_06-58-44/checkpoint_epoch=3-step=1871',\n",
        "        # restore='/content/drive/MyDrive/Logs/delete/train_Stage1_e42ac_00061_61_batch_size=16,learning_rate=0.01,n_fmaps=16_2021-07-29_02-41-53/checkpoint_epoch=4-step=1169',\n",
        "        # restore='/content/drive/MyDrive/Logs/delete/train_Stage1_e42ac_00061_61_batch_size=16,learning_rate=0.01,n_fmaps=16_2021-07-29_06-58-44/checkpoint_epoch=4-step=1169',\n",
        "        # restore='/content/drive/MyDrive/Logs/delete/train_Stage1_e42ac_00062_62_batch_size=32,learning_rate=0.01,n_fmaps=16_2021-07-29_06-58-44/checkpoint_epoch=4-step=584',\n",
        "        # restore='/content/drive/MyDrive/Logs/delete/train_Stage1_e42ac_00091_91_batch_size=16,learning_rate=0.001,n_fmaps=32_2021-07-29_15-46-04/checkpoint_epoch=2-step=701',\n",
        "        # restore='/content/drive/MyDrive/Logs/delete/train_Stage1_e42ac_00094_94_batch_size=128,learning_rate=0.001,n_fmaps=32_2021-07-29_18-06-24/checkpoint_epoch=2-step=86',\n",
        "        # restore='/content/drive/MyDrive/Logs/delete/train_Stage1_e42ac_00096_96_batch_size=16,learning_rate=0.01,n_fmaps=32_2021-07-29_18-06-24/checkpoint_epoch=2-step=701',\n",
        "        # restore='/content/drive/MyDrive/Logs/delete/train_Stage1_e42ac_00097_97_batch_size=32,learning_rate=0.01,n_fmaps=32_2021-07-29_18-06-24/checkpoint_epoch=2-step=350',\n",
        "    )\n",
        "\n",
        "    print('Best checkpoint path found is: ', analysis.best_checkpoint)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_Stage1_asha(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "        tune_Stage1_pbt(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # ASHA scheduler\n",
        "        # tune_Stage1_asha(num_samples=1, num_epochs=10, gpus_per_trial=torch.cuda.device_count())\n",
        "        # Population based training\n",
        "        tune_Stage1_pbt(num_samples=1, num_epochs=30, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.3/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 10 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.46 GiB heap, 0.0/3.73 GiB objects (0.0/1.0 GPU_group_0_beac11d826a7d79a76cabf34ea966465, 0.0/2.0 CPU_group_beac11d826a7d79a76cabf34ea966465, 0.0/1.0 GPU_group_beac11d826a7d79a76cabf34ea966465, 0.0/2.0 CPU_group_0_beac11d826a7d79a76cabf34ea966465, 0.0/1.0 accelerator_type:K80)<br>Current best trial: b4baf_00001 with FID=1036.5872802734375 and parameters={'learning_rate': 1.293064765963745e-07, 'n_fmaps': 32, 'batch_size': 128}<br>Result logdir: /content/drive/MyDrive/Logs/F/Stage1/pbt_tanh<br>Number of trials: 5/5 (3 ERROR, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name              </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">     loss_D</th><th style=\"text-align: right;\">    FID</th><th style=\"text-align: right;\">  FID_cross</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_Stage1_b4baf_00002</td><td>RUNNING </td><td>172.28.0.2:9410</td><td style=\"text-align: right;\">    1.55168e-07</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">13.1917 </td><td style=\"text-align: right;\">2.95509e-06</td><td style=\"text-align: right;\">1056.06</td><td style=\"text-align: right;\">    1022.24</td><td style=\"text-align: right;\">                  28</td></tr>\n",
              "<tr><td>train_Stage1_b4baf_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">    1.29306e-07</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">13.1274 </td><td style=\"text-align: right;\">4.41215e-06</td><td style=\"text-align: right;\">1036.59</td><td style=\"text-align: right;\">    1023.18</td><td style=\"text-align: right;\">                  25</td></tr>\n",
              "<tr><td>train_Stage1_b4baf_00000</td><td>ERROR   </td><td>               </td><td style=\"text-align: right;\">    7.10993e-07</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\"> 7.86082</td><td style=\"text-align: right;\">0.00141576 </td><td style=\"text-align: right;\">2183.95</td><td style=\"text-align: right;\">    5852.13</td><td style=\"text-align: right;\">                  17</td></tr>\n",
              "<tr><td>train_Stage1_b4baf_00004</td><td>ERROR   </td><td>               </td><td style=\"text-align: right;\">    1.05036e-05</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 7.5413 </td><td style=\"text-align: right;\">0.000866798</td><td style=\"text-align: right;\">2539.51</td><td style=\"text-align: right;\">    4158.96</td><td style=\"text-align: right;\">                  17</td></tr>\n",
              "<tr><td>train_Stage1_b4baf_00003</td><td>ERROR   </td><td>               </td><td style=\"text-align: right;\">    1.25788e-06</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\"> 9.35253</td><td style=\"text-align: right;\">0.000120068</td><td style=\"text-align: right;\">2516.17</td><td style=\"text-align: right;\">    4421.87</td><td style=\"text-align: right;\">                  17</td></tr>\n",
              "</tbody>\n",
              "</table><br>Number of errored trials: 3<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name              </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                        </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_Stage1_b4baf_00000</td><td style=\"text-align: right;\">           1</td><td>/content/drive/MyDrive/Logs/F/Stage1/pbt_tanh/train_Stage1_b4baf_00000_0_n_fmaps=8_2021-08-19_23-46-43/error.txt  </td></tr>\n",
              "<tr><td>train_Stage1_b4baf_00004</td><td style=\"text-align: right;\">           1</td><td>/content/drive/MyDrive/Logs/F/Stage1/pbt_tanh/train_Stage1_b4baf_00004_4_n_fmaps=128_2021-08-19_23-57-33/error.txt</td></tr>\n",
              "<tr><td>train_Stage1_b4baf_00003</td><td style=\"text-align: right;\">           1</td><td>/content/drive/MyDrive/Logs/F/Stage1/pbt_tanh/train_Stage1_b4baf_00003_3_n_fmaps=64_2021-08-19_23-53-56/error.txt </td></tr>\n",
              "</tbody>\n",
              "</table><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-20 02:47:34,125\tERROR tune.py:546 -- Trials did not complete: [train_Stage1_b4baf_00000, train_Stage1_b4baf_00004, train_Stage1_b4baf_00003, train_Stage1_b4baf_00002, train_Stage1_b4baf_00001]\n",
            "2021-08-20 02:47:34,126\tINFO tune.py:550 -- Total run time: 4599.78 seconds (4595.41 seconds for the tuning loop).\n",
            "2021-08-20 02:47:34,131\tWARNING tune.py:555 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best checkpoint path found is:  /content/drive/MyDrive/Logs/F/Stage1/pbt_tanh/train_Stage1_b4baf_00001_1_n_fmaps=16_2021-08-19_23-46-43/checkpoint_epoch=21-step=9856/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYz8Db9q-AVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269fe71a-5925-46fa-8d10-699c8b443580"
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDjtdt4YnreC"
      },
      "source": [
        "!cat /content/drive/MyDrive/Logs/Stage1/pbt/F/train_Stage1_0711f_00001_1_n_fmaps=16_2021-08-08_18-54-16/error.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btkO_vqvN5Yi"
      },
      "source": [
        "## Stage 2\n",
        "Here we tune hyperparameters as we train our modified DCGAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0efCKmqQkp3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "outputId": "75b3871a-3815-4f63-a701-2fabff882ae9"
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_Stage2(config, checkpoint_dir=None, num_epochs=10, num_gpus=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    kwargs = {\n",
        "        'limit_train_batches' : 0.05,\n",
        "        'limit_val_batches' : 0.05,\n",
        "        'progress_bar_refresh_rate' : math.ceil(8250//config['batch_size']),\n",
        "        'max_epochs' : num_epochs,\n",
        "        'prepare_data_per_node' : False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        'gpus' : math.ceil(num_gpus),\n",
        "        'logger' : TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        'callbacks' : [\n",
        "            TuneReportCheckpointCallback(\n",
        "                {\n",
        "                    'loss_G': 'Stage2/G/train/loss', \n",
        "                    'loss_D': 'Stage2/D/train/loss', \n",
        "                    # Switch up the auroc vlues when training on different dataset -----------------------------------------------\n",
        "                    'auroc': 'Stage2/ResNet(F)/val/auroc', \n",
        "                    'auroc_cross': 'Stage2/ResNet(J)/val/auroc',\n",
        "                },\n",
        "            ),\n",
        "        ],\n",
        "        # 'stochastic_weight_avg' : True,\n",
        "        # works with only one optimizer\n",
        "        # 'benchmark' : True,\n",
        "    }\n",
        "    \n",
        "    dm = npyImageData(config)                                              # Specify image width here    \n",
        "    if checkpoint_dir is not None:\n",
        "        kwargs['resume_from_checkpoint'] = os.path.join(checkpoint_dir, 'checkpoint')\n",
        "        # model = Stage2.load_from_checkpoint(kwargs['resume_from_checkpoint'], config=config)\n",
        "    # else:\n",
        "        # model = Stage2(config)\n",
        "    model = Stage2(config)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "\n",
        "# # # __tune_asha_begin__\n",
        "# def tune_Stage2_asha(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "#     # print(os.cpu_count(), torch.cuda.device_count())\n",
        "#     analysis = tune.run(\n",
        "#         tune.with_parameters(\n",
        "#             train_Stage2,\n",
        "#             num_epochs=num_epochs,\n",
        "#             num_gpus=gpus_per_trial\n",
        "#         ),\n",
        "#         # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "#         name='Stage2/pbt/J',\n",
        "#         metric='auroc',\n",
        "#         mode='max',\n",
        "#         config={'learning_rate': 1e-4,\n",
        "#                 'n_fmaps': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "#                 'batch_size': 8,\n",
        "#                 },\n",
        "#         # config={'learning_rate': 0.01,\n",
        "#         #         'n_fmaps': 32,\n",
        "#         #         'batch_size': 32,\n",
        "#         #         },\n",
        "#         # stop=TrialPlateauStopper('loss_G'),\n",
        "#         resources_per_trial={'cpu': os.cpu_count(),\n",
        "#                              'gpu': gpus_per_trial,\n",
        "#                             },\n",
        "#         local_dir='./drive/MyDrive/Logs',\n",
        "#         scheduler = ASHAScheduler(max_t=num_epochs, grace_period=2,  reduction_factor=2),\n",
        "#         progress_reporter=JupyterNotebookReporter(\n",
        "#             overwrite=True,\n",
        "#             parameter_columns=['learning_rate', 'n_fmaps', 'batch_size'],\n",
        "#             metric_columns=['loss_G', 'loss_D', 'auroc', 'auroc_cross', 'training_iteration'],\n",
        "#             sort_by_metric=True,\n",
        "#         ),\n",
        "#         fail_fast = True,\n",
        "#         # reuse_actors=True,\n",
        "#         # num_samples=num_samples,\n",
        "#         resume='PROMPT',\n",
        "# #         restore='/content/drive/MyDrive/Logs/delete/train_Stage2_e42ac_00025_25_batch_size=8,learning_rate=0.01,n_fmaps=8_2021-07-28_21-16-18/checkpoint_epoch=4-step=2339',\n",
        "#     )\n",
        "\n",
        "# #     print('Best hyperparameters found were: ', analysis.best_config)\n",
        "\n",
        "# # # __tune_asha_end__\n",
        "\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_Stage2_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_Stage2,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial\n",
        "        ),\n",
        "        # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "        name='Stage2/pbt/F',\n",
        "        metric='auroc',\n",
        "        mode='max',\n",
        "        config={'learning_rate': 1e-4,\n",
        "                'n_fmaps': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "                'res_depth': tune.choice([1, 2, 3, 4]),\n",
        "                'batch_size': 8,\n",
        "                },\n",
        "        # config={'learning_rate': 0.01,\n",
        "        #         'n_fmaps': 32,\n",
        "        #         'batch_size': 32,\n",
        "        #         },\n",
        "        # stop=TrialPlateauStopper('loss_G'),\n",
        "        resources_per_trial={'cpu': os.cpu_count(),\n",
        "                             'gpu': gpus_per_trial,\n",
        "                            },\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        scheduler = PopulationBasedTraining(time_attr='training_iteration',\n",
        "                                            quantile_fraction=0.5,\n",
        "                                            resample_probability=0.8,\n",
        "                                            perturbation_interval=1,\n",
        "                                            hyperparam_mutations={\n",
        "                                                'learning_rate': tune.loguniform(1e-7, 1e-1),\n",
        "                                                'batch_size': [8, 16, 32, 64, 128],\n",
        "                                            },\n",
        "                                            ),\n",
        "        progress_reporter=JupyterNotebookReporter(\n",
        "            overwrite=False,\n",
        "            parameter_columns=['learning_rate', 'n_fmaps', 'res_depth', 'batch_size'],\n",
        "            metric_columns=['loss_G', 'loss_D', 'auroc', 'auroc_cross', 'training_iteration'],\n",
        "            sort_by_metric=True,\n",
        "        ),\n",
        "        fail_fast = True,\n",
        "        # reuse_actors=True,\n",
        "        # num_samples=num_samples,\n",
        "        resume='PROMPT',\n",
        "    )\n",
        "\n",
        "    print('Best hyperparameters found were: ', analysis.best_config)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_Stage2_asha(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "        tune_Stage2_pbt(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # ASHA scheduler\n",
        "        # tune_Stage2_asha(num_samples=1, num_epochs=10, gpus_per_trial=torch.cuda.device_count())\n",
        "        # Population based training\n",
        "        tune_Stage2_pbt(num_samples=1, num_epochs=30, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resume from local directory? (/content/drive/MyDrive/Logs/Stage2/pbt/F) [y/N]: y\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-19 20:23:46,918\tWARNING trial_runner.py:455 -- Attempting to resume experiment from /content/drive/MyDrive/Logs/Stage2/pbt/F. This will ignore any new changes to the specification.\n",
            "2021-08-19 20:23:46,953\tINFO tune.py:473 -- TrialRunner resumed, ignoring new add_experiment.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.74 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /content/drive/MyDrive/Logs/Stage2/pbt/F<br>Number of trials: 5/5 (1 ERROR, 4 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name              </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  res_depth</th><th style=\"text-align: right;\">  batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_Stage2_f85f5_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_Stage2_f85f5_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_Stage2_f85f5_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_Stage2_f85f5_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">           8</td></tr>\n",
              "<tr><td>train_Stage2_f85f5_00000</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">           8</td></tr>\n",
              "</tbody>\n",
              "</table><br>Number of errored trials: 1<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name              </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                             </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_Stage2_f85f5_00000</td><td style=\"text-align: right;\">           1</td><td>/content/drive/MyDrive/Logs/Stage2/pbt/F/train_Stage2_f85f5_00000_0_n_fmaps=8,res_depth=4_2021-08-19_20-21-01/error.txt</td></tr>\n",
              "</tbody>\n",
              "</table><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TuneError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6e70a5ca6ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# tune_Stage2_asha(num_samples=1, num_epochs=10, gpus_per_trial=torch.cuda.device_count())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Population based training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mtune_Stage2_pbt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-6e70a5ca6ee8>\u001b[0m in \u001b[0;36mtune_Stage2_pbt\u001b[0;34m(num_samples, num_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# reuse_actors=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# num_samples=num_samples,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PROMPT'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_Stage2_f85f5_00000])"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9QBsNzAL7u8"
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSyTgd-d1MPG"
      },
      "source": [
        "!cat /content/drive/MyDrive/Logs/Stage2/pbt/F/train_Stage2_6f508_00000_0_n_fmaps=8_2021-08-13_14-04-54/error.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfPgHHMdNOzQ"
      },
      "source": [
        "## StackGAN:\n",
        "Here we tune hyperparameters for generating images that resemble the images from input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdR_s_6zGtp4"
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_StackGAN_tune_checkpoint(config,\n",
        "                                   checkpoint_dir=None,\n",
        "                                   num_epochs=10,\n",
        "                                   num_gpus=torch.cuda.device_count()):\n",
        "    data_dir = os.path.expanduser('/content/images/')\n",
        "    trainer = pl.Trainer(\n",
        "        # accumulate_grad_batches=2,\n",
        "        # limit_train_batches=0.20,\n",
        "        # limit_val_batches=0.20,\n",
        "        num_sanity_val_steps=-1,\n",
        "        max_epochs=num_epochs,\n",
        "        prepare_data_per_node = False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        gpus=math.ceil(num_gpus),\n",
        "        # tpu_cores = 8,\n",
        "        logger=TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        # progress_bar_refresh_rate=1,\n",
        "        callbacks=[\n",
        "            TuneReportCheckpointCallback(\n",
        "                metrics={\n",
        "                    'loss_G1': 'G1/train/loss/full',\n",
        "                    'loss_G2': 'G2/train/loss/full',\n",
        "                    'loss_D1': 'D1/train/loss',\n",
        "                    'loss_D2': 'D2/train/loss',\n",
        "                    'lossR': 'R/train/loss',\n",
        "                    'auroc': 'Pre/val/auroc',\n",
        "                },\n",
        "                filename='checkpoint',\n",
        "                # on='training_end'\n",
        "            )\n",
        "        ],\n",
        "        # stochastic_weight_avg=True,\n",
        "        # works with only one optimizer\n",
        "        )\n",
        "    dm = npyImageData(config, data_dir)\n",
        "    if checkpoint_dir:\n",
        "        # Currently, this leads to errors:\n",
        "        # model = StackGAN.load_from_checkpoint(\n",
        "        #     os.path.join(checkpoint, 'checkpoint'))\n",
        "        # Workaround:\n",
        "        ckpt = pl_load(\n",
        "            os.path.join(checkpoint_dir, 'checkpoint'),\n",
        "            map_location=lambda storage, loc: storage)\n",
        "        model = StackGAN._load_model_state(\n",
        "            ckpt, config=config, \n",
        "            # data_dir=data_dir\n",
        "            )\n",
        "        trainer.current_epoch = ckpt['epoch']\n",
        "    else:\n",
        "        model = StackGAN(config)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "\n",
        "# __tune_asha_begin__\n",
        "def tune_StackGAN_asha(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    config = {\n",
        "        'learning_rate': tune.choice([1e-4]),\n",
        "        'feature_maps': tune.choice([64]),\n",
        "        'batch_size': tune.choice([128, 64]),\n",
        "    }\n",
        "\n",
        "    scheduler = ASHAScheduler(\n",
        "        max_t=num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "\n",
        "    reporter = CLIReporter(\n",
        "        # overwrite=True,\n",
        "        parameter_columns=['learning_rate', 'feature_maps', 'batch_size'],\n",
        "        metric_columns=['loss_G1', 'loss_G2', 'loss_D1', 'loss_D2', 'lossR', 'auroc', 'training_iteration'],\n",
        "        )\n",
        "\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_StackGAN_tune_checkpoint,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial),\n",
        "        name='tune_StackGAN_asha_model_j',\n",
        "        metric='auroc',\n",
        "        mode='max',\n",
        "        config=config,\n",
        "        resources_per_trial={\n",
        "            'cpu': os.cpu_count(),\n",
        "            'gpu': gpus_per_trial,\n",
        "            # 'tpu': 8,\n",
        "        },\n",
        "        num_samples=num_samples,\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter,\n",
        "        # restore='/content/drive/MyDrive/Logs/tune_StackGAN_1_asha_model_j/train_StackGAN_tune_checkpoint_fa25b_00000_0_batch_size=64,feature_maps=64,learning_rate=0.0001_2021-07-06_20-23-13/checkpoint_epoch=0-step=937',\n",
        "        fail_fast = True,\n",
        "        resume='PROMPT',\n",
        "        )\n",
        "\n",
        "    print('Best hyperparameters found were: ', analysis.best_config)\n",
        "\n",
        "# __tune_asha_end__\n",
        "\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_StackGAN_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    config = {\n",
        "        'learning_rate': 1e-4,\n",
        "        'feature_maps': 64,\n",
        "        'batch_size': 64,\n",
        "    }\n",
        "\n",
        "    scheduler = PopulationBasedTraining(\n",
        "        perturbation_interval=4,\n",
        "        hyperparam_mutations={\n",
        "            'learning_rate': [1e-4, 1e-3],\n",
        "            'feature_maps': [64, 128],\n",
        "            'batch_size': [32, 64, 128]\n",
        "        })\n",
        "\n",
        "    reporter = CLIReporter(\n",
        "        # overwrite=True,\n",
        "        parameter_columns=['learning_rate', 'feature_maps', 'batch_size'],\n",
        "        metric_columns=['loss_G1', 'loss_G2', 'loss_D1', 'loss_D2', 'lossR', 'auroc', 'training_iteration'],\n",
        "        )\n",
        "\n",
        "    analysis = tune.run(\n",
        "        # resume=True,\n",
        "        tune.with_parameters(\n",
        "            train_StackGAN_tune_checkpoint,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial),\n",
        "        name='tune_StackGAN_pbt_model_j',\n",
        "        metric='auroc',\n",
        "        mode='max',\n",
        "        resources_per_trial={\n",
        "            'cpu': os.cpu_count(),\n",
        "            'gpu': gpus_per_trial,\n",
        "            # 'tpu': 8,\n",
        "        },\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter,\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        # restore='/content/drive/MyDrive/Logs/tune_StackGAN_1_asha_model_j/train_StackGAN_tune_checkpoint_fa25b_00000_0_batch_size=64,feature_maps=64,learning_rate=0.0001_2021-07-06_20-23-13/checkpoint_epoch=0-step=937',\n",
        "        fail_fast = True,\n",
        "        # resume='PROMPT',\n",
        "        )\n",
        "\n",
        "    print('Best hyperparameters found were: ', analysis.best_config)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_StackGAN_asha(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "        tune_StackGAN_pbt(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # ASHA scheduler\n",
        "        tune_StackGAN_asha(num_samples=2, num_epochs=1, gpus_per_trial=torch.cuda.device_count())\n",
        "        # Population based training\n",
        "        # tune_StackGAN_pbt(num_samples=8, num_epochs=5, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}