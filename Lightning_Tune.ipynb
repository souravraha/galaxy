{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lightning_Tune.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WK9GeW6miiXr",
        "ASOiXXn-36Wf",
        "FbXpnU7Y4Cr9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravraha/galaxy/blob/pbt2/Lightning_Tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDsadYRa5Rh5"
      },
      "source": [
        "# Mount Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF5oJHq0_WxS"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', timeout_ms=600000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDzU0Yty6Qsw"
      },
      "source": [
        "# Prerequisites/ shell commands"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI_RfiMRk5j_"
      },
      "source": [
        "## Install/uninstall packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMwknUIDcTW1"
      },
      "source": [
        "# If you are running on Google Colab, uncomment below to install the necessary dependencies \n",
        "# before beginning the exercise.\n",
        "\n",
        "print('Setting up colab environment')\n",
        "# !pip uninstall -y -q pyarrow\n",
        "!pip install -q lightning-bolts GPy\n",
        "!pip install -q ray[debug] ray[default]\n",
        "!pip install -U -q ray[tune] matplotlib==3.4.3\n",
        "# !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "# A hack to force the runtime to restart, needed to include the above dependencies.\n",
        "print('Done installing! Restarting via forced crash (this is not an issue).')\n",
        "import os\n",
        "os._exit(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK9GeW6miiXr"
      },
      "source": [
        "## Download and extract data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdfevhA2fGYr"
      },
      "source": [
        "Here choose the model you wish to use for training/testing. Don't forget to make modifications in the following sections:\n",
        "\n",
        "1.   GLOBAL in class definition of npyImageData.\n",
        "2.   correct assignment of metric keys while defining the training wrapper for Tune.\n",
        "3.   name of the experiment initiated/resumed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZUIrgOfbwPe"
      },
      "source": [
        "# 'a': 1Cjcw2EWorhdhJSGoWOdxsEUDxvl943dt, 'b': 15yXXC4h5VsytP3Ak1jfUSjQhdgP2s23K, 'c': 1vuQ-pLzoKT4Hd_V7949r9eND9E2fB_u_,\n",
        "# 'd': , 'e': 1wFuasvb7PthxXtMUlsD13uzYHWlWt06H, 'f': 17l6H61tLAu26zGuei38r_T5ssjbYUeaJ, \n",
        "# 'g': 1SxQVosWeEjY3Pyn8LRXA11rLnZ9HK_7B, 'h': 1Atau0RH4oyLAiYReW-G9a8l9pUNltglF, 'i': 15lEgsR1p00KSHieaT9a1nkbJ86pDxwgp, \n",
        "# 'j': 1m0EQUbqZZeyl76XsQIKWU5Qd7jGmmWhB, 'k': , 'l': 1meTDi4aeWfdChOiXeLtUOGhjVDVu000e\n",
        "\n",
        "# fake data\n",
        "# 'fpgan': 1-4o0yqSBA9WSY9gTYamIez_RAekwDsHV\n",
        "\n",
        "!rm -rf images/\n",
        "!gdown --id 17l6H61tLAu26zGuei38r_T5ssjbYUeaJ -O - --quiet | tar --skip-old-files -zxf -\n",
        "# !rm ./model_f.tgz\n",
        "\n",
        "# def prepare_data(data_dir: str = '/content'):\n",
        "#     with FileLock(os.path.expanduser(data_dir+'.lock')):\n",
        "#         gdown.download('https://drive.google.com/uc?id=17l6H61tLAu26zGuei38r_T5ssjbYUeaJ', data_dir+'/model_j.tgz', quiet=True)\n",
        "        \n",
        "#         temp = tarfile.open(data_dir+'/model_j.tgz', 'r|gz')\n",
        "#         temp.extractall()\n",
        "#         temp.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxQTZTEy5GWe"
      },
      "source": [
        "# Line wrapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXMwcAw45FsR"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "    display(HTML('''<style>pre{white-space: pre-wrap;}</style>'''))\n",
        "    \n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB3f7W9_kazP"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR6G_K6bWVqd",
        "outputId": "2d1cea59-c10c-4290-e079-3de25fac000d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "# from pathlib import Path\n",
        "from itertools import cycle\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "# ------------------------------------\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "# ------------------------------------\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torchvision import transforms, datasets\n",
        "# ------------------------------------\n",
        "from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay\n",
        "# ------------------------------------\n",
        "import torchmetrics as tm\n",
        "# ------------------------------------\n",
        "import pytorch_lightning as pl\n",
        "from pl_bolts.models.gans import DCGAN\n",
        "from pl_bolts.callbacks import ModuleDataMonitor\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pl_bolts.models.self_supervised.resnets import BasicBlock\n",
        "# from pytorch_lightning.utilities.cloud_io import load as pl_load\n",
        "from drive.MyDrive.ml.Callbacks.confused_logits import ConfusedLogitCallback\n",
        "from drive.MyDrive.ml.Callbacks.save_images import SaveImages\n",
        "# ------------------------------------\n",
        "from ray import tune\n",
        "# from ray.tune.stopper import TrialPlateauStopper\n",
        "from ray.tune import CLIReporter, JupyterNotebookReporter\n",
        "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
        "from ray.tune.schedulers.pb2 import PB2\n",
        "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
        "# ------------------------------------"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre{white-space: pre-wrap;}</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hczXOvdE54S"
      },
      "source": [
        "# Class definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snbv_zoNiWfW"
      },
      "source": [
        "## DataModule\n",
        "This creates dataloaders which need to be supplied to train, validate or test the module we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yItuGxXmXzGr",
        "outputId": "4f28a5a5-d9ef-4933-ec35-430f3f388525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "class npyImageData(pl.LightningDataModule):\n",
        "    def __init__(self, config, img_width: int = 150, data_dir: str = '/content/images/'):\n",
        "        super().__init__()\n",
        "        # This method is not implemented\n",
        "        # self.save_hyperparameters()\n",
        "        self.bs = int(2**np.rint(config['bs']))\n",
        "        self.data_dir = os.path.expanduser(data_dir)\n",
        "        \n",
        "        # Change the source file containing mean and stdv when changing dataset ------------------------------------------------------\n",
        "        self.transform = transforms.Compose([\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            # transforms.RandomVerticalFlip(),\n",
        "            # F : [mean=71.75926373866668, std=96.139484964214, min=5.0, max=966.0]\n",
        "            # J : [mean=50.271541595458984, std=94.8838882446289, min=0, max=1007.0]\n",
        "            transforms.Normalize(mean=(0,), std=(966,)),\n",
        "            transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "            # this shift-scales the pixel values -> [-1, 1]\n",
        "            transforms.Resize(img_width, transforms.InterpolationMode.NEAREST),\n",
        "        ])\n",
        "\n",
        "    @staticmethod\n",
        "    def npy_loader(path):\n",
        "        # s=np.load(path).astype('float',copy=False)\n",
        "        return torch.from_numpy(np.load(path)).unsqueeze(0).float()\n",
        "        # Convert to tenssor first, and then to float, otherwise final dtype \n",
        "        # would be float64, which would raise errors in conv layers      ###### type as\n",
        "\n",
        "    def setup(self, stage: str = None):\n",
        "        if stage in ('fit', None):\n",
        "            self.train_set = datasets.DatasetFolder(os.path.join(self.data_dir,'train'), \n",
        "                self.npy_loader, ('.npy'), self.transform,)\n",
        "            # self.train_set, self.val_set = random_split(self.full_set, [60000, 15000])            \n",
        "            self.val_set = datasets.DatasetFolder(os.path.join(self.data_dir,'val'),  \n",
        "                self.npy_loader, ('.npy'), self.transform,)\n",
        "            self.dims = tuple(self.train_set[0][0].shape)\n",
        "\n",
        "        if stage in ('test', None):\n",
        "            self.test_set = datasets.DatasetFolder(os.path.join(self.data_dir,'val'),  \n",
        "                self.npy_loader, ('.npy'), self.transform,)\n",
        "            self.dims = getattr(self, 'dims', self.test_set[0][0].shape)\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_set, self.bs, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_set, self.bs, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_set, self.bs, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre{white-space: pre-wrap;}</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C3gKSFKKDaY"
      },
      "source": [
        "dm = npyImageData({'lr': 0.001, 'bs': 8})\n",
        "# model = LensResnet.load_from_checkpoint(os.path.join(BEST_F_RESNET, 'checkpoint'), config={'lr': 0.001, 'bs': 8})\n",
        "# trainer = pl.Trainer(gpus=1)\n",
        "# trainer.predict(model, dm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0bm1afc11hN"
      },
      "source": [
        "## ResNet\n",
        "We modify a ResNet slightly for our purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojZ0yT4z168p",
        "outputId": "8202668f-5508-4ba4-fa1c-0a3154fff007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "PRE_F_RESNET = '/content/drive/MyDrive/Logs/F/LensResnet/PRETRAINED.pth'\n",
        "PRE_J_RESNET = '/content/drive/MyDrive/Logs/J/LensResnet/PRETRAINED.pth'\n",
        "\n",
        "class LensResnet(pl.LightningModule):\n",
        "    def __init__(self, config, image_channels: int = 1, num_classes: int = 3, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "        self.lr = 10**config['lr']\n",
        "\n",
        "        # --------------------------------------------------------------------------------------------------\n",
        "        self.backbone = torch.load(PRE_F_RESNET, map_location=self.device)\n",
        "        # self.backbone = resnet18(num_classes=self.hparams.num_classes)\n",
        "        # self.backbone.conv1 = nn.LazyConv2d(64, 7, 2, 3, bias=False)\n",
        "        \n",
        "        self.train_metrics = tm.MetricCollection([tm.AUROC(self.hparams.num_classes, average='weighted'),],\n",
        "            prefix='LensResnet/train/'\n",
        "        )\n",
        "        self.val_metrics = tm.MetricCollection(\n",
        "            [tm.PrecisionRecallCurve(self.hparams.num_classes), tm.ROC(self.hparams.num_classes),\n",
        "            tm.AveragePrecision(self.hparams.num_classes), tm.AUROC(self.hparams.num_classes, average=None)]\n",
        "        )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.backbone.parameters(), self.lr)\n",
        "\n",
        "    def forward(self, x, prob=False):\n",
        "        logits = self.backbone(x)\n",
        "        return logits.softmax(1) if prob else logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        self.last_logits = self(imgs)\n",
        "        loss = F.cross_entropy(self.last_logits, labels)\n",
        "        self.log('LensResnet/train/loss', loss)\n",
        "        #  keep only scalars here, for no errors\n",
        "        \n",
        "        preds = self.last_logits.softmax(1)\n",
        "        self.train_metrics.update(preds, labels)\n",
        "        try:\n",
        "            self.log_dict(self.train_metrics.compute(), prog_bar=True)\n",
        "        except Exception as f:\n",
        "            print(f)\n",
        "        finally:            \n",
        "            # self.train_metrics.reset()\n",
        "            # self.log_dict automatically resets at the end of epoch\n",
        "            return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        logits = self(imgs)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        self.log('LensResnet/val/loss', loss)\n",
        "        #  keep only scalars here, for no errors\n",
        "        \n",
        "        preds = logits.softmax(1)\n",
        "        self.val_metrics.update(preds, labels)\n",
        "\n",
        "    def validation_epoch_end(self, Listofdicts):\n",
        "        colors = cycle(['r', 'g', 'b'])\n",
        "        fig, ax = plt.subplots(1,2, subplot_kw={'xlim': [-0.05, 1.05], 'ylim': [-0.05, 1.05], 'aspect': 1}, figsize=(10, 5))\n",
        "        # ---------------------------------------------------------------------------------------------------------\n",
        "        fig.suptitle('One vs. all PR & ROC curves for different types of substructures in model J (orginal data)')\n",
        "        \n",
        "        Dict = self.val_metrics.compute()\n",
        "        self.val_metrics.reset()\n",
        "        \n",
        "        key, val = list(Dict.keys()), list(Dict.values())\n",
        "        for b in range(2):\n",
        "            if key[b] != 'ROC':\n",
        "                ax[b].plot([0, 1], [1/self.hparams.num_classes, 1/self.hparams.num_classes], 'k--')\n",
        "            else:\n",
        "                ax[b].plot([0, 1], [0, 1], 'k--')\n",
        "            \n",
        "            prec_FPR, rec_TPR, _ = val[b]\n",
        "            for i, color, cls in zip(range(self.hparams.num_classes), colors, self.trainer.datamodule.val_set.classes):\n",
        "                if key[b] != 'ROC':\n",
        "                    PrecisionRecallDisplay(prec_FPR[i].cpu(), rec_TPR[i].cpu(), val[2 + b][i], cls).plot(ax[b], c=color)\n",
        "                else:\n",
        "                    RocCurveDisplay(prec_FPR[i].cpu(), rec_TPR[i].cpu(), val[2 + b][i], cls).plot(ax[b], c=color)\n",
        "                \n",
        "            ax[b].legend(loc='best')\n",
        "            self.log('LensResnet/val/' + key[2 + b], min(val[2 + b]))\n",
        "\n",
        "        self.logger.experiment.add_figure('LensResnet/val/PR_ROC', fig)\n",
        "        fig.savefig(str(self.trainer.log_dir) + '/PR_ROC_step_{:05d}.png'.format(self.global_step))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre{white-space: pre-wrap;}</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRVE-YyyWNUj"
      },
      "source": [
        "m = LensResnet({'lr': 1e-3})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc0oRARcKBv3"
      },
      "source": [
        "## LensGAN128\n",
        "Here we subclass a DCGAN to create our low resolution GAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kclAeom914wK",
        "outputId": "8aa1b95c-93d4-4b97-9ede-f1c42aa98b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "BEST_F_RESNET = '/content/drive/MyDrive/Logs/F/LensResnet/pbt_tanh/train_LensResnet_eb619_00000_0_2021-09-02_19-42-34/checkpoint_epoch=2-step=28124'\n",
        "BEST_J_RESNET = '/content/drive/MyDrive/Logs/J/LensResnet/pbt_tanh_fine/train_LensResnet_93609_00000_0_2021-09-02_21-06-00/checkpoint_epoch=2-step=28124'\n",
        "\n",
        "class LensGAN128(DCGAN):\n",
        "    def __init__(self, config, num_classes: int = 3, **kwargs):\n",
        "        super().__init__(feature_maps_gen=config['n_fmaps'], feature_maps_disc=config['n_fmaps'], \n",
        "                         learning_rate=10**config['lr'], **kwargs)\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "\n",
        "        # Batch-norm needs depends upon out channels of the previous layer\n",
        "        first = self.generator._make_gen_block(1, self.hparams.feature_maps_gen * 16)\n",
        "        # Accepts inputs of any channels\n",
        "        first[0] = nn.LazyConvTranspose2d(self.hparams.feature_maps_gen * 16, kernel_size=4, stride=1, padding=0)\n",
        "        # Turn this into the second layer\n",
        "        self.generator.gen[0] = self.generator._make_gen_block(self.hparams.feature_maps_gen * 16, self.hparams.feature_maps_gen * 8)\n",
        "        self.generator.gen = nn.Sequential(first, *list(self.generator.gen))\n",
        "        \n",
        "        # Turn this into the penultimate layer\n",
        "        self.discriminator.disc[-1] = self.discriminator._make_disc_block(self.hparams.feature_maps_disc * 8, self.hparams.feature_maps_disc * 16)\n",
        "        # self.discriminator.disc = nn.Sequential(*list(self.discriminator.disc), nn.LazyConv2d(1, kernel_size=4, stride=1, padding=0, bias=False))\n",
        "        # # Necessary if using ACGAN, else could be appended to disc module\n",
        "        self.discriminator.add_module('critic', nn.LazyConv2d(1, kernel_size=4, stride=1, padding=0, bias=False))\n",
        "        # # Remove if ACGAN not needed \n",
        "        self.discriminator.add_module('aux', nn.Sequential(nn.Flatten(), nn.LazyLinear(self.hparams.num_classes)))\n",
        "        self.discriminator.forward = self.discriminator_forward\n",
        "\n",
        "        for i in range(5):\n",
        "            # Necessary for implementing gradient penalty, else remove\n",
        "            # if i != 0:\n",
        "                # self.discriminator.disc[i][1] = nn.LayerNorm([self.discriminator.disc[i][0].out_channels, 2 ** (6 - i), 2 ** (6 - i)])\n",
        "            # Remove if LeakyRelu not needed in generator\n",
        "            self.generator.gen[i][-1] = self.discriminator.disc[i][-1]\n",
        "            # Implement dropouts\n",
        "            # self.generator.gen[i] = nn.Sequential(*list(self.generator.gen[i]), nn.Dropout())\n",
        "            # self.discriminator.disc[i] = nn.Sequential(*list(self.discriminator.disc[i]), nn.Dropout())\n",
        "\n",
        "        # Not needed in WGAN architectures\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        temp = LensResnet.load_from_checkpoint(os.path.join(BEST_F_RESNET, 'checkpoint'))\n",
        "        temp.freeze()\n",
        "        self.modelF = temp.backbone     # torch.load(PRE_F_RESNET, map_location=self.device).eval())\n",
        "        # Proper way to copy the last layer\n",
        "        self.lastF = self.modelF.fc\n",
        "        self.modelF.fc = nn.Identity()\n",
        "        \n",
        "        temp = LensResnet.load_from_checkpoint(os.path.join(BEST_J_RESNET, 'checkpoint'))\n",
        "        temp.freeze()\n",
        "        self.modelJ = temp.backbone     # torch.load(PRE_J_RESNET, map_location=self.device).eval())\n",
        "        # Proper way to copy the last layer\n",
        "        self.lastJ = self.modelJ.fc\n",
        "        self.modelJ.fc = nn.Identity()\n",
        "\n",
        "        self.imgMetrics = tm.MetricCollection(\n",
        "            {\n",
        "                'FID_F' : tm.FID(self.modelF),\n",
        "                'FID_J' : tm.FID(self.modelJ),\n",
        "            },\n",
        "            prefix='LensGAN128/val/',\n",
        "        )\n",
        "\n",
        "        metrics = tm.MetricCollection(\n",
        "            [tm.PrecisionRecallCurve(self.hparams.num_classes), tm.ROC(self.hparams.num_classes),\n",
        "            tm.AveragePrecision(self.hparams.num_classes), tm.AUROC(self.hparams.num_classes, average=None)],\n",
        "        )\n",
        "        self.FMetrics = metrics.clone()\n",
        "        self.JMetrics = metrics.clone()\n",
        "    \n",
        "    def discriminator_forward(self, x):\n",
        "        # Add noise to the data\n",
        "        inp = x + torch.randn_like(x) * np.exp(-self.global_step * len(x) / 7500)\n",
        "        # # Not needed if not using ACGAN\n",
        "        out5 = self.discriminator.disc(inp)\n",
        "        return self.discriminator.critic(out5).squeeze(), self.discriminator.aux(out5)\n",
        "        # return self.discriminator.disc(inp).squeeze()\n",
        "\n",
        "    def forward(self, noise, labels, all_layers=False):\n",
        "        inp = torch.cat((F.one_hot(labels, self.hparams.num_classes), noise), 1)\n",
        "        if all_layers:\n",
        "            out = [inp.view(*inp.shape, 1, 1)]\n",
        "            for layer in self.generator.gen:\n",
        "                out.append(layer(out[-1]))\n",
        "            return out[1:]\n",
        "        else:\n",
        "            return super().forward(inp)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        real, self.labels = batch\n",
        "        fake = self._get_fake_data(self.labels).type_as(real)\n",
        "\n",
        "        # Train discriminator\n",
        "        result = None\n",
        "        if optimizer_idx == 0:\n",
        "            result = self._disc_step(real, fake.detach())\n",
        "\n",
        "        # Train generator\n",
        "        if optimizer_idx == 1:\n",
        "            result = self._gen_step(fake)\n",
        "\n",
        "        del self.labels\n",
        "        return result\n",
        "\n",
        "    def _disc_step(self, real, fake):\n",
        "        # # Not needed if using gradient penalty\n",
        "        # for p in self.discriminator.parameters():\n",
        "        #     p.data.clamp_(-0.01, 0.01)\n",
        "        disc_loss = self._get_disc_loss(real, fake)\n",
        "        self.log('LensGAN128/D/train/loss', disc_loss)\n",
        "        return disc_loss\n",
        "\n",
        "    def _gen_step(self, fake):\n",
        "        gen_loss = self._get_gen_loss(fake)\n",
        "        self.log('LensGAN128/G/train/loss', gen_loss)\n",
        "        return gen_loss\n",
        "\n",
        "    def _get_disc_loss(self, real, fake):\n",
        "        # Train with real\n",
        "        # realCritic_pred = self.discriminator(real)\n",
        "        realCritic_pred, realAux_pred = self.discriminator(real)\n",
        "        # real_loss = -realCritic_pred.mean()\n",
        "        real_gt = torch.ones_like(realCritic_pred)\n",
        "        real_loss = self.criterion(realCritic_pred, real_gt)\n",
        "        self.log('LensGAN128/D/train/loss/real', real_loss)\n",
        "\n",
        "        # Train with fake\n",
        "        # fakeCritic_pred = self.discriminator(fake)\n",
        "        fakeCritic_pred, fakeAux_pred = self.discriminator(fake)\n",
        "        # fake_loss = fakeCritic_pred.mean()\n",
        "        fake_gt = torch.zeros_like(fakeCritic_pred)\n",
        "        fake_loss = self.criterion(fakeCritic_pred, fake_gt)\n",
        "        self.log('LensGAN128/D/train/loss/fake', fake_loss)\n",
        "\n",
        "        # # Classifier loss\n",
        "        class_loss = nn.CrossEntropyLoss()(realAux_pred, self.labels) \n",
        "        # + nn.CrossEntropyLoss()(fakeAux_pred, self.labels)\n",
        "        self.log('LensGAN128/D/train/loss/class', class_loss)\n",
        "\n",
        "        # # Compute gradient penalty\n",
        "        # gp = 10 * self._gradient_penalty(real, fake)\n",
        "        # self.log('LensGAN128/D/train/loss/gp', gp)\n",
        "\n",
        "        # Modi\n",
        "        return real_loss + fake_loss + class_loss \n",
        "        # + gp \n",
        "\n",
        "    def _get_gen_loss(self, fake):\n",
        "        # Train with fake\n",
        "        # fakeCritic_pred = self.discriminator(fake)\n",
        "        fakeCritic_pred, fakeAux_pred = self.discriminator(fake)\n",
        "        # fake_loss = -fakeCritic_pred.mean()\n",
        "        fake_gt = torch.ones_like(fakeCritic_pred)\n",
        "        fake_loss = self.criterion(fakeCritic_pred, fake_gt)\n",
        "        self.log('LensGAN128/G/train/loss/fake', fake_loss)\n",
        "\n",
        "        # Classifier loss\n",
        "        class_loss = nn.CrossEntropyLoss()(fakeAux_pred, self.labels)\n",
        "        self.log('LensGAN128/G/train/loss/class', class_loss)\n",
        "\n",
        "        return fake_loss + class_loss\n",
        "\n",
        "    def _get_fake_data(self, labels, **kwargs):\n",
        "        batch_size = len(labels)\n",
        "        noise = self._get_noise(batch_size, self.hparams.latent_dim)\n",
        "        fake = self(noise, labels, **kwargs)\n",
        "\n",
        "        return fake\n",
        "\n",
        "    # def _gradient_penalty(self, real, fake):\n",
        "    #     \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
        "    #     # Random weight term for interpolation between real and fake samples\n",
        "    #     alpha = torch.rand(len(real), 1, 1, 1)\n",
        "    #     # Get random interpolation between real and fake samples\n",
        "    #     mix = torch.lerp(real, fake, alpha.type_as(real)).requires_grad_(True)\n",
        "    #     # # Remove the underscore if not using ACGAN\n",
        "    #     d_mix ,_ = self.discriminator(mix)\n",
        "    #     # Get gradient w.r.t. mix\n",
        "    #     gradients = torch.autograd.grad(\n",
        "    #         outputs=d_mix,\n",
        "    #         inputs=mix,\n",
        "    #         grad_outputs=torch.ones_like(d_mix),\n",
        "    #         create_graph=True,\n",
        "    #         retain_graph=True,\n",
        "    #         only_inputs=True,\n",
        "    #     )[0]\n",
        "    #     gradients = gradients.view(len(mix), -1)\n",
        "    #     gp = ((gradients.norm(2, dim=1) - 1) ** 2)\n",
        "    #     return gp.mean()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # print(self.global_step, batch_idx, len(self.imgMetrics.FID_J.fake_features))\n",
        "        imgs128, labels = batch\n",
        "        self.imgMetrics.update(F.interpolate(imgs128, 150), real=True)\n",
        "        fake = F.interpolate(self._get_fake_data(labels), 150).type_as(imgs128)\n",
        "        self.imgMetrics.update(fake, real=False)\n",
        "        \n",
        "        if self.global_step == 0:\n",
        "            self.FMetrics.update(self.lastF(self.modelF(F.interpolate(imgs128, 150))).softmax(1), labels)\n",
        "            self.JMetrics.update(self.lastJ(self.modelJ(F.interpolate(imgs128, 150))).softmax(1), labels)\n",
        "        else:\n",
        "            self.FMetrics.update(self.lastF(self.modelF(fake)).softmax(1), labels)\n",
        "            self.JMetrics.update(self.lastJ(self.modelJ(fake)).softmax(1), labels)\n",
        "\n",
        "    def validation_epoch_end(self, ListofDicts):\n",
        "        # Classification scores\n",
        "        fid = self.imgMetrics.compute()\n",
        "        # self.log_dict(fid) isn't compatible with val_check_interval      \n",
        "        self.log_dict(self.imgMetrics)\n",
        "        \n",
        "        fig = plt.figure(constrained_layout=True, figsize=(10, 9))\n",
        "        # -----------------------------------------------------------------------------------------------------\n",
        "        if self.global_step == 0:\n",
        "            fig.suptitle('One vs. all PR & ROC curves for different types of substructures in model F (original data)')\n",
        "        else:\n",
        "            fig.suptitle('One vs. all PR & ROC curves for different types of substructures in model F (generated data)')\n",
        "        subfigs = fig.subfigures(2, 1)\n",
        "        colors = cycle(['r', 'g', 'b'])\n",
        "        \n",
        "        for a, src in enumerate(['F', 'J']):\n",
        "            if self.global_step == 0:\n",
        "                subfigs[a].suptitle('Classifier : model ' + src)\n",
        "            else:\n",
        "                subfigs[a].suptitle('Classifier : model ' + src + ', FID : {:0.2f}'.format(fid['LensGAN128/val/FID_'+ src]))\n",
        "            ax = subfigs[a].subplots(1,2, subplot_kw={'xlim': [-0.05,1.05], 'ylim': [-0.05,1.05], 'aspect': 1})\n",
        "            \n",
        "            temp = getattr(self, src + 'Metrics')\n",
        "            Dict = temp.compute()\n",
        "            temp.reset()\n",
        "\n",
        "            key, val = list(Dict.keys()), list(Dict.values())\n",
        "            for b in range(2):\n",
        "                if key[b] != 'ROC':\n",
        "                    ax[b].plot([0, 1], [1/self.hparams.num_classes, 1/self.hparams.num_classes], 'k--')\n",
        "                else:\n",
        "                    ax[b].plot([0, 1], [0, 1], 'k--')\n",
        "                \n",
        "                prec_FPR, rec_TPR, _ = val[b]\n",
        "                for i, color, cls in zip(range(self.hparams.num_classes), colors, self.trainer.datamodule.val_set.classes):\n",
        "                    if key[b] != 'ROC':\n",
        "                        PrecisionRecallDisplay(prec_FPR[i].cpu(), rec_TPR[i].cpu(), val[2 + b][i], cls).plot(ax[b], c=color)\n",
        "                    else:\n",
        "                        RocCurveDisplay(prec_FPR[i].cpu(), rec_TPR[i].cpu(), val[2 + b][i], cls).plot(ax[b], c=color)\n",
        "                    \n",
        "                ax[b].legend(loc='best')\n",
        "                self.log('LensGAN128/LensResnet(' + src + ')/val/' + key[2 + b], sum(val[2 + b])/len(val[2 + b]))\n",
        "\n",
        "        self.logger.experiment.add_figure('LensGAN128/LensResnet/val/PR_ROC', fig)\n",
        "        fig.savefig(str(self.trainer.log_dir) + '/PR_ROC_step_{:05d}.png'.format(self.global_step))\n",
        "\n",
        "        # Save layer-wise activations\n",
        "        labels = torch.arange(self.hparams.num_classes, device=self.device)\n",
        "        imgs = self._get_fake_data(labels, all_layers=True)\n",
        "        for lyr, img4d in enumerate(imgs[:-1]):\n",
        "            new = list(img4d)\n",
        "            for cls, filters3d in enumerate(new):\n",
        "                new[cls] = make_grid(filters3d.unsqueeze(1), nrow=int(np.ceil(np.sqrt(len(filters3d)))), normalize=True)\n",
        "                # print(three3d.shape)\n",
        "                # new[cls] = three3d[0].unsqueeze(0)\n",
        "                # print(new[cls].shape)\n",
        "\n",
        "            imgs[lyr] = F.interpolate(torch.stack(new), 150)\n",
        "            # print(imgs[lyr].shape)\n",
        "\n",
        "        save_image(torch.cat(imgs[-2::-1]), \n",
        "                str(self.trainer.log_dir) + '/F_maps_step_{:05d}.png'.format(self.global_step), \n",
        "                #  kwargs for make_grid\n",
        "                nrow=self.hparams.num_classes, pad_value=0.5)\n",
        "        \n",
        "        imgs = imgs[-1]\n",
        "        while len(labels) > 0:\n",
        "            x, y = self.trainer.datamodule.val_set[np.random.randint(0, len(self.trainer.datamodule.val_set))]\n",
        "            if y == labels[0]:\n",
        "                imgs = torch.cat((imgs, x.unsqueeze(0).type_as(imgs)))\n",
        "                labels = labels[1:]\n",
        "\n",
        "        save_image(F.interpolate(imgs, 150), \n",
        "                str(self.trainer.log_dir) + '/Fake_step_{:05d}.png'.format(self.global_step), \n",
        "                #  kwargs for make_grid\n",
        "                nrow=self.hparams.num_classes, normalize=True, value_range=(-1,1), pad_value=0.5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre{white-space: pre-wrap;}</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9biIaX6MJuO"
      },
      "source": [
        "m = LensGAN128({'lr':0.001, 'n_fmaps': 128, 'bs': 8})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u1b8lr2puNw"
      },
      "source": [
        "## Stage 2\n",
        "Here we subclass a DCGAN to create our high resolution GAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMwzBib_zulo"
      },
      "source": [
        "class Generator2(nn.Module):\n",
        "    def __init__(self, ngf: int = 128, image_channels: int = 1, res_depth: int = 6):\n",
        "        super().__init__()\n",
        "\n",
        "        ker, strd = 4, 2\n",
        "        pad = int((ker - 2)/2)\n",
        "        res_ker, res_strd, res_pad = 3, 1, 1\n",
        "        \n",
        "        # 64 -> 32\n",
        "        self.preprocessing = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, ngf, ker, strd, pad, bias=False),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        # residuals\n",
        "        layer = []\n",
        "        for _ in range(res_depth):\n",
        "            layer.append(BasicBlock(ngf, ngf))\n",
        "        self.residual = nn.Sequential(*layer)\n",
        "        \n",
        "        self.ending_residual = nn.Sequential(\n",
        "            nn.Conv2d(ngf, ngf, res_ker, res_strd, res_pad, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        # at this part, add the residual inputs from after the preprocessing\n",
        "\n",
        "        image_width = 150 # upscaling should be factor of 2 increase\n",
        "        mode = 'nearest' # upscaling method is nearest-neighbour\n",
        "        self.main = nn.Sequential(\n",
        "            # 32 -> 75\n",
        "            nn.Upsample(image_width//2, mode=mode),\n",
        "            nn.Conv2d(ngf, ngf*4, res_ker, res_strd, res_pad, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(True),\n",
        "            # 75 -> 150\n",
        "            nn.Upsample(image_width, mode=mode),\n",
        "            nn.Conv2d(ngf*4, image_channels, res_ker, res_strd, res_pad, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, in_x):\n",
        "        x_p = self.preprocessing(in_x)\n",
        "        x_r = x_p\n",
        "        x_r = self.residual(x_r)\n",
        "        x_r = self.ending_residual(x_r)\n",
        "        # large residual connections\n",
        "        x_f = x_r + x_p\n",
        "        return self.main(x_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snK9DNDARgi7"
      },
      "source": [
        "BEST_F_LensGAN128 = '/content/drive/MyDrive/Logs/F/LensGAN128/pbt_tanh_1/train_LensGAN128_90727_00001_1_n_fmaps=16_2021-08-30_08-02-05/checkpoint_epoch=4-step=1988/'\n",
        "BEST_J_LensGAN128 ='/content/drive/MyDrive/Logs/J/LensGAN128/pbt_tanh/train_LensGAN128_28c03_00003_3_n_fmaps=64_2021-08-31_20-45-44/checkpoint_epoch=2-step=1403/'\n",
        "\n",
        "class Stage2(DCGAN):\n",
        "    def __init__(self, config, num_classes: int = 3, **kwargs):\n",
        "        super().__init__(feature_maps_gen=config['n_fmaps'], feature_maps_disc=config['n_fmaps'], learning_rate=config['learning_rate'])\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "\n",
        "        self.generator = Generator2(self.hparams.feature_maps_gen, self.hparams.image_channels, config['res_depth'])\n",
        "\n",
        "        # These are better as attributes, instead of being returned by a method\n",
        "        self.modelF = getattr(self, 'modelF', LensResnet.load_from_checkpoint(os.path.join(BEST_RESNET_F, 'checkpoint')).eval())\n",
        "        self.modelJ = getattr(self, 'modelJ', LensResnet.load_from_checkpoint(os.path.join(BEST_RESNET_J, 'checkpoint')).eval())\n",
        "        # Workaround:\n",
        "        self.lowres = getattr(self, 'lowres', LensGAN128.load_from_checkpoint(os.path.join(BEST_LensGAN128_F, 'checkpoint')).eval())\n",
        "        \n",
        "        metrics = tm.MetricCollection(\n",
        "            [\n",
        "             tm.AUROC(num_classes=self.hparams.num_classes, compute_on_step=False, average=None), \n",
        "             tm.ROC(num_classes=self.hparams.num_classes, compute_on_step=False),\n",
        "            ]\n",
        "        )\n",
        "        self.metricsF = metrics.clone()\n",
        "        self.metricsJ = metrics.clone()\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.generator(noise)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        real, self.labels = batch\n",
        "\n",
        "        # Train discriminator\n",
        "        result = None\n",
        "        if optimizer_idx == 0:\n",
        "            result = self._disc_step(real)\n",
        "\n",
        "        # Train generator\n",
        "        if optimizer_idx == 1:\n",
        "            result = self._gen_step(real)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _disc_step(self, real):\n",
        "        disc_loss = self._get_disc_loss(real)\n",
        "        self.log('Stage2/D/train/loss', disc_loss, on_epoch=True)\n",
        "        return disc_loss\n",
        "\n",
        "    def _gen_step(self, real):\n",
        "        gen_loss = self._get_gen_loss(real)\n",
        "        self.log('Stage2/G/train/loss', gen_loss, on_epoch=True)\n",
        "        return gen_loss\n",
        "\n",
        "    def _get_gen_loss(self, real: torch.Tensor) -> torch.Tensor:\n",
        "        # Train with fake\n",
        "        fake_pred = self._get_fake_pred(real)\n",
        "        fake_gt = torch.ones_like(fake_pred)\n",
        "        gen_loss = self.criterion(fake_pred, fake_gt)\n",
        "\n",
        "        # class_pred =  self._get_class_pred(len(real))\n",
        "        # gen_loss += F.cross_entropy(class_pred, self.labels)\n",
        "\n",
        "        return gen_loss\n",
        "\n",
        "    def _get_class_pred(self, batch_size) -> torch.Tensor:\n",
        "        # ----------------------------------------------------------------------------------------------------------------\n",
        "        return self.modelF.backbone(self(self._get_noise(batch_size, self.hparams.latent_dim)))\n",
        "\n",
        "    def _get_noise(self, n_samples: int, latent_dim: int, labels = None):\n",
        "        # can't use self in function definition\n",
        "        if labels is None:\n",
        "            labels = self.labels\n",
        "            # getattr(self, 'labels', torch.randint(self.hparams.num_classes, (n_samples,), device=self.device))  # last dimension is the hidden dimension\n",
        "        return self.lowres(super()._get_noise(n_samples, latent_dim), labels)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        out = self(self._get_noise(labels.shape[0], self.hparams.latent_dim, labels))\n",
        "        self.metricsF.update(self.modelF(out), labels)\n",
        "        self.metricsJ.update(self.modelJ(out), labels)\n",
        "        # out = Fig.interpolate(out_64, 150)\n",
        "\n",
        "    def validation_epoch_end(self, listofDicts):\n",
        "        fig, ax = plt.subplots(1,2, \n",
        "            subplot_kw={'xlim': [0,1], 'xlabel': 'False Positive Rate', 'ylim': [0,1.05], \n",
        "                        'ylabel': 'True Positive Rate',\n",
        "            },\n",
        "            figsize=[11, 5],\n",
        "        )\n",
        "        for j, letter in enumerate(['F', 'J']):\n",
        "            output = getattr(self, 'metrics' + letter).compute()\n",
        "            self.log('Stage2/ResNet(' + letter + ')/val/auroc', output['AUROC'].min())\n",
        "            fprList, tprList, _ = output['ROC']\n",
        "            \n",
        "            colors = cycle(['red', 'blue', 'green'])\n",
        "            for i, color in zip(range(self.hparams.num_classes), colors):\n",
        "                ax[j].plot(fprList[i].cpu(), tprList[i].cpu(), color=color,\n",
        "                        label='ROC curve of class {0} (area = {1:0.4f})'\n",
        "                        ''.format(i, output['AUROC'][i]))\n",
        "            post_plotting(ax[j])\n",
        "            ax[j].set_title('One vs. all ROC curve (' + letter + ')')\n",
        "        \n",
        "        fig.tight_layout()\n",
        "        self.logger.experiment.add_figure('Stage2/ResNet/val/ROC', fig)\n",
        "        fig.savefig(str(self.trainer.log_dir) + '/ROC_step_{:05d}.png'.format(self.global_step))\n",
        "\n",
        "        labels = torch.arange(self.hparams.num_classes, device=self.device)\n",
        "        save_image(self(self._get_noise(labels.shape[0], self.hparams.latent_dim, labels)), \n",
        "                   str(self.trainer.log_dir) + '/Fake_step_{:05d}.png'.format(self.global_step), \n",
        "                  #  kwargs for make_grid\n",
        "                   normalize=True, value_range=(-1,1))\n",
        "\n",
        "    def on_fit_end(self):\n",
        "        delattr(self, 'modelF')\n",
        "        delattr(self, 'modelJ')\n",
        "        delattr(self, 'labels')\n",
        "        delattr(self, 'lowres')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0XraYESGws1"
      },
      "source": [
        "# Tune Hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbXpnU7Y4Cr9"
      },
      "source": [
        "## ResNet\n",
        "Here we tune hyperparameters as we train our modified ResNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otF0QlxlGsZs"
      },
      "source": [
        "%rm -rf /content/drive/MyDrive/Logs/fakeF/PGAN/LensResnet/pbt_tanh_validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOMd0E5Q9mkw"
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_LensResnet(config, checkpoint_dir=None, num_epochs=10, num_gpus=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    kwargs = {\n",
        "        # 'limit_train_batches' : 0.005,\n",
        "        # 'limit_val_batches' : 0.005,\n",
        "        'progress_bar_refresh_rate' : int(8250//int(2**np.rint(config['bs']))),\n",
        "        'max_epochs' : num_epochs,\n",
        "        'prepare_data_per_node' : False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        'gpus' : int(num_gpus),\n",
        "        'logger' : TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        'callbacks' : [\n",
        "            TuneReportCheckpointCallback(\n",
        "                {\n",
        "                    'loss': 'LensResnet/val/loss', \n",
        "                    'auroc': 'LensResnet/val/AUROC', \n",
        "                    'ap' : 'LensResnet/val/AveragePrecision',\n",
        "                },\n",
        "            ),\n",
        "            ModuleDataMonitor(['backbone.layer2', 'backbone.layer4', 'backbone.fc']),\n",
        "            ConfusedLogitCallback(5),\n",
        "        ],\n",
        "        'stochastic_weight_avg' : True,\n",
        "        # works with only one optimizer\n",
        "        'benchmark' : True,\n",
        "        'precision' : 16,     # can't use on cpu\n",
        "        # 'track_grad_norm': 2,\n",
        "        # 'gradient_clip_val' : 0.5, \n",
        "        # 'gradient_clip_algorithm' : 'value',\n",
        "    }\n",
        "    \n",
        "    dm = npyImageData(config)                                              # Specify image width here    \n",
        "    if checkpoint_dir is not None:\n",
        "        kwargs['resume_from_checkpoint'] = os.path.join(checkpoint_dir, 'checkpoint')\n",
        "        # model = LensResnet.load_from_checkpoint(kwargs['resume_from_checkpoint'], config=config)\n",
        "    # else:\n",
        "\n",
        "    model = LensResnet(config)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_LensResnet_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_LensResnet,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial\n",
        "        ),\n",
        "        # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "        name='J/LensResnet/pbt_tanh_fine',\n",
        "        metric='loss',\n",
        "        mode='min',\n",
        "        # stop=TrialPlateauStopper('auroc'),\n",
        "        resources_per_trial={'cpu': os.cpu_count(), 'gpu': gpus_per_trial},\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        # config={'lr': tune.choice([1e-4, 1e-3, 1e-5, 1e-2, 1e-6, 1e-1, 1e-7]),\n",
        "        #         'bs': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "        #         },\n",
        "        # scheduler = pbtScheduler(max_t=num_epochs, grace_period=2, reduction_factor=2),\n",
        "        # Can't use RB2 as it requires mutations to be continuous\n",
        "        config={'lr': 1e-5,\n",
        "                'bs': 8,\n",
        "                # RuntimeError: stack expects each tensor to be equal size, but got [128] at entry 0 and [120] at entry 585\n",
        "                },\n",
        "        scheduler = PopulationBasedTraining(time_attr='training_iteration', quantile_fraction=0.4,\n",
        "                                            resample_probability=0.2,  perturbation_interval=1,\n",
        "                                            hyperparam_mutations={\n",
        "                                                'lr': tune.loguniform(1e-6, 1e-4),\n",
        "                                                'bs': [8, 16, 32, 64, 128],\n",
        "                                            },\n",
        "        ),\n",
        "        progress_reporter=JupyterNotebookReporter(\n",
        "            overwrite=False,\n",
        "            parameter_columns=['lr', 'bs'],\n",
        "            metric_columns=['loss', 'auroc', 'ap', 'training_iteration'],\n",
        "        ),\n",
        "        fail_fast = True,\n",
        "        # reuse_actors=True,\n",
        "        num_samples=num_samples,\n",
        "        # resume='PROMPT',\n",
        "    )\n",
        "    BEST_J_RESNET = analysis.best_checkpoint\n",
        "    print('Best checkpoint path found is: ', BEST_J_RESNET)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_LensResnet_pbt(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # pbt scheduler\n",
        "        tune_LensResnet_pbt(num_samples=1, num_epochs=5, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPxU2-AggCrI"
      },
      "source": [
        "## LensGAN128\n",
        "Here we tune hyperparameters as we train our modified DCGAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr0jbpHhgs79",
        "outputId": "7115e990-6364-40ff-a3f4-23d49ce67ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%rm -rf drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre{white-space: pre-wrap;}</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz_mb3SxcDnF",
        "outputId": "c95790e4-381a-412c-de8c-f3d8a805a462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_LensGAN128(config, checkpoint_dir=None, num_steps=10000, num_gpus=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    kwargs = {\n",
        "        # 'limit_train_batches' : 0.05,\n",
        "        # 'limit_val_batches' : 0.05,\n",
        "        'progress_bar_refresh_rate' : int(7500//int(2**np.rint(config['bs']))),\n",
        "        'val_check_interval' : 0.10,\n",
        "        'max_steps' : num_steps,\n",
        "        'prepare_data_per_node' : False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        'gpus' : int(num_gpus),\n",
        "        'logger' : TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        'callbacks' : [\n",
        "            TuneReportCheckpointCallback(\n",
        "                {\n",
        "                    'loss_G': 'LensGAN128/G/train/loss', \n",
        "                    'loss_D': 'LensGAN128/D/train/loss', \n",
        "                    # Switch up the FID vlues when training on different dataset -----------------------------------------------\n",
        "                    'FID': 'LensGAN128/val/FID_F', \n",
        "                    'FID_cross': 'LensGAN128/val/FID_J',\n",
        "                    'auroc': 'LensGAN128/LensResnet(F)/val/AUROC',\n",
        "                    'auroc_cross': 'LensGAN128/LensResnet(J)/val/AUROC',\n",
        "                    'ap': 'LensGAN128/LensResnet(F)/val/AveragePrecision',\n",
        "                    'ap_cross': 'LensGAN128/LensResnet(J)/val/AveragePrecision'\n",
        "                },\n",
        "                # Validation end is better, resumes with updated checkpoint\n",
        "                # on='train_end',\n",
        "            ),\n",
        "            ModuleDataMonitor(True),\n",
        "        ],\n",
        "        # 'stochastic_weight_avg' : True,\n",
        "        # works with only one optimizer\n",
        "        'benchmark' : True,\n",
        "        'precision' : 16,\n",
        "    }\n",
        "    \n",
        "    dm = npyImageData(config, 128)                                              # Specify image width here    \n",
        "    if checkpoint_dir is not None:\n",
        "        kwargs['resume_from_checkpoint'] = os.path.join(checkpoint_dir, 'checkpoint')\n",
        "\n",
        "    model = LensGAN128(config)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_LensGAN128_pbt(num_samples=10, num_steps=10000, gpus_per_trial=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_LensGAN128,\n",
        "            num_steps=num_steps,\n",
        "            num_gpus=gpus_per_trial\n",
        "        ),\n",
        "        # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "        name='F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2', \n",
        "        metric='auroc',\n",
        "        mode='max',\n",
        "        # stop=TrialPlateauStopper('FID'),\n",
        "        resources_per_trial={'cpu': os.cpu_count(), 'gpu': gpus_per_trial},\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        config={'lr': -3,\n",
        "                'n_fmaps': tune.grid_search([8, 16, 32, 64]),\n",
        "                'bs': 3,\n",
        "                },\n",
        "        # config = {'lr': 2.340983544823817e-05, 'n_fmaps': 32, 'bs': 8},\n",
        "        scheduler = PB2('training_iteration', quantile_fraction=0.25, perturbation_interval=2,\n",
        "                            # resample_probability=0.25,  \n",
        "                            hyperparam_bounds={\n",
        "                                'lr': [-6, -3],  #tune.loguniform(1e-5, 1e-3),\n",
        "                                'bs': [3, 7],    #[8, 16, 32, 64, 128],\n",
        "                            },\n",
        "        ),\n",
        "        progress_reporter=JupyterNotebookReporter(\n",
        "            overwrite=False,\n",
        "            parameter_columns=['lr', 'n_fmaps', 'bs'],\n",
        "            metric_columns=['loss_G', 'loss_D', 'FID', 'auroc', 'ap',\n",
        "                            # 'FID_cross', 'auroc_cross', 'ap_cross', \n",
        "                            'training_iteration'],\n",
        "            max_report_frequency=5 * 60,\n",
        "        ),\n",
        "        fail_fast = True,\n",
        "        # reuse_actors=True,\n",
        "        num_samples=num_samples,\n",
        "        # resume='PROMPT',\n",
        "    )\n",
        "    # ---------------------------------------------------------------------------------------------\n",
        "    # Plot by wall-clock time\n",
        "    # dfs = analysis.fetch_trial_dataframes()\n",
        "    # # This plots everything on the same plot\n",
        "    # ax = None\n",
        "    # for d in dfs.values():\n",
        "    #     ax = d.plot('training_iteration', ['loss_G', 'loss_D', 'FID', 'auroc', 'ap'], \n",
        "    #                 ax=ax, subplots=True, legend=False, layout=(2, 3))\n",
        "\n",
        "    #     ax.xlabel('iterations')\n",
        "    #     ax.ylabel('Test Accuracy')\n",
        "\n",
        "    # print('best config:', analysis.get_best_config('auroc'))\n",
        "\n",
        "    print('Best checkpoint path found is: ', analysis.best_checkpoint)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_LensGAN128_pbt(num_samples=1, num_steps=10000, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # pbt scheduler\n",
        "        tune_LensGAN128_pbt(num_samples=1, num_steps=10000, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre{white-space: pre-wrap;}</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-27 22:32:15,970\tINFO services.py:1255 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.4/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   warnings.warn('Lazy modules are a new feature under heavy development '\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `FID` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m Using native 16bit precision.\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m GPU available: True, used: True\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/memory.py:484: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   | Name          | Type               | Params\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 0 | generator     | DCGANGenerator     | 174 K \n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 1 | discriminator | DCGANDiscriminator | 174 K \n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 2 | criterion     | BCEWithLogitsLoss  | 0     \n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 3 | modelF        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 4 | lastF         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 5 | modelJ        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 6 | lastJ         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 7 | imgMetrics    | MetricCollection   | 22.3 M\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 8 | FMetrics      | MetricCollection   | 0     \n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 9 | JMetrics      | MetricCollection   | 0     \n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 349 K     Trainable params\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 22.3 M    Non-trainable params\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 22.7 M    Total params\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 90.772    Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:377: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   f\"Your {mode}_dataloader has `shuffle=True`, it is best practice to turn\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \rValidation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \r                                                              \r\rTraining: -1it [00:00, ?it/s]\rTraining:   0%|          | 0/18755 [00:00<00:01, 14665.40it/s]\rEpoch 0:   0%|          | 0/18755 [00:00<00:07, 2434.30it/s]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \rEpoch 0:   5%|         | 937/18755 [02:06<39:58,  7.43it/s]\rEpoch 0:   5%|         | 937/18755 [02:06<39:58,  7.43it/s, loss=2.36, v_num=.]\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \rValidating:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \n",
            "Epoch 0:  15%|        | 2811/18755 [03:48<21:35, 12.30it/s, loss=2.36, v_num=.]\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \n",
            "Epoch 0:  20%|        | 3748/18755 [03:48<15:16, 16.37it/s, loss=2.36, v_num=.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_LensGAN128_bdf63_00000:\n",
            "  FID: 84.125\n",
            "  FID_cross: 62.875\n",
            "  ap: 0.321110337972641\n",
            "  ap_cross: 0.31725966930389404\n",
            "  auroc: 0.47711431980133057\n",
            "  auroc_cross: 0.4726691246032715\n",
            "  date: 2021-10-27_22-36-30\n",
            "  done: false\n",
            "  experiment_id: 21aaf213df50413ebb97f44bdd47bd47\n",
            "  hostname: 9396f81d6793\n",
            "  iterations_since_restore: 1\n",
            "  loss_D: 2.412370443344116\n",
            "  loss_G: 2.016472816467285\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1734\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 249.931711435318\n",
            "  time_this_iter_s: 249.931711435318\n",
            "  time_total_s: 249.931711435318\n",
            "  timestamp: 1635374190\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: bdf63_00000\n",
            "  \n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \rEpoch 0:  20%|        | 3748/18755 [03:52<15:30, 16.13it/s, loss=2.36, v_num=.]\n",
            "                                                             \u001b[A\n",
            "Epoch 0:  20%|        | 3748/18755 [04:06<16:26, 15.21it/s, loss=2.36, v_num=.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.4/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: bdf63_00000 with auroc=0.47711431980133057 and parameters={'lr': -3, 'n_fmaps': 8, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">   FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">     ap</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>RUNNING </td><td>172.28.0.2:1734</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 2.01647</td><td style=\"text-align: right;\"> 2.41237</td><td style=\"text-align: right;\">84.125</td><td style=\"text-align: right;\">0.477114</td><td style=\"text-align: right;\">0.32111</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \rEpoch 0:  25%|       | 4685/18755 [06:06<18:20, 12.78it/s, loss=2.36, v_num=.]\rEpoch 0:  25%|       | 4685/18755 [06:06<18:20, 12.78it/s, loss=2.13, v_num=.]\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \rValidating:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1734)\u001b[0m \rValidating: 100%|| 937/938 [01:42<00:00,  9.12it/s]\u001b[A\rEpoch 0:  35%|      | 6559/18755 [07:49<14:32, 13.98it/s, loss=2.13, v_num=.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_LensGAN128_bdf63_00000:\n",
            "  FID: 71.625\n",
            "  FID_cross: 74.6875\n",
            "  ap: 0.36591458320617676\n",
            "  ap_cross: 0.37903136014938354\n",
            "  auroc: 0.5362882614135742\n",
            "  auroc_cross: 0.5620301365852356\n",
            "  date: 2021-10-27_22-40-31\n",
            "  done: false\n",
            "  experiment_id: 21aaf213df50413ebb97f44bdd47bd47\n",
            "  hostname: 9396f81d6793\n",
            "  iterations_since_restore: 2\n",
            "  loss_D: 2.340337038040161\n",
            "  loss_G: 1.929384469985962\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1734\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 490.7602655887604\n",
            "  time_this_iter_s: 240.82855415344238\n",
            "  time_total_s: 490.7602655887604\n",
            "  timestamp: 1635374431\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: bdf63_00000\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1734)\u001b[0m 2021-10-27 22:40:32,191\tINFO trainable.py:76 -- Checkpoint size is 96446854 bytes\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   warnings.warn('Lazy modules are a new feature under heavy development '\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `FID` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m Using native 16bit precision.\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m GPU available: True, used: True\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/memory.py:484: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   | Name          | Type               | Params\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 0 | generator     | DCGANGenerator     | 697 K \n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 1 | discriminator | DCGANDiscriminator | 697 K \n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 2 | criterion     | BCEWithLogitsLoss  | 0     \n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 3 | modelF        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 4 | lastF         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 5 | modelJ        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 6 | lastJ         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 7 | imgMetrics    | MetricCollection   | 22.3 M\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 8 | FMetrics      | MetricCollection   | 0     \n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 9 | JMetrics      | MetricCollection   | 0     \n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 1.4 M     Trainable params\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 22.3 M    Non-trainable params\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 23.7 M    Total params\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 94.955    Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:377: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   f\"Your {mode}_dataloader has `shuffle=True`, it is best practice to turn\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation sanity check: 0it [00:00, ?it/s]\n",
            "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1733)\u001b[0m \r                                                              \r\rTraining: -1it [00:00, ?it/s]\rTraining:   0%|          | 0/18755 [00:00<00:01, 11214.72it/s]\rEpoch 0:   0%|          | 0/18755 [00:00<00:08, 2097.15it/s]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: bdf63_00000 with auroc=0.5362882614135742 and parameters={'lr': -3, 'n_fmaps': 8, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (1 PAUSED, 2 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">   FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">      ap</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.92938</td><td style=\"text-align: right;\"> 2.34034</td><td style=\"text-align: right;\">71.625</td><td style=\"text-align: right;\">0.536288</td><td style=\"text-align: right;\">0.365915</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1733)\u001b[0m \rEpoch 0:   5%|         | 937/18755 [02:46<52:40,  5.64it/s]\rEpoch 0:   5%|         | 937/18755 [02:46<52:40,  5.64it/s, loss=2.2, v_num=.]\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1733)\u001b[0m \rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1733)\u001b[0m \rValidating:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1733)\u001b[0m \n",
            "Epoch 0:  15%|        | 2811/18755 [04:29<25:27, 10.44it/s, loss=2.2, v_num=.]\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1733)\u001b[0m \n",
            "Epoch 0:  20%|        | 3748/18755 [04:29<18:00, 13.89it/s, loss=2.2, v_num=.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_LensGAN128_bdf63_00001:\n",
            "  FID: 81.875\n",
            "  FID_cross: 47.5\n",
            "  ap: 0.3736208379268646\n",
            "  ap_cross: 0.39330777525901794\n",
            "  auroc: 0.5460797548294067\n",
            "  auroc_cross: 0.5858370661735535\n",
            "  date: 2021-10-27_22-45-35\n",
            "  done: false\n",
            "  experiment_id: 7ea089312fa647f3ade9e732d22a6a17\n",
            "  hostname: 9396f81d6793\n",
            "  iterations_since_restore: 1\n",
            "  loss_D: 2.0539863109588623\n",
            "  loss_G: 2.560209035873413\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1733\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 292.2613983154297\n",
            "  time_this_iter_s: 292.2613983154297\n",
            "  time_total_s: 292.2613983154297\n",
            "  timestamp: 1635374735\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: bdf63_00001\n",
            "  \n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1733)\u001b[0m \rEpoch 0:  20%|        | 3748/18755 [04:34<18:16, 13.68it/s, loss=2.2, v_num=.]\n",
            "                                                             \u001b[A\n",
            "Epoch 0:  20%|        | 3748/18755 [04:46<19:05, 13.10it/s, loss=2.2, v_num=.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.3/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: bdf63_00001 with auroc=0.5460797548294067 and parameters={'lr': -3, 'n_fmaps': 16, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (1 PAUSED, 2 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">   FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">      ap</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>RUNNING </td><td>172.28.0.2:1733</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 2.56021</td><td style=\"text-align: right;\"> 2.05399</td><td style=\"text-align: right;\">81.875</td><td style=\"text-align: right;\">0.54608 </td><td style=\"text-align: right;\">0.373621</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.92938</td><td style=\"text-align: right;\"> 2.34034</td><td style=\"text-align: right;\">71.625</td><td style=\"text-align: right;\">0.536288</td><td style=\"text-align: right;\">0.365915</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1733)\u001b[0m \rEpoch 0:  25%|       | 4685/18755 [07:32<22:39, 10.35it/s, loss=2.2, v_num=.]\rEpoch 0:  25%|       | 4685/18755 [07:32<22:39, 10.35it/s, loss=2.07, v_num=.]\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1733)\u001b[0m \rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1733)\u001b[0m \rValidating:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1733)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=1733)\u001b[0m \rValidating: 100%|| 937/938 [01:43<00:00,  9.07it/s]\u001b[A\rEpoch 0:  35%|      | 6559/18755 [09:15<17:13, 11.80it/s, loss=2.07, v_num=.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n",
            "2021-10-27 22:50:21,391\tINFO pbt.py:490 -- [pbt]: no checkpoint for trial. Skip exploit for Trial train_LensGAN128_bdf63_00001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_LensGAN128_bdf63_00001:\n",
            "  FID: 73.5\n",
            "  FID_cross: 79.375\n",
            "  ap: 0.33673495054244995\n",
            "  ap_cross: 0.32726797461509705\n",
            "  auroc: 0.50468510389328\n",
            "  auroc_cross: 0.4807695150375366\n",
            "  date: 2021-10-27_22-50-21\n",
            "  done: false\n",
            "  experiment_id: 7ea089312fa647f3ade9e732d22a6a17\n",
            "  hostname: 9396f81d6793\n",
            "  iterations_since_restore: 2\n",
            "  loss_D: 3.0946192741394043\n",
            "  loss_G: 1.6753308773040771\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1733\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 578.5164506435394\n",
            "  time_this_iter_s: 286.25505232810974\n",
            "  time_total_s: 578.5164506435394\n",
            "  timestamp: 1635375021\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: bdf63_00001\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 2021-10-27 22:50:21,863\tINFO trainable.py:76 -- Checkpoint size is 111630790 bytes\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   warnings.warn('Lazy modules are a new feature under heavy development '\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `FID` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m Using native 16bit precision.\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m GPU available: True, used: True\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/memory.py:484: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   | Name          | Type               | Params\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 0 | generator     | DCGANGenerator     | 2.8 M \n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 1 | discriminator | DCGANDiscriminator | 2.8 M \n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 2 | criterion     | BCEWithLogitsLoss  | 0     \n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 3 | modelF        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 4 | lastF         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 5 | modelJ        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 6 | lastJ         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 7 | imgMetrics    | MetricCollection   | 22.3 M\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 8 | FMetrics      | MetricCollection   | 0     \n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 9 | JMetrics      | MetricCollection   | 0     \n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 5.6 M     Trainable params\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 22.3 M    Non-trainable params\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 27.9 M    Total params\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 111.676   Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:377: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   f\"Your {mode}_dataloader has `shuffle=True`, it is best practice to turn\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \rValidation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \r                                                              \r\rTraining: -1it [00:00, ?it/s]\rTraining:   0%|          | 0/18755 [00:00<00:01, 11554.56it/s]\rEpoch 0:   0%|          | 0/18755 [00:00<00:10, 1746.90it/s]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.2/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: bdf63_00000 with auroc=0.5362882614135742 and parameters={'lr': -3, 'n_fmaps': 8, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (2 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">   FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">      ap</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.92938</td><td style=\"text-align: right;\"> 2.34034</td><td style=\"text-align: right;\">71.625</td><td style=\"text-align: right;\">0.536288</td><td style=\"text-align: right;\">0.365915</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.67533</td><td style=\"text-align: right;\"> 3.09462</td><td style=\"text-align: right;\">73.5  </td><td style=\"text-align: right;\">0.504685</td><td style=\"text-align: right;\">0.336735</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \rEpoch 0:   5%|         | 937/18755 [04:06<1:18:03,  3.80it/s]\rEpoch 0:   5%|         | 937/18755 [04:06<1:18:03,  3.80it/s, loss=2.36, v_num=.]\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \rValidating:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \n",
            "Epoch 0:  15%|        | 2811/18755 [05:50<33:08,  8.02it/s, loss=2.36, v_num=.] \n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \n",
            "Epoch 0:  20%|        | 3748/18755 [05:51<23:25, 10.67it/s, loss=2.36, v_num=.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_LensGAN128_bdf63_00002:\n",
            "  FID: 71.625\n",
            "  FID_cross: 52.125\n",
            "  ap: 0.3034307360649109\n",
            "  ap_cross: 0.2859871983528137\n",
            "  auroc: 0.4587584435939789\n",
            "  auroc_cross: 0.41751348972320557\n",
            "  date: 2021-10-27_22-56-48\n",
            "  done: false\n",
            "  experiment_id: 1d49674708844e52b575466fc987c792\n",
            "  hostname: 9396f81d6793\n",
            "  iterations_since_restore: 1\n",
            "  loss_D: 2.46213698387146\n",
            "  loss_G: 1.836939811706543\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2082\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 374.1809239387512\n",
            "  time_this_iter_s: 374.1809239387512\n",
            "  time_total_s: 374.1809239387512\n",
            "  timestamp: 1635375408\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: bdf63_00002\n",
            "  \n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \rEpoch 0:  20%|        | 3748/18755 [05:55<23:43, 10.54it/s, loss=2.36, v_num=.]\n",
            "                                                             \u001b[A\n",
            "Epoch 0:  20%|        | 3748/18755 [06:05<24:24, 10.25it/s, loss=2.36, v_num=.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.2/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: bdf63_00000 with auroc=0.5362882614135742 and parameters={'lr': -3, 'n_fmaps': 8, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (2 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">   FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">      ap</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>RUNNING </td><td>172.28.0.2:2082</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.83694</td><td style=\"text-align: right;\"> 2.46214</td><td style=\"text-align: right;\">71.625</td><td style=\"text-align: right;\">0.458758</td><td style=\"text-align: right;\">0.303431</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.92938</td><td style=\"text-align: right;\"> 2.34034</td><td style=\"text-align: right;\">71.625</td><td style=\"text-align: right;\">0.536288</td><td style=\"text-align: right;\">0.365915</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.67533</td><td style=\"text-align: right;\"> 3.09462</td><td style=\"text-align: right;\">73.5  </td><td style=\"text-align: right;\">0.504685</td><td style=\"text-align: right;\">0.336735</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \rEpoch 0:  25%|       | 4685/18755 [10:17<30:54,  7.59it/s, loss=2.36, v_num=.]\rEpoch 0:  25%|       | 4685/18755 [10:17<30:54,  7.59it/s, loss=2.24, v_num=.]\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \rValidating:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 5.0/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: bdf63_00000 with auroc=0.5362882614135742 and parameters={'lr': -3, 'n_fmaps': 8, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (2 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">   FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">      ap</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>RUNNING </td><td>172.28.0.2:2082</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.83694</td><td style=\"text-align: right;\"> 2.46214</td><td style=\"text-align: right;\">71.625</td><td style=\"text-align: right;\">0.458758</td><td style=\"text-align: right;\">0.303431</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.92938</td><td style=\"text-align: right;\"> 2.34034</td><td style=\"text-align: right;\">71.625</td><td style=\"text-align: right;\">0.536288</td><td style=\"text-align: right;\">0.365915</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.67533</td><td style=\"text-align: right;\"> 3.09462</td><td style=\"text-align: right;\">73.5  </td><td style=\"text-align: right;\">0.504685</td><td style=\"text-align: right;\">0.336735</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2082)\u001b[0m \rValidating: 100%|| 937/938 [01:44<00:00,  8.93it/s]\u001b[A\rEpoch 0:  35%|      | 6559/18755 [12:02<22:23,  9.08it/s, loss=2.24, v_num=.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n",
            "2021-10-27 23:03:00,293\tINFO pbt.py:490 -- [pbt]: no checkpoint for trial. Skip exploit for Trial train_LensGAN128_bdf63_00002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_LensGAN128_bdf63_00002:\n",
            "  FID: 51.59375\n",
            "  FID_cross: 59.0\n",
            "  ap: 0.324062705039978\n",
            "  ap_cross: 0.33693385124206543\n",
            "  auroc: 0.4889622628688812\n",
            "  auroc_cross: 0.5065863728523254\n",
            "  date: 2021-10-27_23-03-00\n",
            "  done: false\n",
            "  experiment_id: 1d49674708844e52b575466fc987c792\n",
            "  hostname: 9396f81d6793\n",
            "  iterations_since_restore: 2\n",
            "  loss_D: 2.7707881927490234\n",
            "  loss_G: 1.9379024505615234\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2082\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 745.5555803775787\n",
            "  time_this_iter_s: 371.3746564388275\n",
            "  time_total_s: 745.5555803775787\n",
            "  timestamp: 1635375780\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: bdf63_00002\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2082)\u001b[0m 2021-10-27 23:03:00,909\tINFO trainable.py:76 -- Checkpoint size is 167065606 bytes\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   warnings.warn('Lazy modules are a new feature under heavy development '\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `FID` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m Using native 16bit precision.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m GPU available: True, used: True\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/memory.py:484: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   | Name          | Type               | Params\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 0 | generator     | DCGANGenerator     | 11.1 M\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 1 | discriminator | DCGANDiscriminator | 11.1 M\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 2 | criterion     | BCEWithLogitsLoss  | 0     \n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 3 | modelF        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 4 | lastF         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 5 | modelJ        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 6 | lastJ         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 7 | imgMetrics    | MetricCollection   | 22.3 M\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 8 | FMetrics      | MetricCollection   | 0     \n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 9 | JMetrics      | MetricCollection   | 0     \n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 22.3 M    Trainable params\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 22.3 M    Non-trainable params\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 44.6 M    Total params\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 178.543   Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:377: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   f\"Your {mode}_dataloader has `shuffle=True`, it is best practice to turn\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \rValidation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \r                                                              \r\rTraining: -1it [00:00, ?it/s]\rTraining:   0%|          | 0/18755 [00:00<00:01, 15768.06it/s]\rEpoch 0:   0%|          | 0/18755 [00:00<00:05, 3495.25it/s]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.3/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: bdf63_00000 with auroc=0.5362882614135742 and parameters={'lr': -3, 'n_fmaps': 8, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (2 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">    FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">      ap</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.67533</td><td style=\"text-align: right;\"> 3.09462</td><td style=\"text-align: right;\">73.5   </td><td style=\"text-align: right;\">0.504685</td><td style=\"text-align: right;\">0.336735</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.9379 </td><td style=\"text-align: right;\"> 2.77079</td><td style=\"text-align: right;\">51.5938</td><td style=\"text-align: right;\">0.488962</td><td style=\"text-align: right;\">0.324063</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.92938</td><td style=\"text-align: right;\"> 2.34034</td><td style=\"text-align: right;\">71.625 </td><td style=\"text-align: right;\">0.536288</td><td style=\"text-align: right;\">0.365915</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \rEpoch 0:   5%|         | 937/18755 [08:07<2:34:12,  1.93it/s]\rEpoch 0:   5%|         | 937/18755 [08:07<2:34:12,  1.93it/s, loss=2.47, v_num=.]\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \rValidating:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.5/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: bdf63_00000 with auroc=0.5362882614135742 and parameters={'lr': -3, 'n_fmaps': 8, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (2 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">    FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">      ap</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.67533</td><td style=\"text-align: right;\"> 3.09462</td><td style=\"text-align: right;\">73.5   </td><td style=\"text-align: right;\">0.504685</td><td style=\"text-align: right;\">0.336735</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.9379 </td><td style=\"text-align: right;\"> 2.77079</td><td style=\"text-align: right;\">51.5938</td><td style=\"text-align: right;\">0.488962</td><td style=\"text-align: right;\">0.324063</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.92938</td><td style=\"text-align: right;\"> 2.34034</td><td style=\"text-align: right;\">71.625 </td><td style=\"text-align: right;\">0.536288</td><td style=\"text-align: right;\">0.365915</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \n",
            "Epoch 0:  15%|        | 2811/18755 [10:05<57:11,  4.65it/s, loss=2.47, v_num=.] \n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \n",
            "Epoch 0:  20%|        | 3748/18755 [10:05<40:24,  6.19it/s, loss=2.47, v_num=.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_LensGAN128_bdf63_00003:\n",
            "  FID: 81.875\n",
            "  FID_cross: 54.34375\n",
            "  ap: 0.32921653985977173\n",
            "  ap_cross: 0.3888176381587982\n",
            "  auroc: 0.4919528067111969\n",
            "  auroc_cross: 0.5538091063499451\n",
            "  date: 2021-10-27_23-13-46\n",
            "  done: false\n",
            "  experiment_id: 2c72ef395fc74d8497319b44496f0c6f\n",
            "  hostname: 9396f81d6793\n",
            "  iterations_since_restore: 1\n",
            "  loss_D: 4.145644187927246\n",
            "  loss_G: 2.999300718307495\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2216\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 631.1108260154724\n",
            "  time_this_iter_s: 631.1108260154724\n",
            "  time_total_s: 631.1108260154724\n",
            "  timestamp: 1635376426\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: bdf63_00003\n",
            "  \n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \rEpoch 0:  20%|        | 3748/18755 [10:12<40:51,  6.12it/s, loss=2.47, v_num=.]\n",
            "                                                             \u001b[A\n",
            "Epoch 0:  20%|        | 3748/18755 [10:25<41:43,  5.99it/s, loss=2.47, v_num=.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 5.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: bdf63_00000 with auroc=0.5362882614135742 and parameters={'lr': -3, 'n_fmaps': 8, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (2 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">    FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">      ap</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>RUNNING </td><td>172.28.0.2:2216</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 2.9993 </td><td style=\"text-align: right;\"> 4.14564</td><td style=\"text-align: right;\">81.875 </td><td style=\"text-align: right;\">0.491953</td><td style=\"text-align: right;\">0.329217</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.67533</td><td style=\"text-align: right;\"> 3.09462</td><td style=\"text-align: right;\">73.5   </td><td style=\"text-align: right;\">0.504685</td><td style=\"text-align: right;\">0.336735</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.9379 </td><td style=\"text-align: right;\"> 2.77079</td><td style=\"text-align: right;\">51.5938</td><td style=\"text-align: right;\">0.488962</td><td style=\"text-align: right;\">0.324063</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.92938</td><td style=\"text-align: right;\"> 2.34034</td><td style=\"text-align: right;\">71.625 </td><td style=\"text-align: right;\">0.536288</td><td style=\"text-align: right;\">0.365915</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 5.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: bdf63_00000 with auroc=0.5362882614135742 and parameters={'lr': -3, 'n_fmaps': 8, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (2 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">    FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">      ap</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>RUNNING </td><td>172.28.0.2:2216</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 2.9993 </td><td style=\"text-align: right;\"> 4.14564</td><td style=\"text-align: right;\">81.875 </td><td style=\"text-align: right;\">0.491953</td><td style=\"text-align: right;\">0.329217</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.67533</td><td style=\"text-align: right;\"> 3.09462</td><td style=\"text-align: right;\">73.5   </td><td style=\"text-align: right;\">0.504685</td><td style=\"text-align: right;\">0.336735</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.9379 </td><td style=\"text-align: right;\"> 2.77079</td><td style=\"text-align: right;\">51.5938</td><td style=\"text-align: right;\">0.488962</td><td style=\"text-align: right;\">0.324063</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.92938</td><td style=\"text-align: right;\"> 2.34034</td><td style=\"text-align: right;\">71.625 </td><td style=\"text-align: right;\">0.536288</td><td style=\"text-align: right;\">0.365915</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \rEpoch 0:  25%|       | 4685/18755 [18:58<56:59,  4.11it/s, loss=2.47, v_num=.]\rEpoch 0:  25%|       | 4685/18755 [18:58<56:59,  4.11it/s, loss=2.17, v_num=.]\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \rValidating:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2216)\u001b[0m \rValidating: 100%|| 937/938 [01:58<00:00,  7.93it/s]\u001b[A\rEpoch 0:  35%|      | 6559/18755 [20:57<38:57,  5.22it/s, loss=2.17, v_num=.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_LensGAN128_bdf63_00003:\n",
            "  FID: 51.9375\n",
            "  FID_cross: 59.90625\n",
            "  ap: 0.35214442014694214\n",
            "  ap_cross: 0.370050847530365\n",
            "  auroc: 0.5088307857513428\n",
            "  auroc_cross: 0.5446629524230957\n",
            "  date: 2021-10-27_23-24-37\n",
            "  done: false\n",
            "  experiment_id: 2c72ef395fc74d8497319b44496f0c6f\n",
            "  hostname: 9396f81d6793\n",
            "  iterations_since_restore: 2\n",
            "  loss_D: 2.5527193546295166\n",
            "  loss_G: 1.7852368354797363\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2216\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 1282.5163836479187\n",
            "  time_this_iter_s: 651.4055576324463\n",
            "  time_total_s: 1282.5163836479187\n",
            "  timestamp: 1635377077\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: bdf63_00003\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-27 23:24:40,678\tINFO trainable.py:76 -- Checkpoint size is 96446854 bytes\n",
            "2021-10-27 23:24:40,928\tWARNING util.py:166 -- The `start_trial` operation took 2.960 s, which may be a performance bottleneck.\n",
            "\u001b[2m\u001b[36m(pid=2216)\u001b[0m 2021-10-27 23:24:41,292\tINFO trainable.py:76 -- Checkpoint size is 378205254 bytes\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 2021-10-27 23:25:04,786\tINFO trainable.py:394 -- Restored on 172.28.0.2 from checkpoint: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2/train_LensGAN128_bdf63_00000_0_n_fmaps=8_2021-10-27_22-32-18/checkpoint_tmp959f90/./\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 2021-10-27 23:25:04,786\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 2, '_timesteps_total': None, '_time_total': 490.7602655887604, '_episodes_total': None}\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   warnings.warn('Lazy modules are a new feature under heavy development '\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `FID` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m Using native 16bit precision.\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m GPU available: True, used: True\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m Restoring states from the checkpoint file at /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2/train_LensGAN128_bdf63_00000_0_n_fmaps=8_2021-10-27_22-32-18/checkpoint_tmp959f90/./checkpoint\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2440)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m Restored all states from the checkpoint file at /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2/train_LensGAN128_bdf63_00000_0_n_fmaps=8_2021-10-27_22-32-18/checkpoint_tmp959f90/./checkpoint\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   | Name          | Type               | Params\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 0 | generator     | DCGANGenerator     | 385 K \n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 1 | discriminator | DCGANDiscriminator | 182 K \n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 2 | criterion     | BCEWithLogitsLoss  | 0     \n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 3 | modelF        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 4 | lastF         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 5 | modelJ        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 6 | lastJ         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 7 | imgMetrics    | MetricCollection   | 22.3 M\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 8 | FMetrics      | MetricCollection   | 0     \n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 9 | JMetrics      | MetricCollection   | 0     \n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 568 K     Trainable params\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 22.3 M    Non-trainable params\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 22.9 M    Total params\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 91.649    Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:377: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   f\"Your {mode}_dataloader has `shuffle=True`, it is best practice to turn\"\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2440)\u001b[0m \r                                                              \r\rTraining: -1it [00:00, ?it/s]\rTraining:   0%|          | 0/18755 [00:00<00:00, 20460.02it/s]\rEpoch 1:   0%|          | 0/18755 [00:00<00:04, 4686.37it/s]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: bdf63_00000 with auroc=0.5362882614135742 and parameters={'lr': -3, 'n_fmaps': 8, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (2 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">    FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">      ap</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.92938</td><td style=\"text-align: right;\"> 2.34034</td><td style=\"text-align: right;\">71.625 </td><td style=\"text-align: right;\">0.536288</td><td style=\"text-align: right;\">0.365915</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.9379 </td><td style=\"text-align: right;\"> 2.77079</td><td style=\"text-align: right;\">51.5938</td><td style=\"text-align: right;\">0.488962</td><td style=\"text-align: right;\">0.324063</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.78524</td><td style=\"text-align: right;\"> 2.55272</td><td style=\"text-align: right;\">51.9375</td><td style=\"text-align: right;\">0.508831</td><td style=\"text-align: right;\">0.352144</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.67533</td><td style=\"text-align: right;\"> 3.09462</td><td style=\"text-align: right;\">73.5   </td><td style=\"text-align: right;\">0.504685</td><td style=\"text-align: right;\">0.336735</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2440)\u001b[0m \rEpoch 1:   5%|         | 937/18755 [02:19<44:17,  6.71it/s]\rEpoch 1:   5%|         | 937/18755 [02:19<44:17,  6.71it/s, loss=2.21, v_num=.]\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2440)\u001b[0m \rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(ImplicitFunc pid=2440)\u001b[0m \rValidating:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "2021-10-27 23:28:14,514\tWARNING tune.py:575 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.49 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: bdf63_00000 with auroc=0.5362882614135742 and parameters={'lr': -3, 'n_fmaps': 8, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2<br>Number of trials: 4/4 (2 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">    FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">      ap</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_bdf63_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.92938</td><td style=\"text-align: right;\"> 2.34034</td><td style=\"text-align: right;\">71.625 </td><td style=\"text-align: right;\">0.536288</td><td style=\"text-align: right;\">0.365915</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.9379 </td><td style=\"text-align: right;\"> 2.77079</td><td style=\"text-align: right;\">51.5938</td><td style=\"text-align: right;\">0.488962</td><td style=\"text-align: right;\">0.324063</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.78524</td><td style=\"text-align: right;\"> 2.55272</td><td style=\"text-align: right;\">51.9375</td><td style=\"text-align: right;\">0.508831</td><td style=\"text-align: right;\">0.352144</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_LensGAN128_bdf63_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 1.67533</td><td style=\"text-align: right;\"> 3.09462</td><td style=\"text-align: right;\">73.5   </td><td style=\"text-align: right;\">0.504685</td><td style=\"text-align: right;\">0.336735</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m 2021-10-27 23:28:14,769\tERROR worker.py:428 -- SystemExit was raised from the worker\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"python/ray/_raylet.pyx\", line 684, in ray._raylet.task_execution_handler\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"python/ray/_raylet.pyx\", line 524, in ray._raylet.execute_task\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"python/ray/_raylet.pyx\", line 561, in ray._raylet.execute_task\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"python/ray/_raylet.pyx\", line 568, in ray._raylet.execute_task\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"python/ray/_raylet.pyx\", line 572, in ray._raylet.execute_task\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"python/ray/_raylet.pyx\", line 522, in ray._raylet.execute_task.function_executor\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/_private/function_manager.py\", line 579, in actor_method_executor\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 448, in _resume_span\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 189, in train_buffered\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m     result = self.train()\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 448, in _resume_span\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 248, in train\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m     result = self.step()\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 448, in _resume_span\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 362, in step\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m     block=True, timeout=RESULT_FETCH_TIMEOUT)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"/usr/lib/python3.7/queue.py\", line 179, in get\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m     self.not_empty.wait(remaining)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m     gotit = waiter.acquire(True, timeout)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/worker.py\", line 425, in sigterm_handler\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m     sys.exit(1)\n",
            "\u001b[2m\u001b[36m(pid=2440)\u001b[0m SystemExit: 1\n",
            "2021-10-27 23:28:14,926\tERROR tune.py:613 -- Trials did not complete: [train_LensGAN128_bdf63_00000, train_LensGAN128_bdf63_00001, train_LensGAN128_bdf63_00002, train_LensGAN128_bdf63_00003]\n",
            "2021-10-27 23:28:14,936\tINFO tune.py:617 -- Total run time: 3357.25 seconds (3356.48 seconds for the tuning loop).\n",
            "2021-10-27 23:28:14,938\tWARNING tune.py:622 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best checkpoint path found is:  /content/drive/MyDrive/Logs/F/LensGAN128/acgan_nodiscfake_leaky_discnoise_full_pb2/train_LensGAN128_bdf63_00000_0_n_fmaps=8_2021-10-27_22-32-18/checkpoint_epoch=0-step=1873/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQJPa94b10ka"
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btkO_vqvN5Yi"
      },
      "source": [
        "## Stage 2\n",
        "Here we tune hyperparameters as we train our modified DCGAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0efCKmqQkp3"
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_Stage2(config, checkpoint_dir=None, num_epochs=10, num_gpus=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    kwargs = {\n",
        "        # 'limit_train_batches' : 0.05,\n",
        "        # 'limit_val_batches' : 0.05,\n",
        "        'progress_bar_refresh_rate' : int(8250//config['batch_size']),\n",
        "        'max_epochs' : num_epochs,\n",
        "        'prepare_data_per_node' : False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        'gpus' : int(num_gpus),\n",
        "        'logger' : TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        'callbacks' : [\n",
        "            TuneReportCheckpointCallback(\n",
        "                {\n",
        "                    'loss_G': 'Stage2/G/train/loss', \n",
        "                    'loss_D': 'Stage2/D/train/loss', \n",
        "                    # Switch up the auroc vlues when training on different dataset -----------------------------------------------\n",
        "                    'auroc': 'Stage2/ResNet(F)/val/auroc', \n",
        "                    'auroc_cross': 'Stage2/ResNet(J)/val/auroc',\n",
        "                },\n",
        "            ),\n",
        "        ],\n",
        "        # 'stochastic_weight_avg' : True,\n",
        "        # works with only one optimizer\n",
        "        # 'benchmark' : True,\n",
        "    }\n",
        "    \n",
        "    dm = npyImageData(config)                                              # Specify image width here    \n",
        "    if checkpoint_dir is not None:\n",
        "        kwargs['resume_from_checkpoint'] = os.path.join(checkpoint_dir, 'checkpoint')\n",
        "        # model = Stage2.load_from_checkpoint(kwargs['resume_from_checkpoint'], config=config)\n",
        "    # else:\n",
        "        # model = Stage2(config)\n",
        "    model = Stage2(config)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "\n",
        "# # # __tune_asha_begin__\n",
        "# def tune_Stage2_asha(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "#     # print(os.cpu_count(), torch.cuda.device_count())\n",
        "#     analysis = tune.run(\n",
        "#         tune.with_parameters(\n",
        "#             train_Stage2,\n",
        "#             num_epochs=num_epochs,\n",
        "#             num_gpus=gpus_per_trial\n",
        "#         ),\n",
        "#         # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "#         name='Stage2/pbt/J',\n",
        "#         metric='auroc',\n",
        "#         mode='max',\n",
        "#         config={'learning_rate': 1e-4,\n",
        "#                 'n_fmaps': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "#                 'batch_size': 8,\n",
        "#                 },\n",
        "#         # config={'learning_rate': 0.01,\n",
        "#         #         'n_fmaps': 32,\n",
        "#         #         'batch_size': 32,\n",
        "#         #         },\n",
        "#         # stop=TrialPlateauStopper('loss_G'),\n",
        "#         resources_per_trial={'cpu': os.cpu_count(),\n",
        "#                              'gpu': gpus_per_trial,\n",
        "#                             },\n",
        "#         local_dir='./drive/MyDrive/Logs',\n",
        "#         scheduler = ASHAScheduler(max_t=num_epochs, grace_period=2,  reduction_factor=2),\n",
        "#         progress_reporter=JupyterNotebookReporter(\n",
        "#             overwrite=True,\n",
        "#             parameter_columns=['learning_rate', 'n_fmaps', 'batch_size'],\n",
        "#             metric_columns=['loss_G', 'loss_D', 'auroc', 'auroc_cross', 'training_iteration'],\n",
        "#             sort_by_metric=True,\n",
        "#         ),\n",
        "#         fail_fast = True,\n",
        "#         # reuse_actors=True,\n",
        "#         # num_samples=num_samples,\n",
        "#         resume='PROMPT',\n",
        "# #         restore='/content/drive/MyDrive/Logs/delete/train_Stage2_e42ac_00025_25_batch_size=8,learning_rate=0.01,n_fmaps=8_2021-07-28_21-16-18/checkpoint_epoch=4-step=2339',\n",
        "#     )\n",
        "\n",
        "# #     print('Best hyperparameters found were: ', analysis.best_config)\n",
        "\n",
        "# # # __tune_asha_end__\n",
        "\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_Stage2_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_Stage2,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial\n",
        "        ),\n",
        "        # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "        name='Stage2/pbt/F',\n",
        "        metric='auroc',\n",
        "        mode='max',\n",
        "        config={'learning_rate': 1e-4,\n",
        "                'n_fmaps': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "                'res_depth': tune.choice([1, 2, 3, 4]),\n",
        "                'batch_size': 8,\n",
        "                },\n",
        "        # config={'learning_rate': 0.01,\n",
        "        #         'n_fmaps': 32,\n",
        "        #         'batch_size': 32,\n",
        "        #         },\n",
        "        # stop=TrialPlateauStopper('loss_G'),\n",
        "        resources_per_trial={'cpu': os.cpu_count(),\n",
        "                             'gpu': gpus_per_trial,\n",
        "                            },\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        scheduler = PopulationBasedTraining(time_attr='training_iteration',\n",
        "                                            quantile_fraction=0.5,\n",
        "                                            resample_probability=0.8,\n",
        "                                            perturbation_interval=1,\n",
        "                                            hyperparam_mutations={\n",
        "                                                'learning_rate': tune.loguniform(1e-7, 1e-1),\n",
        "                                                'batch_size': [8, 16, 32, 64, 128],\n",
        "                                            },\n",
        "                                            ),\n",
        "        progress_reporter=JupyterNotebookReporter(\n",
        "            overwrite=False,\n",
        "            parameter_columns=['learning_rate', 'n_fmaps', 'res_depth', 'batch_size'],\n",
        "            metric_columns=['loss_G', 'loss_D', 'auroc', 'auroc_cross', 'training_iteration'],\n",
        "            sort_by_metric=True,\n",
        "        ),\n",
        "        fail_fast = True,\n",
        "        # reuse_actors=True,\n",
        "        # num_samples=num_samples,\n",
        "        resume='PROMPT',\n",
        "    )\n",
        "\n",
        "    print('Best hyperparameters found were: ', analysis.best_config)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_Stage2_asha(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "        tune_Stage2_pbt(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # ASHA scheduler\n",
        "        # tune_Stage2_asha(num_samples=1, num_epochs=10, gpus_per_trial=torch.cuda.device_count())\n",
        "        # Population based training\n",
        "        tune_Stage2_pbt(num_samples=1, num_epochs=30, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}