{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lightning_Tune.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WK9GeW6miiXr",
        "ASOiXXn-36Wf",
        "FbXpnU7Y4Cr9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravraha/galaxy/blob/pgan/Lightning_Tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDsadYRa5Rh5"
      },
      "source": [
        "# Mount Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF5oJHq0_WxS"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', timeout_ms=600000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDzU0Yty6Qsw"
      },
      "source": [
        "# Prerequisites/ shell commands"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI_RfiMRk5j_"
      },
      "source": [
        "## Install/uninstall packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMwknUIDcTW1"
      },
      "source": [
        "# If you are running on Google Colab, uncomment below to install the necessary dependencies \n",
        "# before beginning the exercise.\n",
        "\n",
        "print('Setting up colab environment')\n",
        "!pip install -q tf-estimator-nightly==2.8.0.dev2021122109 imgaug==0.2.6 matplotlib==3.4.3 torchmetrics[image] lightning-bolts GPy ray[tune]\n",
        "\n",
        "# A hack to force the runtime to restart, needed to include the above dependencies.\n",
        "print('Done installing! Restarting via forced crash (this is not an issue).')\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK9GeW6miiXr"
      },
      "source": [
        "## Download and extract data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZUIrgOfbwPe"
      },
      "source": [
        "# 'a': 1Cjcw2EWorhdhJSGoWOdxsEUDxvl943dt, 'b': 15yXXC4h5VsytP3Ak1jfUSjQhdgP2s23K, 'c': 1vuQ-pLzoKT4Hd_V7949r9eND9E2fB_u_,\n",
        "# 'd': , 'e': 1wFuasvb7PthxXtMUlsD13uzYHWlWt06H, 'f': 17l6H61tLAu26zGuei38r_T5ssjbYUeaJ, \n",
        "# 'g': 1SxQVosWeEjY3Pyn8LRXA11rLnZ9HK_7B, 'h': 1Atau0RH4oyLAiYReW-G9a8l9pUNltglF, 'i': 15lEgsR1p00KSHieaT9a1nkbJ86pDxwgp, \n",
        "# 'j': 1m0EQUbqZZeyl76XsQIKWU5Qd7jGmmWhB, 'k': , 'l': 1meTDi4aeWfdChOiXeLtUOGhjVDVu000e\n",
        "\n",
        "# fake data\n",
        "# 'fpgan': 1-4o0yqSBA9WSY9gTYamIez_RAekwDsHV\n",
        "\n",
        "!rm -rf images/\n",
        "# !pip install -q --upgrade --no-cache-dir gdown\n",
        "!gdown --id 17l6H61tLAu26zGuei38r_T5ssjbYUeaJ -O - --quiet | tar --skip-old-files -zxf -"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxQTZTEy5GWe"
      },
      "source": [
        "# Line wrapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXMwcAw45FsR"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "    display(HTML('''<style>pre{white-space: pre-wrap;}</style>'''))\n",
        "    \n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB3f7W9_kazP"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR6G_K6bWVqd"
      },
      "source": [
        "import os, copy, psutil, ray\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import cycle\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "# ------------------------------------\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "# ------------------------------------\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torchvision import transforms, datasets\n",
        "# ------------------------------------\n",
        "from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay\n",
        "# ------------------------------------\n",
        "import torchmetrics as tm\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance as FID\n",
        "from torchmetrics.image.kid import KernelInceptionDistance as KID\n",
        "# ------------------------------------\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# from pl_bolts.models.autoencoders import VAE\n",
        "from pl_bolts.models.gans import DCGAN, Pix2Pix\n",
        "from pl_bolts.callbacks import ModuleDataMonitor\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pl_bolts.models.self_supervised.resnets import BasicBlock\n",
        "from pytorch_lightning.callbacks import TQDMProgressBar #ModelCheckpoint\n",
        "# from drive.MyDrive.ml.Callbacks.confused_logits import ConfusedLogitCallback\n",
        "# from drive.MyDrive.ml.Callbacks.save_images import SaveImages\n",
        "# ------------------------------------\n",
        "from ray import tune\n",
        "# from ray.tune.stopper import TrialPlateauStopper\n",
        "from ray.tune import CLIReporter, JupyterNotebookReporter\n",
        "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
        "from ray.tune.schedulers.pb2 import PB2\n",
        "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
        "# ------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hczXOvdE54S"
      },
      "source": [
        "# Class definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snbv_zoNiWfW"
      },
      "source": [
        "## DataModule\n",
        "This creates dataloaders which need to be supplied to train, validate or test the module we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yItuGxXmXzGr"
      },
      "source": [
        "class npyImageData(pl.LightningDataModule):\n",
        "    def __init__(self, config, img_width: int = 150, data_dir: str = '/content/images/'):\n",
        "        super().__init__()\n",
        "        # This method is not implemented\n",
        "        # self.save_hyperparameters()\n",
        "        self.bs = int(2**np.rint(config['bs']))\n",
        "        self.data_dir = os.path.expanduser(data_dir)\n",
        "        self.prepare_data_per_node = False\n",
        "\n",
        "        # Change the source file containing mean and stdv when changing dataset ------------------------------------------------------\n",
        "        self.transform = transforms.Compose([\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            # transforms.RandomVerticalFlip(),\n",
        "            # F : [mean=71.75926373866668, std=96.139484964214, min=5.0, max=966.0]\n",
        "            # J : [mean=50.271541595458984, std=94.8838882446289, min=0, max=1007.0]\n",
        "            transforms.Normalize(mean=(0,), std=(966,)),\n",
        "            transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "            # this shift-scales the pixel values -> [-1, 1]\n",
        "            transforms.Resize(img_width, transforms.InterpolationMode.NEAREST),\n",
        "        ])\n",
        "\n",
        "    @staticmethod\n",
        "    def npy_loader(path):\n",
        "        # s=np.load(path).astype('float',copy=False)\n",
        "        return torch.from_numpy(np.load(path)).unsqueeze(0).float()\n",
        "        # Convert to tenssor first, and then to float, otherwise final dtype \n",
        "        # would be float64, which would raise errors in conv layers      ###### type as\n",
        "\n",
        "    def setup(self, stage: str = None):\n",
        "        if stage in ('fit', None):\n",
        "            self.train_set = datasets.DatasetFolder(os.path.join(self.data_dir,'train'), \n",
        "                self.npy_loader, ('.npy'), self.transform,)\n",
        "            # self.train_set, self.val_set = random_split(self.full_set, [60000, 15000])            \n",
        "            self.val_set = datasets.DatasetFolder(os.path.join(self.data_dir,'val'),  \n",
        "                self.npy_loader, ('.npy'), self.transform,)\n",
        "            # self.dims = tuple(self.train_set[0][0].shape)\n",
        "\n",
        "        if stage in ('test', None):\n",
        "            self.test_set = datasets.DatasetFolder(os.path.join(self.data_dir,'val'),  \n",
        "                self.npy_loader, ('.npy'), self.transform,)\n",
        "            # self.dims = getattr(self, 'dims', self.test_set[0][0].shape)\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_set, self.bs, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_set, self.bs, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_set, self.bs, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C3gKSFKKDaY"
      },
      "source": [
        "dm = npyImageData({'lr': 0.001, 'bs': 8})\n",
        "# model = LensResnet.load_from_checkpoint(os.path.join(BEST_F_RESNET, 'checkpoint'), config={'lr': 0.001, 'bs': 8})\n",
        "# trainer = pl.Trainer(gpus=1)\n",
        "# trainer.predict(model, dm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0bm1afc11hN"
      },
      "source": [
        "## ResNet\n",
        "We modify a ResNet slightly for our purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojZ0yT4z168p"
      },
      "source": [
        "PRE_F_RESNET = '/content/drive/MyDrive/Logs/F/LensResnet/PRETRAINED.pth'\n",
        "PRE_J_RESNET = '/content/drive/MyDrive/Logs/J/LensResnet/PRETRAINED.pth'\n",
        "\n",
        "class LensResnet(pl.LightningModule):\n",
        "    def __init__(self, config, image_channels: int = 1, num_classes: int = 3, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "        self.lr = 10**config['lr']\n",
        "\n",
        "        # --------------------------------------------------------------------------------------------------\n",
        "        self.backbone = torch.load(PRE_F_RESNET, map_location=self.device)\n",
        "        # self.backbone = resnet18(num_classes=self.hparams.num_classes)\n",
        "        # self.backbone.conv1 = nn.LazyConv2d(64, 7, 2, 3, bias=False)\n",
        "        \n",
        "        self.train_metrics = tm.MetricCollection([tm.AUROC(self.hparams.num_classes, average='weighted'),],\n",
        "            prefix='LensResnet/train/'\n",
        "        )\n",
        "        self.val_metrics = tm.MetricCollection(\n",
        "            [tm.PrecisionRecallCurve(self.hparams.num_classes), tm.ROC(self.hparams.num_classes),\n",
        "            tm.AveragePrecision(self.hparams.num_classes), tm.AUROC(self.hparams.num_classes, average=None)]\n",
        "        )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.backbone.parameters(), self.lr)\n",
        "\n",
        "    def forward(self, x, prob=False):\n",
        "        logits = self.backbone(x)\n",
        "        return logits.softmax(1) if prob else logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        self.last_logits = self(imgs)\n",
        "        loss = F.cross_entropy(self.last_logits, labels)\n",
        "        self.log('LensResnet/train/loss', loss)\n",
        "        #  keep only scalars here, for no errors\n",
        "        \n",
        "        preds = self.last_logits.softmax(1)\n",
        "        self.train_metrics.update(preds, labels)\n",
        "        try:\n",
        "            self.log_dict(self.train_metrics.compute(), prog_bar=True)\n",
        "        except Exception as f:\n",
        "            print(f)\n",
        "        finally:            \n",
        "            # self.train_metrics.reset()\n",
        "            # self.log_dict automatically resets at the end of epoch\n",
        "            return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        logits = self(imgs)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        self.log('LensResnet/val/loss', loss)\n",
        "        #  keep only scalars here, for no errors\n",
        "        \n",
        "        preds = logits.softmax(1)\n",
        "        self.val_metrics.update(preds, labels)\n",
        "\n",
        "    def validation_epoch_end(self, Listofdicts):\n",
        "        colors = cycle(['r', 'g', 'b'])\n",
        "        fig, ax = plt.subplots(1,2, subplot_kw={'xlim': [-0.05, 1.05], 'ylim': [-0.05, 1.05], 'aspect': 1}, figsize=(10, 5))\n",
        "        # ---------------------------------------------------------------------------------------------------------\n",
        "        fig.suptitle('One vs. all PR & ROC curves for different types of substructures in model J (orginal data)')\n",
        "        \n",
        "        Dict = self.val_metrics.compute()\n",
        "        self.val_metrics.reset()\n",
        "        \n",
        "        key, val = list(Dict.keys()), list(Dict.values())\n",
        "        for b in range(2):\n",
        "            if key[b] != 'ROC':\n",
        "                ax[b].plot([0, 1], [1/self.hparams.num_classes, 1/self.hparams.num_classes], 'k--')\n",
        "            else:\n",
        "                ax[b].plot([0, 1], [0, 1], 'k--')\n",
        "            \n",
        "            prec_FPR, rec_TPR, _ = val[b]\n",
        "            for i, color, cls in zip(range(self.hparams.num_classes), colors, self.trainer.datamodule.val_set.classes):\n",
        "                if key[b] != 'ROC':\n",
        "                    PrecisionRecallDisplay(prec_FPR[i].cpu(), rec_TPR[i].cpu(), val[2 + b][i], cls).plot(ax[b], c=color)\n",
        "                else:\n",
        "                    RocCurveDisplay(prec_FPR[i].cpu(), rec_TPR[i].cpu(), val[2 + b][i], cls).plot(ax[b], c=color)\n",
        "                \n",
        "            ax[b].legend(loc='best')\n",
        "            self.log('LensResnet/val/' + key[2 + b], min(val[2 + b]))\n",
        "\n",
        "        self.logger.experiment.add_figure('LensResnet/val/PR_ROC', fig)\n",
        "        fig.savefig(str(self.trainer.log_dir) + '/PR_ROC_step_{:05d}.png'.format(self.global_step))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRVE-YyyWNUj"
      },
      "source": [
        "m = LensResnet({'lr': 1e-3})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc0oRARcKBv3"
      },
      "source": [
        "## LensGAN128\n",
        "Here we subclass a DCGAN to create our low resolution GAN."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getLayerNormalizationFactor(x):\n",
        "    size = x.weight.size()\n",
        "    fan_in = np.prod(size[1:])\n",
        "    return np.sqrt(2.0 / fan_in)\n",
        "\n",
        "\n",
        "class ConstrainedLayer(nn.Module):\n",
        "    def __init__(self, module, equalized=True, lrMul=1.0, initBiasToZero=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.module = module\n",
        "        self.equalized = equalized\n",
        "\n",
        "        if initBiasToZero:\n",
        "            self.module.bias.data.fill_(0)\n",
        "        if self.equalized:\n",
        "            self.module.weight.data.normal_(0, 1)\n",
        "            self.module.weight.data /= lrMul\n",
        "            self.weight = getLayerNormalizationFactor(self.module) * lrMul\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.module(x)\n",
        "        if self.equalized:\n",
        "            x *= self.weight\n",
        "        return x\n",
        "\n",
        "class SNLayer(nn.Module):\n",
        "    def __init__(self, module, spec=True, initBiasToZero=True):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.module = module if not spec else nn.utils.parametrizations.spectral_norm(module)\n",
        "        if initBiasToZero:\n",
        "            self.module.bias.data.fill_(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.module(x)\n",
        "        return x\n",
        "\n",
        "class EqualizedConv2d(SNLayer):\n",
        "    def __init__(self, nChannelsPrev, nChannels, kernelSize=4, stride=2, padding=1, bias=True, **kwargs):\n",
        "        super().__init__(nn.Conv2d(nChannelsPrev, nChannels, kernelSize, stride, padding, bias=bias), **kwargs)\n",
        "class EqualizedConvTranspose2d(SNLayer):\n",
        "    def __init__(self, nChannelsPrev, nChannels, kernelSize=4, stride=2, padding=1, bias=True, **kwargs):\n",
        "        super().__init__(nn.ConvTranspose2d(nChannelsPrev, nChannels, kernelSize, stride, padding, bias=bias), **kwargs)\n",
        "class EqualizedLinear(SNLayer):\n",
        "    def __init__(self, nChannelsPrev, nChannels=1, bias=True, **kwargs):\n",
        "        super().__init__(nn.Linear(nChannelsPrev, nChannels, bias=bias), **kwargs)"
      ],
      "metadata": {
        "id": "hGtvjuKo4q_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kclAeom914wK"
      },
      "source": [
        "from torch.nn.modules.linear import Identity\n",
        "BEST_F_RESNET = '/content/drive/MyDrive/Logs/F/LensResnet/pbt_tanh/train_LensResnet_eb619_00000_0_2021-09-02_19-42-34/checkpoint_epoch=2-step=28124'\n",
        "BEST_J_RESNET = '/content/drive/MyDrive/Logs/J/LensResnet/pbt_tanh_fine/train_LensResnet_93609_00000_0_2021-09-02_21-06-00/checkpoint_epoch=2-step=28124'\n",
        "\n",
        "class LensGAN128(DCGAN):\n",
        "    def __init__(self, config, num_classes: int = 3, step_size: int = 3000, **kwargs):\n",
        "        super().__init__(feature_maps_gen=config['n_fmaps'], feature_maps_disc=config['n_fmaps'], \n",
        "                         learning_rate=10**config['lr'], **kwargs)\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "\n",
        "        del self.generator.gen, self.discriminator.disc\n",
        "        self.discriminator.disc, self.generator.gen = nn.ModuleList(), nn.ModuleList()\n",
        "        self.discriminator.fromGrey, self.generator.toGrey = nn.ModuleList(), nn.ModuleList()\n",
        "        chnl = self.hparams.config['n_fmaps'] ** 2 // 4\n",
        "        c, kw = True, {'s': 1, 'p' : 0}\n",
        "        while chnl >= self.hparams.feature_maps_gen:\n",
        "            self.generator.gen.append(\n",
        "                self._make_gen_block(self.hparams.latent_dim if c else min(2 * chnl, 512), min(chnl, 512), **(kw if c else {}))\n",
        "            )\n",
        "            self.generator.toGrey.append(nn.Sequential(EqualizedConvTranspose2d(min(chnl, 512), 1, 1, 1, 0), nn.Tanh()))\n",
        "            self.discriminator.fromGrey.append(EqualizedConv2d(1, min(chnl, 512), 1, 1, 0))\n",
        "            self.discriminator.disc.append(self._make_disc_block(min(chnl, 512), 1 if c else min(2 * chnl, 512), **(kw if c else {})))\n",
        "            chnl = chnl//2\n",
        "            c = False\n",
        "        # Remove dropout from last layer\n",
        "        del self.discriminator.disc[0][-1]\n",
        "\n",
        "        self.generator.add_module('mu', nn.Embedding(self.hparams.num_classes, self.hparams.latent_dim))\n",
        "        self.generator.add_module('sigma', nn.Embedding(self.hparams.num_classes, self.hparams.latent_dim))\n",
        "        self.generator.forward = self.forward \n",
        "        # # Remove if ACGAN not needed \n",
        "        self.discriminator.add_module(\n",
        "            'aux', nn.Sequential(\n",
        "                nn.Flatten(), EqualizedLinear(min(self.hparams.config['n_fmaps']**2 // 4, 512) * 4**2, self.hparams.config['n_fmaps']),\n",
        "                nn.LeakyReLU(0.2, inplace=True), nn.Dropout(0.3), EqualizedLinear(self.hparams.config['n_fmaps'], self.hparams.num_classes)\n",
        "            )\n",
        "        )\n",
        "        self.discriminator.forward = self.discriminator_forward\n",
        "\n",
        "        self.stage = 0\n",
        "        self.alpha = 1.0\n",
        "        self.ssimloss = 10\n",
        "\n",
        "        # Not needed in WGAN architectures\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        tmp = LensResnet.load_from_checkpoint(os.path.join(BEST_F_RESNET, 'checkpoint'))\n",
        "        tmp.freeze()\n",
        "        self.modelF = tmp.backbone     # torch.load(PRE_F_RESNET, map_location=self.device).eval())\n",
        "        # Proper way to copy the last layer\n",
        "        self.lastF = self.modelF.fc\n",
        "        self.modelF.fc = nn.Identity()\n",
        "        \n",
        "        tmp = LensResnet.load_from_checkpoint(os.path.join(BEST_J_RESNET, 'checkpoint'))\n",
        "        tmp.freeze()\n",
        "        self.modelJ = tmp.backbone     # torch.load(PRE_J_RESNET, map_location=self.device).eval())\n",
        "        # Proper way to copy the last layer\n",
        "        self.lastJ = self.modelJ.fc\n",
        "        self.modelJ.fc = nn.Identity()\n",
        "\n",
        "        self.imgMetrics = tm.MetricCollection(\n",
        "            {\n",
        "                'FID_F' : FID(self.modelF),\n",
        "                'FID_J' : FID(self.modelJ)\n",
        "            },\n",
        "            prefix='LensGAN128/val/',\n",
        "        )\n",
        "\n",
        "        self.metrics = tm.MetricCollection(\n",
        "            [tm.PrecisionRecallCurve(self.hparams.num_classes), tm.ROC(self.hparams.num_classes),\n",
        "            tm.AveragePrecision(self.hparams.num_classes, average=None), tm.AUROC(self.hparams.num_classes, average=None)],\n",
        "        )\n",
        "    \n",
        "    @staticmethod\n",
        "    def _make_gen_block(x : int, y : int, k :int = 4, s : int = 2, p : int = 1, b : bool = True) -> nn.Sequential:\n",
        "        return nn.Sequential(\n",
        "            EqualizedConvTranspose2d(x, y, k, s, p, b),\n",
        "            nn.BatchNorm2d(y),\n",
        "            # nn.LocalResponseNorm(2*y, 2, 0.5, 1e-8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_disc_block(x : int, y : int, k :int = 4, s : int = 2, p : int = 1, b : bool = True) -> nn.Sequential:\n",
        "        return nn.Sequential(\n",
        "            EqualizedConv2d(x, y, k, s, p, b),\n",
        "            # nn.LocalResponseNorm(s, 1, 0.5, 1e-8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "    def discriminator_forward(self, inp):\n",
        "        # Add noise to the data\n",
        "        # inp = inp + torch.randn_like(inp) * np.exp(-self.global_step * len(inp) / self.hparams.step_size)\n",
        "        x = self.discriminator.fromGrey[self.stage](inp)\n",
        "        out = self.discriminator.disc[self.stage](x)\n",
        "        if 0 <= self.alpha < 1.0:\n",
        "            out = torch.lerp(self.discriminator.fromGrey[self.stage - 1](F.adaptive_avg_pool2d(inp, out.shape[-2:])), out, self.alpha)\n",
        "        \n",
        "        for layer in reversed(self.discriminator.disc[:self.stage]):\n",
        "            # shouldn't combine in a single line\n",
        "            x = out\n",
        "            out = layer(out)\n",
        "\n",
        "        # # Not needed if not using ACGAN\n",
        "        # out5 = self.discriminator.disc(inp)\n",
        "        return out.squeeze(), self.discriminator.aux(x)\n",
        "        # return self.discriminator.disc(inp).squeeze()\n",
        "\n",
        "    def forward(self, noise, labels, all_layers=False):\n",
        "        inp = noise * self.generator.sigma(labels) + self.generator.mu(labels)\n",
        "        # inp = torch.cat((F.one_hot(labels, self.hparams.num_classes), noise), 1)\n",
        "        out = [inp.view(*inp.shape, 1, 1)]\n",
        "        \n",
        "        for layer in self.generator.gen[:self.stage+1]:\n",
        "            out.append(layer(out[-1]))\n",
        "        \n",
        "        # for i, layer in enumerate(self.generator.toGrey[:self.stage+1], 1):\n",
        "        #     out[i] = layer(out[i])\n",
        "        out[-1] = self.generator.toGrey[self.stage](out[-1])\n",
        "\n",
        "        if 0 <= self.alpha < 1.0:\n",
        "            out[-1] = torch.lerp(F.interpolate(self.generator.toGrey[self.stage - 1](out[-2]), out[-1].shape[-2:]), out[-1], self.alpha)\n",
        "\n",
        "        return out[1:] if all_layers else out[-1]\n",
        "\n",
        "    # Save layer-wise activations\n",
        "    def plotting(self):\n",
        "        self.eval()\n",
        "        torch.set_grad_enabled(False)\n",
        "\n",
        "        labels = torch.arange(self.hparams.num_classes, device=self.device)\n",
        "        imgs = self._get_fake_data(labels, all_layers=True)\n",
        "        for lyr, img4d in enumerate(imgs[:-1]):\n",
        "            new = list(img4d)\n",
        "            for cls, filters3d in enumerate(new):\n",
        "                new[cls] = make_grid(filters3d.unsqueeze(1), nrow=int(np.ceil(np.sqrt(len(filters3d)))), normalize=True)\n",
        "\n",
        "            imgs[lyr] = F.interpolate(torch.stack(new), 150)\n",
        "\n",
        "        if len(imgs) > 1:\n",
        "            save_image(torch.cat(imgs[-2::-1]), \n",
        "                str(self.trainer.log_dir) + '/F_maps_step_{:05d}.png'.format(self.global_step), \n",
        "                #  kwargs for make_grid\n",
        "                nrow=self.hparams.num_classes, pad_value=0.5)\n",
        "        \n",
        "        imgs = imgs[-1]\n",
        "        while len(labels) > 0:\n",
        "            x, y = self.trainer.datamodule.val_set[np.random.randint(0, len(self.trainer.datamodule.val_set))]\n",
        "            if y == labels[0]:\n",
        "                x = F.adaptive_avg_pool2d(x.unsqueeze(0).type_as(imgs), imgs.shape[-2:])\n",
        "                imgs = torch.cat((imgs, x))\n",
        "                labels = labels[1:]\n",
        "\n",
        "        save_image(F.interpolate(imgs, 150), \n",
        "                str(self.trainer.log_dir) + '/Fake_step_{:05d}.png'.format(self.global_step), \n",
        "                #  kwargs for make_grid\n",
        "                nrow=self.hparams.num_classes, normalize=True, value_range=(-1,1), pad_value=0.5)\n",
        "        \n",
        "        self.train()\n",
        "        torch.set_grad_enabled(True)\n",
        "\n",
        "    def on_train_batch_start(self, batch, batch_idx):\n",
        "        if self.global_step % self.hparams.step_size == 0:\n",
        "            self.plotting()\n",
        "\n",
        "        # Update stage and alpha\n",
        "        if self.alpha == 1.0 and self.stage < len(self.generator.gen) - 1:\n",
        "            s = self.trainer.logged_metrics.get('loss_G', None)\n",
        "            if s != None and s < np.exp(-self.stage) * 2.0:\n",
        "            # if self.ssimloss < 0.2: #np.exp(-self.stage):\n",
        "                self.plotting()\n",
        "                self.stage += 1\n",
        "                self.alpha = 0.0\n",
        "        self.alpha = min(self.alpha + 1/self.hparams.step_size, 1.0)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        real, self.labels = batch # Can remove this attribute when not using acgan\n",
        "        fake = self._get_fake_data(self.labels).type_as(real)\n",
        "        # ssim = tm.functional.multiscale_structural_similarity_index_measure(\n",
        "        #   F.interpolate(fake, real.shape[-2:]), real, True, 0.4, 3, \n",
        "        #   betas=tuple(np.diff(np.sort(np.random.rand(self.stage)), prepend=0, append=1)),\n",
        "        # )\n",
        "        real = F.adaptive_avg_pool2d(real, fake.shape[-2:])\n",
        "        ssim = tm.functional.multiscale_structural_similarity_index_measure(\n",
        "          fake, real.detach(), True, 0.4, 3, \n",
        "          betas=tuple(np.diff(np.sort(np.random.rand(self.stage)), prepend=0, append=1)), normalize='relu',\n",
        "        )\n",
        "        # print(ssim)\n",
        "        self.ssimloss = torch.clamp(-torch.log10(ssim), max=10)\n",
        "        # self.mse = F.mse_loss(fake.detach(), real.detach())\n",
        "\n",
        "        # Train discriminator\n",
        "        result = None\n",
        "        if optimizer_idx == 0:\n",
        "            result = self._disc_step(real, fake.detach())\n",
        "\n",
        "        # Train generator\n",
        "        if optimizer_idx == 1:\n",
        "            result = self._gen_step(fake)\n",
        "        \n",
        "        return result\n",
        "\n",
        "    def _disc_step(self, real, fake):\n",
        "        # # Not needed if using gradient penalty\n",
        "        # for p in self.discriminator.parameters():\n",
        "        #     p.data.clamp_(-0.01, 0.01)\n",
        "        disc_loss = self._get_disc_loss(real, fake)\n",
        "        self.log('loss_D', disc_loss, True)\n",
        "        return disc_loss\n",
        "\n",
        "    def _gen_step(self, fake):\n",
        "        gen_loss = self._get_gen_loss(fake)\n",
        "        self.log('loss_G', gen_loss, True)\n",
        "        return gen_loss\n",
        "\n",
        "    def _get_disc_loss(self, real, fake):\n",
        "        # Train with real\n",
        "        # realCritic_pred = self.discriminator(real)\n",
        "        realCritic_pred, realAux_pred = self.discriminator(real)\n",
        "        # real_loss = -realCritic_pred.mean()\n",
        "        real_gt = torch.ones_like(realCritic_pred)\n",
        "        real_loss = self.criterion(realCritic_pred, real_gt)\n",
        "        self.log('loss_D_real', real_loss, True)\n",
        "\n",
        "        # Train with fake\n",
        "        # fakeCritic_pred = self.discriminator(fake)\n",
        "        fakeCritic_pred, _ = self.discriminator(fake)\n",
        "        # fake_loss = fakeCritic_pred.mean()\n",
        "        fake_gt = torch.zeros_like(fakeCritic_pred)\n",
        "        fake_loss = self.criterion(fakeCritic_pred, fake_gt)\n",
        "        self.log('loss_D_fake', fake_loss, True)\n",
        "\n",
        "        # # Classifier loss\n",
        "        class_loss = nn.CrossEntropyLoss()(realAux_pred, self.labels) \n",
        "        # + nn.CrossEntropyLoss()(fakeAux_pred, self.labels)\n",
        "        self.log('loss_D_class', class_loss, True)\n",
        "\n",
        "        # # Compute gradient penalty\n",
        "        # gp = 10 * self._gradient_penalty(real, fake)\n",
        "        # self.log('loss_D_gp', gp, True)\n",
        "\n",
        "        # Modi\n",
        "        return real_loss + fake_loss + class_loss #+ gp \n",
        "\n",
        "    def _get_gen_loss(self, fake):\n",
        "        # Train with fake\n",
        "        # fakeCritic_pred = self.discriminator(fake)\n",
        "        fakeCritic_pred, fakeAux_pred = self.discriminator(fake)\n",
        "        # fake_loss = -fakeCritic_pred.mean()\n",
        "        fake_gt = torch.ones_like(fakeCritic_pred)\n",
        "        fake_loss = self.criterion(fakeCritic_pred, fake_gt)\n",
        "        self.log('loss_G_fake', fake_loss, True)\n",
        "\n",
        "        # Classifier loss\n",
        "        class_loss = nn.CrossEntropyLoss()(fakeAux_pred, self.labels)\n",
        "        self.log('loss_G_class', class_loss, True)\n",
        "\n",
        "        # L2 loss\n",
        "        # self.log('loss_G_mse', self.mse, True)\n",
        "\n",
        "        self.log('loss_G_ssim', self.ssimloss, True)\n",
        "        \n",
        "        return fake_loss + class_loss + self.ssimloss\n",
        "\n",
        "    def _get_fake_data(self, labels, **kwargs):\n",
        "        batch_size = len(labels)\n",
        "        noise = self._get_noise(batch_size, self.hparams.latent_dim)\n",
        "        fake = self(noise, labels, **kwargs)\n",
        "\n",
        "        return fake\n",
        "\n",
        "    # def _gradient_penalty(self, real, fake):\n",
        "    #     \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
        "    #     # Random weight term for interpolation between real and fake samples\n",
        "    #     alpha = torch.rand(len(real), 1, 1, 1)\n",
        "    #     # Get random interpolation between real and fake samples\n",
        "    #     mix = torch.lerp(real, fake, alpha.type_as(real)).requires_grad_(True)\n",
        "    #     # # Remove the underscore if not using ACGAN\n",
        "    #     d_mix ,_ = self.discriminator(mix)\n",
        "    #     # Get gradient w.r.t. mix\n",
        "    #     gradients = torch.autograd.grad(\n",
        "    #         outputs=d_mix,\n",
        "    #         inputs=mix,\n",
        "    #         grad_outputs=torch.ones_like(d_mix),\n",
        "    #         create_graph=True,\n",
        "    #         retain_graph=True,\n",
        "    #         only_inputs=True,\n",
        "    #     )[0]\n",
        "    #     gradients = gradients.view(len(mix), -1)\n",
        "    #     gp = ((gradients.norm(2, dim=1) - 1) ** 2)\n",
        "    #     return gp.mean()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        orig, labels = batch\n",
        "        self.imgMetrics.update(orig, real=True)\n",
        "        fake = self._get_fake_data(labels).type_as(orig)\n",
        "        # ssim = tm.functional.multiscale_structural_similarity_index_measure(\n",
        "        #   fake, F.adaptive_avg_pool2d(orig, fake.shape[-2:]), True, 0.4, 3, \n",
        "        #   betas=tuple(np.diff(np.sort(np.random.rand(self.stage)), prepend=0, append=1)), reduction=None\n",
        "        # )\n",
        "        fake = F.interpolate(fake, orig.shape[-2:])\n",
        "        self.imgMetrics.update(fake, real=False)\n",
        "\n",
        "        return {\n",
        "            'y0' : labels, \n",
        "            'y1' : self.lastF(self.modelF(orig)).softmax(1), \n",
        "            'y2' : self.lastF(self.modelF(fake)).softmax(1),\n",
        "            'y3' : self.lastJ(self.modelJ(orig)).softmax(1), \n",
        "            'y4' : self.lastJ(self.modelJ(fake)).softmax(1),\n",
        "            # 'y5' : ssim\n",
        "        }\n",
        "\n",
        "    def curve_plot(self, ax, score, b, src, colors, y0 = -1):\n",
        "        keys, items = list(score[y0].keys()), list(score[y0].values())\n",
        "        score1, score2, _ = items[b]\n",
        "        if b == 0:\n",
        "            ax.plot([0, 1], [1/self.hparams.num_classes, 1/self.hparams.num_classes], 'k--')\n",
        "        else:\n",
        "            ax.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "        for i, color, cls in zip(range(self.hparams.num_classes), colors, \n",
        "                                self.trainer.datamodule.val_set.classes):\n",
        "            if b == 0:\n",
        "                PrecisionRecallDisplay(precision=score1[i].cpu(), recall=score2[i].cpu(), \n",
        "                                    average_precision=items[2 + b][i], estimator_name=cls).plot(ax, c=color)\n",
        "            else:\n",
        "                RocCurveDisplay(fpr=score1[i].cpu(), tpr=score2[i].cpu(), roc_auc=items[2 + b][i], \n",
        "                                estimator_name=cls).plot(ax, c=color)\n",
        "\n",
        "        ax.legend(loc='best')\n",
        "        if y0 % 4 == 3:\n",
        "            self.log('LensGAN128/LensResnet(' + src + ')/val/' + keys[2 + b], sum(items[2 + b])/len(items[2 + b]))\n",
        "        else:\n",
        "            ax.set_title('Class ' + str(y0) + ' is fake')\n",
        "\n",
        "    def validation_epoch_end(self, ListofDicts):\n",
        "        # Classification scores\n",
        "        Fid = self.imgMetrics.compute()\n",
        "        # self.log_dict(Fid) isn't compatible with val_check_interval      \n",
        "        self.log_dict(Fid)\n",
        "        self.imgMetrics.reset()\n",
        "\n",
        "        # ssim = torch.cat([x['y5'] for x in ListofDicts]).mean()\n",
        "        # self.log('LensGAN128/val/ssim', ssim)\n",
        "\n",
        "        labels = torch.cat([x['y0'] for x in ListofDicts])\n",
        "        orig = [torch.cat([x['y1'] for x in ListofDicts]), torch.cat([x['y3'] for x in ListofDicts])]\n",
        "        fake = [torch.cat([x['y2'] for x in ListofDicts]), torch.cat([x['y4'] for x in ListofDicts])]\n",
        "\n",
        "        fig = plt.figure(constrained_layout=True, figsize=(20, 18))\n",
        "        char = 'original' if self.global_step == 0 else 'generated'\n",
        "        fig.suptitle('One vs. all PR & ROC curves for different types of substructures in model F (' \n",
        "                     + char + ' data)'\n",
        "                      # \\nStructural Similarity Index Measure: {:0.4f}'.format(ssim)\n",
        "                     )\n",
        "\n",
        "        # Different datasets\n",
        "        subfigs = fig.subfigures(2, 1)\n",
        "        colors = cycle(['r', 'g', 'b'])\n",
        "\n",
        "        # -----------------------------------------------------------------------------------------------------\n",
        "        if self.global_step > 0:\n",
        "            cake = []\n",
        "            for _ in range(self.hparams.num_classes):\n",
        "                cake.append(copy.deepcopy(orig))\n",
        "\n",
        "            for m, y0 in enumerate(labels):\n",
        "                for a, yn in enumerate(cake[int(y0)]):\n",
        "                    yn[m] = copy.deepcopy(fake[a][m])\n",
        "\n",
        "            cake.append(copy.deepcopy(fake))     \n",
        "\n",
        "        for a, src in enumerate(['F', 'J']):\n",
        "            output=[]\n",
        "            subfigs[a].suptitle('Classifier : model ' + src + ', Frechet Inception Distance : {:0.4f}'.format(Fid['LensGAN128/val/FID_'+ src]))\n",
        "            if self.global_step == 0:\n",
        "                ax = subfigs[a].subplots(1, 2, subplot_kw={'xlim': [-0.05,1.05], 'ylim': [-0.05,1.05], 'aspect': 1})\n",
        "                self.metrics.reset()\n",
        "                output.append(self.metrics(orig[a], labels))\n",
        "\n",
        "            else:\n",
        "                subsub = subfigs[a].subfigures(1, 2)\n",
        "                for x in cake:\n",
        "                    self.metrics.reset()\n",
        "                    output.append(self.metrics(x[a], labels))\n",
        "            \n",
        "            # Different curve types\n",
        "            for b in range(2):\n",
        "                if self.global_step == 0:\n",
        "                    self.curve_plot(ax[b], output, b, src, colors)\n",
        "                else:\n",
        "                    ax = subsub[b].subplots(2, 2, subplot_kw={'xlim': [-0.05,1.05], 'ylim': [-0.05,1.05], 'aspect': 1})\n",
        "                    for x in range(2):\n",
        "                        for y in range(2):\n",
        "                            self.curve_plot(ax[x, y], output, b, src, colors, int(str(x) + str(y), 2))\n",
        "\n",
        "        self.logger.experiment.add_figure('LensGAN128/LensResnet/val/PR_ROC', fig)\n",
        "        fig.savefig(str(self.trainer.log_dir) + '/PR_ROC_step_{:05d}.png'.format(self.global_step))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9biIaX6MJuO"
      },
      "source": [
        "# del m\n",
        "m = LensGAN128({'lr':0.001, 'n_fmaps': 64, 'bs': 8, 'latent_dim' : 512})\n",
        "print(m.generator, m.discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bta9qP9PwThP"
      },
      "source": [
        "## VAE\n",
        "Here we subclass a VAE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQqtxbYjwZUM"
      },
      "source": [
        "BEST_F_RESNET = '/content/drive/MyDrive/Logs/F/LensResnet/pbt_tanh/train_LensResnet_eb619_00000_0_2021-09-02_19-42-34/checkpoint_epoch=2-step=28124'\n",
        "BEST_J_RESNET = '/content/drive/MyDrive/Logs/J/LensResnet/pbt_tanh_fine/train_LensResnet_93609_00000_0_2021-09-02_21-06-00/checkpoint_epoch=2-step=28124'\n",
        "\n",
        "class LensVAE(VAE):\n",
        "    def __init__(self, config, num_classes: int = 3, **kwargs):\n",
        "        super().__init__(input_height=config['input_height'], latent_dim=config['latent_dim'], \n",
        "                         lr=config['lr'], first_conv=True, maxpool1=True, **kwargs)\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "\n",
        "        self.encoder.conv1 = nn.LazyConv2d(self.encoder.conv1.out_channels, 3 ,1, 1, bias=False)\n",
        "        self.decoder.conv1 = nn.LazyConv2d(1, 3 ,1, 1, bias=False)\n",
        "        self.decoder.linear = nn.LazyLinear(self.decoder.linear.out_features, False)\n",
        "\n",
        "        temp = LensResnet.load_from_checkpoint(os.path.join(BEST_F_RESNET, 'checkpoint'))\n",
        "        temp.freeze()\n",
        "        self.modelF = temp.backbone     # torch.load(PRE_F_RESNET, map_location=self.device).eval())\n",
        "        # Proper way to copy the last layer\n",
        "        self.lastF = self.modelF.fc\n",
        "        self.modelF.fc = nn.Identity()\n",
        "        \n",
        "        temp = LensResnet.load_from_checkpoint(os.path.join(BEST_J_RESNET, 'checkpoint'))\n",
        "        temp.freeze()\n",
        "        self.modelJ = temp.backbone     # torch.load(PRE_J_RESNET, map_location=self.device).eval())\n",
        "        # Proper way to copy the last layer\n",
        "        self.lastJ = self.modelJ.fc\n",
        "        self.modelJ.fc = nn.Identity()\n",
        "\n",
        "        self.imgMetrics = tm.MetricCollection(\n",
        "            {\n",
        "                'FID_F' : tm.FID(self.modelF),\n",
        "                'FID_J' : tm.FID(self.modelJ),\n",
        "            },\n",
        "            prefix='LensVAE/val/',\n",
        "        )\n",
        "\n",
        "        metrics = tm.MetricCollection(\n",
        "            [tm.PrecisionRecallCurve(self.hparams.num_classes), tm.ROC(self.hparams.num_classes),\n",
        "            tm.AveragePrecision(self.hparams.num_classes, average=None), tm.AUROC(self.hparams.num_classes, average=None)],\n",
        "        )\n",
        "        self.FMetrics = metrics.clone()\n",
        "        self.JMetrics = metrics.clone()\n",
        "    \n",
        "\n",
        "    def forward(self, y):\n",
        "        # x = self.encoder(x)\n",
        "        # mu = self.fc_mu(x)\n",
        "        # log_var = self.fc_var(x)\n",
        "        # _, _, z = self.sample(0, 1)\n",
        "        inp = torch.cat((F.one_hot(y, self.hparams.num_classes), \n",
        "                         torch.randn(len(y), self.latent_dim, device=self.device)), 1)\n",
        "        return self.decoder(inp)\n",
        "\n",
        "    def _run_step(self, x, y):\n",
        "        x = self.encoder(x)\n",
        "        mu = self.fc_mu(x)\n",
        "        log_var = self.fc_var(x)\n",
        "        p, q, z = self.sample(mu, log_var)\n",
        "        inp = torch.cat((F.one_hot(y, self.hparams.num_classes), z), 1)\n",
        "        return z, self.decoder(inp), p, q\n",
        "\n",
        "    def step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        z, x_hat, p, q = self._run_step(x, y)\n",
        "\n",
        "        recon_loss = F.mse_loss(x_hat, x, reduction=\"mean\")\n",
        "\n",
        "        kl = torch.distributions.kl_divergence(q, p)\n",
        "        kl = kl.mean()\n",
        "        kl *= self.kl_coeff\n",
        "\n",
        "        loss = kl + recon_loss\n",
        "\n",
        "        logs = {\n",
        "            \"recon_loss\": recon_loss,\n",
        "            \"kl\": kl,\n",
        "            \"loss\": loss,\n",
        "        }\n",
        "        return loss, logs\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        self.imgMetrics.update(imgs, real=True)\n",
        "        fake = F.interpolate(self(labels), 150).type_as(imgs)\n",
        "        self.imgMetrics.update(fake, real=False)\n",
        "        \n",
        "        if self.global_step == 0:\n",
        "            self.FMetrics.update(self.lastF(self.modelF(imgs)).softmax(1), labels)\n",
        "            self.JMetrics.update(self.lastJ(self.modelJ(imgs)).softmax(1), labels)\n",
        "        else:\n",
        "            self.FMetrics.update(self.lastF(self.modelF(fake)).softmax(1), labels)\n",
        "            self.JMetrics.update(self.lastJ(self.modelJ(fake)).softmax(1), labels)\n",
        "\n",
        "    def validation_epoch_end(self, ListofDicts):\n",
        "        # Classification scores\n",
        "        fid = self.imgMetrics.compute()\n",
        "        # self.log_dict(fid) isn't compatible with val_check_interval      \n",
        "        self.log_dict(self.imgMetrics)\n",
        "        \n",
        "        fig = plt.figure(constrained_layout=True, figsize=(10, 9))\n",
        "        # -----------------------------------------------------------------------------------------------------\n",
        "        if self.global_step == 0:\n",
        "            fig.suptitle('One vs. all PR & ROC curves for different types of substructures in model F (original data)')\n",
        "        else:\n",
        "            fig.suptitle('One vs. all PR & ROC curves for different types of substructures in model F (generated data)')\n",
        "        subfigs = fig.subfigures(2, 1)\n",
        "        colors = cycle(['r', 'g', 'b'])\n",
        "        \n",
        "        for a, src in enumerate(['F', 'J']):\n",
        "            if self.global_step == 0:\n",
        "                subfigs[a].suptitle('Classifier : model ' + src)\n",
        "            else:\n",
        "                subfigs[a].suptitle('Classifier : model ' + src + ', FID : {:0.2f}'.format(fid['LensVAE/val/FID_'+ src]))\n",
        "            ax = subfigs[a].subplots(1,2, subplot_kw={'xlim': [-0.05,1.05], 'ylim': [-0.05,1.05], 'aspect': 1})\n",
        "            \n",
        "            temp = getattr(self, src + 'Metrics')\n",
        "            Dict = temp.compute()\n",
        "            temp.reset()\n",
        "\n",
        "            key, val = list(Dict.keys()), list(Dict.values())\n",
        "            for b in range(2):\n",
        "                if key[b] != 'ROC':\n",
        "                    ax[b].plot([0, 1], [1/self.hparams.num_classes, 1/self.hparams.num_classes], 'k--')\n",
        "                else:\n",
        "                    ax[b].plot([0, 1], [0, 1], 'k--')\n",
        "                \n",
        "                prec_FPR, rec_TPR, _ = val[b]\n",
        "                for i, color, cls in zip(range(self.hparams.num_classes), colors, self.trainer.datamodule.val_set.classes):\n",
        "                    if key[b] != 'ROC':\n",
        "                        PrecisionRecallDisplay(prec_FPR[i].cpu(), rec_TPR[i].cpu(), val[2 + b][i], cls).plot(ax[b], c=color)\n",
        "                    else:\n",
        "                        RocCurveDisplay(prec_FPR[i].cpu(), rec_TPR[i].cpu(), val[2 + b][i], cls).plot(ax[b], c=color)\n",
        "                    \n",
        "                ax[b].legend(loc='best')\n",
        "                self.log('LensVAE/LensResnet(' + src + ')/val/' + key[2 + b], sum(val[2 + b])/len(val[2 + b]))\n",
        "\n",
        "        self.logger.experiment.add_figure('LensVAE/LensResnet/val/PR_ROC', fig)\n",
        "        fig.savefig(str(self.trainer.log_dir) + '/PR_ROC_step_{:05d}.png'.format(self.global_step))\n",
        "\n",
        "        # Save layer-wise activations\n",
        "        labels = torch.arange(self.hparams.num_classes, device=self.device)\n",
        "        imgs = self(labels)\n",
        "        # for lyr, img4d in enumerate(imgs[:-1]):\n",
        "        #     new = list(img4d)\n",
        "        #     for cls, filters3d in enumerate(new):\n",
        "        #         new[cls] = make_grid(filters3d.unsqueeze(1), nrow=int(np.ceil(np.sqrt(len(filters3d)))), normalize=True)\n",
        "        #         # print(three3d.shape)\n",
        "        #         # new[cls] = three3d[0].unsqueeze(0)\n",
        "        #         # print(new[cls].shape)\n",
        "\n",
        "        #     imgs[lyr] = F.interpolate(torch.stack(new), 150)\n",
        "        #     # print(imgs[lyr].shape)\n",
        "\n",
        "        # save_image(torch.cat(imgs[-2::-1]), \n",
        "        #         str(self.trainer.log_dir) + '/F_maps_step_{:05d}.png'.format(self.global_step), \n",
        "        #         #  kwargs for make_grid\n",
        "        #         nrow=self.hparams.num_classes, pad_value=0.5)\n",
        "        \n",
        "        # imgs = imgs[-1]\n",
        "        while len(labels) > 0:\n",
        "            x, y = self.trainer.datamodule.val_set[np.random.randint(0, len(self.trainer.datamodule.val_set))]\n",
        "            if y == labels[0]:\n",
        "                try:\n",
        "                    imgs = torch.cat((imgs, x.unsqueeze(0).type_as(imgs)))\n",
        "                except Exception as f:\n",
        "                    print(imgs.size(), x.size())\n",
        "                    raise Exception(f)\n",
        "                labels = labels[1:]\n",
        "\n",
        "        save_image(F.interpolate(imgs, 150), \n",
        "                str(self.trainer.log_dir) + '/Fake_step_{:05d}.png'.format(self.global_step), \n",
        "                #  kwargs for make_grid\n",
        "                nrow=self.hparams.num_classes, normalize=True, value_range=(-1,1), pad_value=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAZ6OaZfWSw1"
      },
      "source": [
        "config={'input_height': 128,\n",
        "        'latent_dim': 100,\n",
        "        'lr': 1e-3,\n",
        "        'bs': 8,\n",
        "        }\n",
        "m = LensVAE(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u1b8lr2puNw"
      },
      "source": [
        "## Stage 2\n",
        "Here we subclass a DCGAN to create our high resolution GAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMwzBib_zulo"
      },
      "source": [
        "class Generator2(nn.Module):\n",
        "    def __init__(self, ngf: int = 128, image_channels: int = 1, res_depth: int = 6):\n",
        "        super().__init__()\n",
        "\n",
        "        ker, strd = 4, 2\n",
        "        pad = int((ker - 2)/2)\n",
        "        res_ker, res_strd, res_pad = 3, 1, 1\n",
        "        \n",
        "        # 64 -> 32\n",
        "        self.preprocessing = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, ngf, ker, strd, pad, bias=False),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        # residuals\n",
        "        layer = []\n",
        "        for _ in range(res_depth):\n",
        "            layer.append(BasicBlock(ngf, ngf))\n",
        "        self.residual = nn.Sequential(*layer)\n",
        "        \n",
        "        self.ending_residual = nn.Sequential(\n",
        "            nn.Conv2d(ngf, ngf, res_ker, res_strd, res_pad, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        # at this part, add the residual inputs from after the preprocessing\n",
        "\n",
        "        image_width = 150 # upscaling should be factor of 2 increase\n",
        "        mode = 'nearest' # upscaling method is nearest-neighbour\n",
        "        self.main = nn.Sequential(\n",
        "            # 32 -> 75\n",
        "            nn.Upsample(image_width//2, mode=mode),\n",
        "            nn.Conv2d(ngf, ngf*4, res_ker, res_strd, res_pad, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(True),\n",
        "            # 75 -> 150\n",
        "            nn.Upsample(image_width, mode=mode),\n",
        "            nn.Conv2d(ngf*4, image_channels, res_ker, res_strd, res_pad, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, in_x):\n",
        "        x_p = self.preprocessing(in_x)\n",
        "        x_r = x_p\n",
        "        x_r = self.residual(x_r)\n",
        "        x_r = self.ending_residual(x_r)\n",
        "        # large residual connections\n",
        "        x_f = x_r + x_p\n",
        "        return self.main(x_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snK9DNDARgi7"
      },
      "source": [
        "BEST_F_LensGAN128 = '/content/drive/MyDrive/Logs/F/LensGAN128/pbt_tanh_1/train_LensGAN128_90727_00001_1_n_fmaps=16_2021-08-30_08-02-05/checkpoint_epoch=4-step=1988/'\n",
        "BEST_J_LensGAN128 ='/content/drive/MyDrive/Logs/J/LensGAN128/pbt_tanh/train_LensGAN128_28c03_00003_3_n_fmaps=64_2021-08-31_20-45-44/checkpoint_epoch=2-step=1403/'\n",
        "\n",
        "class Stage2(DCGAN):\n",
        "    def __init__(self, config, num_classes: int = 3, **kwargs):\n",
        "        super().__init__(feature_maps_gen=config['n_fmaps'], feature_maps_disc=config['n_fmaps'], learning_rate=config['learning_rate'])\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "\n",
        "        self.generator = Generator2(self.hparams.feature_maps_gen, self.hparams.image_channels, config['res_depth'])\n",
        "\n",
        "        # These are better as attributes, instead of being returned by a method\n",
        "        self.modelF = getattr(self, 'modelF', LensResnet.load_from_checkpoint(os.path.join(BEST_RESNET_F, 'checkpoint')).eval())\n",
        "        self.modelJ = getattr(self, 'modelJ', LensResnet.load_from_checkpoint(os.path.join(BEST_RESNET_J, 'checkpoint')).eval())\n",
        "        # Workaround:\n",
        "        self.lowres = getattr(self, 'lowres', LensGAN128.load_from_checkpoint(os.path.join(BEST_LensGAN128_F, 'checkpoint')).eval())\n",
        "        \n",
        "        metrics = tm.MetricCollection(\n",
        "            [\n",
        "             tm.AUROC(num_classes=self.hparams.num_classes, compute_on_step=False, average=None), \n",
        "             tm.ROC(num_classes=self.hparams.num_classes, compute_on_step=False),\n",
        "            ]\n",
        "        )\n",
        "        self.metricsF = metrics.clone()\n",
        "        self.metricsJ = metrics.clone()\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.generator(noise)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        real, self.labels = batch\n",
        "\n",
        "        # Train discriminator\n",
        "        result = None\n",
        "        if optimizer_idx == 0:\n",
        "            result = self._disc_step(real)\n",
        "\n",
        "        # Train generator\n",
        "        if optimizer_idx == 1:\n",
        "            result = self._gen_step(real)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _disc_step(self, real):\n",
        "        disc_loss = self._get_disc_loss(real)\n",
        "        self.log('Stage2/D/train/loss', disc_loss, on_epoch=True)\n",
        "        return disc_loss\n",
        "\n",
        "    def _gen_step(self, real):\n",
        "        gen_loss = self._get_gen_loss(real)\n",
        "        self.log('Stage2/G/train/loss', gen_loss, on_epoch=True)\n",
        "        return gen_loss\n",
        "\n",
        "    def _get_gen_loss(self, real: torch.Tensor) -> torch.Tensor:\n",
        "        # Train with fake\n",
        "        fake_pred = self._get_fake_pred(real)\n",
        "        fake_gt = torch.ones_like(fake_pred)\n",
        "        gen_loss = self.criterion(fake_pred, fake_gt)\n",
        "\n",
        "        # class_pred =  self._get_class_pred(len(real))\n",
        "        # gen_loss += F.cross_entropy(class_pred, self.labels)\n",
        "\n",
        "        return gen_loss\n",
        "\n",
        "    def _get_class_pred(self, batch_size) -> torch.Tensor:\n",
        "        # ----------------------------------------------------------------------------------------------------------------\n",
        "        return self.modelF.backbone(self(self._get_noise(batch_size, self.hparams.latent_dim)))\n",
        "\n",
        "    def _get_noise(self, n_samples: int, latent_dim: int, labels = None):\n",
        "        # can't use self in function definition\n",
        "        if labels is None:\n",
        "            labels = self.labels\n",
        "            # getattr(self, 'labels', torch.randint(self.hparams.num_classes, (n_samples,), device=self.device))  # last dimension is the hidden dimension\n",
        "        return self.lowres(super()._get_noise(n_samples, latent_dim), labels)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        out = self(self._get_noise(labels.shape[0], self.hparams.latent_dim, labels))\n",
        "        self.metricsF.update(self.modelF(out), labels)\n",
        "        self.metricsJ.update(self.modelJ(out), labels)\n",
        "\n",
        "    def validation_epoch_end(self, listofDicts):\n",
        "        fig, ax = plt.subplots(1,2, \n",
        "            subplot_kw={'xlim': [0,1], 'xlabel': 'False Positive Rate', 'ylim': [0,1.05], \n",
        "                        'ylabel': 'True Positive Rate',\n",
        "            },\n",
        "            figsize=[11, 5],\n",
        "        )\n",
        "        for j, letter in enumerate(['F', 'J']):\n",
        "            output = getattr(self, 'metrics' + letter).compute()\n",
        "            self.log('Stage2/ResNet(' + letter + ')/val/auroc', output['AUROC'].min())\n",
        "            fprList, tprList, _ = output['ROC']\n",
        "            \n",
        "            colors = cycle(['red', 'blue', 'green'])\n",
        "            for i, color in zip(range(self.hparams.num_classes), colors):\n",
        "                ax[j].plot(fprList[i].cpu(), tprList[i].cpu(), color=color,\n",
        "                        label='ROC curve of class {0} (area = {1:0.4f})'\n",
        "                        ''.format(i, output['AUROC'][i]))\n",
        "            post_plotting(ax[j])\n",
        "            ax[j].set_title('One vs. all ROC curve (' + letter + ')')\n",
        "        \n",
        "        fig.tight_layout()\n",
        "        self.logger.experiment.add_figure('Stage2/ResNet/val/ROC', fig)\n",
        "        fig.savefig(str(self.trainer.log_dir) + '/ROC_step_{:05d}.png'.format(self.global_step))\n",
        "\n",
        "        labels = torch.arange(self.hparams.num_classes, device=self.device)\n",
        "        save_image(self(self._get_noise(labels.shape[0], self.hparams.latent_dim, labels)), \n",
        "                   str(self.trainer.log_dir) + '/Fake_step_{:05d}.png'.format(self.global_step), \n",
        "                  #  kwargs for make_grid\n",
        "                   normalize=True, value_range=(-1,1))\n",
        "\n",
        "    def on_fit_end(self):\n",
        "        delattr(self, 'modelF')\n",
        "        delattr(self, 'modelJ')\n",
        "        delattr(self, 'labels')\n",
        "        delattr(self, 'lowres')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0XraYESGws1"
      },
      "source": [
        "# Tune Hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbXpnU7Y4Cr9"
      },
      "source": [
        "## ResNet\n",
        "Here we tune hyperparameters as we train our modified ResNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otF0QlxlGsZs"
      },
      "source": [
        "%rm -rf /content/drive/MyDrive/Logs/fakeF/PGAN/LensResnet/pbt_tanh_validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOMd0E5Q9mkw"
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_LensResnet(config, checkpoint_dir=None, num_epochs=10, num_gpus=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    kwargs = {\n",
        "        # 'limit_train_batches' : 0.005,\n",
        "        # 'limit_val_batches' : 0.005,\n",
        "        'progress_bar_refresh_rate' : int(8250//int(2**np.rint(config['bs']))),\n",
        "        'max_epochs' : num_epochs,\n",
        "        'prepare_data_per_node' : False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        'gpus' : int(num_gpus),\n",
        "        'logger' : TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        'callbacks' : [\n",
        "            TuneReportCheckpointCallback(\n",
        "                {\n",
        "                    'loss': 'LensResnet/val/loss', \n",
        "                    'auroc': 'LensResnet/val/AUROC', \n",
        "                    'ap' : 'LensResnet/val/AveragePrecision',\n",
        "                },\n",
        "            ),\n",
        "            ModuleDataMonitor(['backbone.layer2', 'backbone.layer4', 'backbone.fc']),\n",
        "            ConfusedLogitCallback(5),\n",
        "        ],\n",
        "        'stochastic_weight_avg' : True,\n",
        "        # works with only one optimizer\n",
        "        'benchmark' : True,\n",
        "        'precision' : 16,     # can't use on cpu\n",
        "        # 'track_grad_norm': 2,\n",
        "        # 'gradient_clip_val' : 0.5, \n",
        "        # 'gradient_clip_algorithm' : 'value',\n",
        "    }\n",
        "    \n",
        "    dm = npyImageData(config)                                              # Specify image width here    \n",
        "    if checkpoint_dir is not None:\n",
        "        kwargs['resume_from_checkpoint'] = os.path.join(checkpoint_dir, 'checkpoint')\n",
        "        # model = LensResnet.load_from_checkpoint(kwargs['resume_from_checkpoint'], config=config)\n",
        "    # else:\n",
        "\n",
        "    model = LensResnet(config)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_LensResnet_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_LensResnet,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial\n",
        "        ),\n",
        "        # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "        name='J/LensResnet/pbt_tanh_fine',\n",
        "        metric='loss',\n",
        "        mode='min',\n",
        "        # stop=TrialPlateauStopper('auroc'),\n",
        "        resources_per_trial={'cpu': os.cpu_count(), 'gpu': gpus_per_trial},\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        # config={'lr': tune.choice([1e-4, 1e-3, 1e-5, 1e-2, 1e-6, 1e-1, 1e-7]),\n",
        "        #         'bs': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "        #         },\n",
        "        # scheduler = pbtScheduler(max_t=num_epochs, grace_period=2, reduction_factor=2),\n",
        "        # Can't use RB2 as it requires mutations to be continuous\n",
        "        config={'lr': 1e-5,\n",
        "                'bs': 8,\n",
        "                # RuntimeError: stack expects each tensor to be equal size, but got [128] at entry 0 and [120] at entry 585\n",
        "                },\n",
        "        scheduler = PopulationBasedTraining(time_attr='training_iteration', quantile_fraction=0.4,\n",
        "                                            resample_probability=0.2,  perturbation_interval=1,\n",
        "                                            hyperparam_mutations={\n",
        "                                                'lr': tune.loguniform(1e-6, 1e-4),\n",
        "                                                'bs': [8, 16, 32, 64, 128],\n",
        "                                            },\n",
        "        ),\n",
        "        progress_reporter=JupyterNotebookReporter(\n",
        "            overwrite=False,\n",
        "            parameter_columns=['lr', 'bs'],\n",
        "            metric_columns=['loss', 'auroc', 'ap', 'training_iteration'],\n",
        "        ),\n",
        "        fail_fast = True,\n",
        "        # reuse_actors=True,\n",
        "        num_samples=num_samples,\n",
        "        # resume='PROMPT',\n",
        "    )\n",
        "    BEST_J_RESNET = analysis.best_checkpoint\n",
        "    print('Best checkpoint path found is: ', BEST_J_RESNET)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_LensResnet_pbt(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # pbt scheduler\n",
        "        tune_LensResnet_pbt(num_samples=1, num_epochs=5, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPxU2-AggCrI"
      },
      "source": [
        "## LensGAN128\n",
        "Here we tune hyperparameters as we train our modified DCGAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr0jbpHhgs79"
      },
      "source": [
        "%rm -rf drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz_mb3SxcDnF",
        "outputId": "25375dc7-ae3b-490b-e2cb-c7591b091656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_LensGAN128(config, checkpoint_dir=None, num_steps=2, num_gpus=torch.cuda.device_count()):\n",
        "    dm = npyImageData(config)                                              # Specify image width here\n",
        "    model = LensGAN128(config, latent_dim=512)\n",
        "    trainer = pl.Trainer(\n",
        "        # detect_anomaly=True,\n",
        "        # limit_train_batches=0.10, limit_val_batches=0.10,\n",
        "        # val_check_interval=0.10, \n",
        "        track_grad_norm=2,\n",
        "        num_sanity_val_steps=10, max_epochs=num_steps,\n",
        "        # prepare_data_per_node=False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        gpus=int(num_gpus), logger=TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        callbacks=[\n",
        "            TuneReportCheckpointCallback(\n",
        "                {\n",
        "                    # 'loss_G': 'LensGAN128/G/train/loss', \n",
        "                    # 'fake_G' : 'LensGAN128/G/train/loss/fake', \n",
        "                    # 'CE_G' : 'LensGAN128/G/train/loss/class', \n",
        "                    # 'ssim_G' : 'LensGAN128/G/train/loss/ssim',\n",
        "                    # 'mse_G' : 'LensGAN128/G/train/loss/mse',\n",
        "                    # 'loss_D': 'LensGAN128/D/train/loss', \n",
        "                    # 'real_D' : 'LensGAN128/D/train/loss/real', \n",
        "                    # 'fake_D' : 'LensGAN128/D/train/loss/fake', \n",
        "                    # 'CE_D' : 'LensGAN128/D/train/loss/class', \n",
        "                    # 'gp_D' : 'LensGAN128/D/train/loss/gp',\n",
        "                    # Switch up the FID vlues when training on different dataset -----------------------------------------------\n",
        "                    'FID_F' : 'LensGAN128/val/FID_F', \n",
        "                    'FID_J' : 'LensGAN128/val/FID_J',\n",
        "                    # 'ssim' : 'LensGAN128/val/ssim',\n",
        "                    'auroc_F' : 'LensGAN128/LensResnet(F)/val/AUROC',\n",
        "                    'auroc_J' : 'LensGAN128/LensResnet(J)/val/AUROC',\n",
        "                    'ap_F' : 'LensGAN128/LensResnet(F)/val/AveragePrecision',\n",
        "                    'ap_J' : 'LensGAN128/LensResnet(J)/val/AveragePrecision'\n",
        "                },\n",
        "                # Validation end is better, resumes with updated checkpoint\n",
        "                # on='train_end',\n",
        "            ),\n",
        "            ModuleDataMonitor(True),\n",
        "            TQDMProgressBar(refresh_rate=int(7500//int(2**np.rint(config['bs'])))),\n",
        "        ],\n",
        "        # stochastic_weight_avg=True,\n",
        "        # works with only one optimizer\n",
        "        benchmark=True, \n",
        "        precision=16,\n",
        "    )\n",
        "    \n",
        "    loc = os.path.join(checkpoint_dir, 'checkpoint') if checkpoint_dir is not None else None\n",
        "    trainer.fit(model, dm, ckpt_path=loc)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_LensGAN128_pbt(num_samples=10, num_steps=2, gpus_per_trial=torch.cuda.device_count()):\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_LensGAN128,\n",
        "            num_steps=num_steps,\n",
        "            num_gpus=gpus_per_trial\n",
        "        ),\n",
        "        # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "        name='F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128', \n",
        "        metric='auroc_F',\n",
        "        mode='max',\n",
        "        resources_per_trial={'cpu': os.cpu_count(), 'gpu': gpus_per_trial},\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        config={'lr': -3,\n",
        "                'n_fmaps': 128,\n",
        "                'bs': 3,\n",
        "                },\n",
        "        scheduler = PB2('training_iteration', quantile_fraction=0.25, perturbation_interval=1,\n",
        "                            # resample_probability=0.25,  \n",
        "                            hyperparam_bounds={\n",
        "                                'lr': [-6, -3],  #tune.loguniform(1e-5, 1e-3),\n",
        "                                'bs': [3, 7],    #[8, 16, 32, 64, 128],\n",
        "                            },\n",
        "        ),\n",
        "        progress_reporter=JupyterNotebookReporter(\n",
        "            overwrite=False,\n",
        "            parameter_columns=['lr', 'n_fmaps', 'bs'],\n",
        "            metric_columns=['FID_F', 'auroc_F', 'ap_F', \n",
        "                            # 'FID_J', 'auroc_J', 'ap_J', \n",
        "                            'training_iteration',\n",
        "                            # 'ssim_G', 'fake_G', 'CE_G', 'real_D', 'fake_D', 'CE_D', \n",
        "                            #'mse_G', 'gp_D',\n",
        "                            ],\n",
        "            max_report_frequency=300,\n",
        "        ),\n",
        "        fail_fast = True,\n",
        "        reuse_actors=True,\n",
        "        num_samples=num_samples,\n",
        "        resume=True,\n",
        "    )\n",
        "    print('Best checkpoint path found is: ', analysis.best_checkpoint)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    ray._private.utils.get_system_memory = lambda: psutil.virtual_memory().total\n",
        "    PL_FAULT_TOLERANT_TRAINING=1\n",
        "    if args.smoke_test:\n",
        "        tune_LensGAN128_pbt(num_samples=1, num_steps=10, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # pbt scheduler\n",
        "        tune_LensGAN128_pbt(num_samples=1, num_steps=10, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>pre{white-space: pre-wrap;}</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-24 01:36:08,469\tWARNING trial_runner.py:646 -- Attempting to resume experiment from /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128. This will ignore any new changes to the specification.\n",
            "2022-05-24 01:36:08,495\tINFO tune.py:605 -- TrialRunner resumed, ignoring new add_experiment but updating trial resources.\n",
            "2022-05-24 01:36:08,684\tINFO trial_runner.py:803 -- starting train_LensGAN128_52f0b_00000\n",
            "2022-05-24 01:36:11,085\tINFO trainable.py:93 -- Checkpoint size is 274857457 bytes\n",
            "2022-05-24 01:36:11,511\tWARNING util.py:171 -- The `start_trial` operation took 2.818 s, which may be a performance bottleneck.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 01:36:11 (running for 00:00:03.04)<br>Memory usage on this node: 6.2/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.5918898582458496 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">   ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:1455</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 191.25</td><td style=\"text-align: right;\">  0.59189</td><td style=\"text-align: right;\">0.51623</td><td style=\"text-align: right;\">                   3</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 2022-05-24 01:36:17,780\tINFO trainable.py:535 -- Restored on 172.28.0.2 from checkpoint: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128/train_LensGAN128_52f0b_00000_0_2022-05-24_00-27-42/checkpoint_tmp0a4be0/./\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 2022-05-24 01:36:17,781\tINFO trainable.py:543 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 3748.126875400543, '_episodes_total': None}\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `FrechetInceptionDistance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m Using 16bit native Automatic Mixed Precision (AMP)\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m GPU available: True, used: True\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:336: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   \"The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7.\"\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:348: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   \"The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\"\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:377: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:377: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:386: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:386: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128/train_LensGAN128_52f0b_00000_0_2022-05-24_00-27-42/./checkpoints exists and is not empty.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m Restoring states from the checkpoint path at /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128/train_LensGAN128_52f0b_00000_0_2022-05-24_00-27-42/checkpoint_tmp0a4be0/./checkpoint\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   | Name          | Type               | Params\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 0 | generator     | DCGANGenerator     | 19.4 M\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 1 | discriminator | DCGANDiscriminator | 16.3 M\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 2 | criterion     | BCEWithLogitsLoss  | 0     \n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 3 | modelF        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 4 | lastF         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 5 | modelJ        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 6 | lastJ         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 7 | imgMetrics    | MetricCollection   | 22.3 M\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 8 | metrics       | MetricCollection   | 0     \n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 35.7 M    Trainable params\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 22.3 M    Non-trainable params\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 58.0 M    Total params\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m 116.048   Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m Restored all states from the checkpoint file at /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128/train_LensGAN128_52f0b_00000_0_2022-05-24_00-27-42/checkpoint_tmp0a4be0/./checkpoint\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:490: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m   category=PossibleUserWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2:   0%|          | 0/10313 [00:00<00:00, -45616705.34it/s]  \n",
            "Epoch 2:   0%|          | 0/10313 [00:00<00:00, -49088.19it/s, loss=nan, v_num=.]\n",
            "Epoch 3:   0%|          | 0/10313 [00:00<00:00, -28976860.72it/s, loss=nan, v_num=.]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m E0524 01:38:22.280083813    3301 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 3:   9%|         | 937/10313 [04:09<-1:55:23, -33.80it/s, loss=nan, v_num=.] \rEpoch 3:   9%|         | 937/10313 [04:09<-1:55:23, -33.80it/s, loss=nan, v_num=.]\rEpoch 3:   9%|         | 937/10313 [04:09<-1:55:23, -33.80it/s, loss=2.13, v_num=., loss_G_fake=0.694, loss_G_class=1.080, loss_G_ssim=0.274, loss_G=2.050, loss_D_real=0.429, loss_D_fake=0.693, loss_D_class=1.120, loss_D=2.240]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 01:41:13 (running for 00:05:05.27)<br>Memory usage on this node: 4.8/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.5918898582458496 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">   ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:1455</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 191.25</td><td style=\"text-align: right;\">  0.59189</td><td style=\"text-align: right;\">0.51623</td><td style=\"text-align: right;\">                   3</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 3:  18%|        | 1874/10313 [08:34<-1:50:22, -14.59it/s, loss=2.13, v_num=., loss_G_fake=0.694, loss_G_class=1.080, loss_G_ssim=0.274, loss_G=2.050, loss_D_real=0.429, loss_D_fake=0.693, loss_D_class=1.120, loss_D=2.240]\rEpoch 3:  18%|        | 1874/10313 [08:34<-1:50:22, -14.59it/s, loss=2.13, v_num=., loss_G_fake=0.694, loss_G_class=1.080, loss_G_ssim=0.274, loss_G=2.050, loss_D_real=0.429, loss_D_fake=0.693, loss_D_class=1.120, loss_D=2.240]\rEpoch 3:  18%|        | 1874/10313 [08:34<-1:50:22, -14.59it/s, loss=2.03, v_num=., loss_G_fake=0.730, loss_G_class=1.140, loss_G_ssim=0.452, loss_G=2.320, loss_D_real=0.163, loss_D_fake=0.687, loss_D_class=1.160, loss_D=2.010]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 01:46:14 (running for 00:10:06.27)<br>Memory usage on this node: 6.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.5918898582458496 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">   ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:1455</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 191.25</td><td style=\"text-align: right;\">  0.59189</td><td style=\"text-align: right;\">0.51623</td><td style=\"text-align: right;\">                   3</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 3:  27%|       | 2811/10313 [12:46<-1:45:24, -8.56it/s, loss=2.03, v_num=., loss_G_fake=0.730, loss_G_class=1.140, loss_G_ssim=0.452, loss_G=2.320, loss_D_real=0.163, loss_D_fake=0.687, loss_D_class=1.160, loss_D=2.010] \rEpoch 3:  27%|       | 2811/10313 [12:46<-1:45:24, -8.56it/s, loss=2.03, v_num=., loss_G_fake=0.730, loss_G_class=1.140, loss_G_ssim=0.452, loss_G=2.320, loss_D_real=0.163, loss_D_fake=0.687, loss_D_class=1.160, loss_D=2.010]\rEpoch 3:  27%|       | 2811/10313 [12:46<-1:45:24, -8.56it/s, loss=2.13, v_num=., loss_G_fake=0.643, loss_G_class=1.100, loss_G_ssim=0.207, loss_G=1.950, loss_D_real=0.415, loss_D_fake=0.769, loss_D_class=1.100, loss_D=2.290]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 01:51:15 (running for 00:15:07.11)<br>Memory usage on this node: 6.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.5918898582458496 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">   ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:1455</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 191.25</td><td style=\"text-align: right;\">  0.59189</td><td style=\"text-align: right;\">0.51623</td><td style=\"text-align: right;\">                   3</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 3:  36%|      | 3748/10313 [16:44<-1:40:28, -5.60it/s, loss=2.13, v_num=., loss_G_fake=0.643, loss_G_class=1.100, loss_G_ssim=0.207, loss_G=1.950, loss_D_real=0.415, loss_D_fake=0.769, loss_D_class=1.100, loss_D=2.290]\rEpoch 3:  36%|      | 3748/10313 [16:44<-1:40:28, -5.60it/s, loss=2.13, v_num=., loss_G_fake=0.643, loss_G_class=1.100, loss_G_ssim=0.207, loss_G=1.950, loss_D_real=0.415, loss_D_fake=0.769, loss_D_class=1.100, loss_D=2.290]\rEpoch 3:  36%|      | 3748/10313 [16:44<-1:40:28, -5.60it/s, loss=2.06, v_num=., loss_G_fake=0.715, loss_G_class=1.090, loss_G_ssim=0.171, loss_G=1.980, loss_D_real=0.381, loss_D_fake=0.665, loss_D_class=1.090, loss_D=2.140]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 01:56:16 (running for 00:20:08.01)<br>Memory usage on this node: 6.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.5918898582458496 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">   ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:1455</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 191.25</td><td style=\"text-align: right;\">  0.59189</td><td style=\"text-align: right;\">0.51623</td><td style=\"text-align: right;\">                   3</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 3:  45%|     | 4685/10313 [20:48<-1:35:02, -3.76it/s, loss=2.06, v_num=., loss_G_fake=0.715, loss_G_class=1.090, loss_G_ssim=0.171, loss_G=1.980, loss_D_real=0.381, loss_D_fake=0.665, loss_D_class=1.090, loss_D=2.140]\rEpoch 3:  45%|     | 4685/10313 [20:48<-1:35:02, -3.76it/s, loss=2.06, v_num=., loss_G_fake=0.715, loss_G_class=1.090, loss_G_ssim=0.171, loss_G=1.980, loss_D_real=0.381, loss_D_fake=0.665, loss_D_class=1.090, loss_D=2.140]\rEpoch 3:  45%|     | 4685/10313 [20:48<-1:35:02, -3.76it/s, loss=2.02, v_num=., loss_G_fake=0.717, loss_G_class=1.150, loss_G_ssim=0.188, loss_G=2.050, loss_D_real=0.212, loss_D_fake=0.671, loss_D_class=1.150, loss_D=2.030]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 02:01:17 (running for 00:25:08.89)<br>Memory usage on this node: 6.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.5918898582458496 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">   ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:1455</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 191.25</td><td style=\"text-align: right;\">  0.59189</td><td style=\"text-align: right;\">0.51623</td><td style=\"text-align: right;\">                   3</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3:  55%|    | 5622/10313 [24:52<-1:28:55, -2.51it/s, loss=2.13, v_num=., loss_G_fake=0.683, loss_G_class=1.030, loss_G_ssim=0.236, loss_G=1.950, loss_D_real=0.433, loss_D_fake=0.706, loss_D_class=1.170, loss_D=2.310]\n",
            "Epoch 3:  64%|   | 6559/10313 [28:55<-1:21:26, -1.62it/s, loss=2.12, v_num=., loss_G_fake=0.655, loss_G_class=1.090, loss_G_ssim=0.201, loss_G=1.940, loss_D_real=0.441, loss_D_fake=0.713, loss_D_class=1.100, loss_D=2.250]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 02:06:18 (running for 00:30:09.84)<br>Memory usage on this node: 6.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.5918898582458496 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">   ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:1455</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 191.25</td><td style=\"text-align: right;\">  0.59189</td><td style=\"text-align: right;\">0.51623</td><td style=\"text-align: right;\">                   3</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 3:  73%|  | 7496/10313 [32:49<-1:10:47, -0.95it/s, loss=2.12, v_num=., loss_G_fake=0.655, loss_G_class=1.090, loss_G_ssim=0.201, loss_G=1.940, loss_D_real=0.441, loss_D_fake=0.713, loss_D_class=1.100, loss_D=2.250]\rEpoch 3:  73%|  | 7496/10313 [32:49<-1:10:47, -0.95it/s, loss=2.12, v_num=., loss_G_fake=0.655, loss_G_class=1.090, loss_G_ssim=0.201, loss_G=1.940, loss_D_real=0.441, loss_D_fake=0.713, loss_D_class=1.100, loss_D=2.250]\rEpoch 3:  73%|  | 7496/10313 [32:49<-1:10:47, -0.95it/s, loss=2.12, v_num=., loss_G_fake=0.643, loss_G_class=1.100, loss_G_ssim=0.138, loss_G=1.880, loss_D_real=0.477, loss_D_fake=0.758, loss_D_class=1.100, loss_D=2.330]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 02:11:19 (running for 00:35:10.85)<br>Memory usage on this node: 6.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.5918898582458496 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">   ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:1455</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 191.25</td><td style=\"text-align: right;\">  0.59189</td><td style=\"text-align: right;\">0.51623</td><td style=\"text-align: right;\">                   3</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 3:  82%| | 8433/10313 [36:53<-2:46:23, -0.43it/s, loss=2.12, v_num=., loss_G_fake=0.643, loss_G_class=1.100, loss_G_ssim=0.138, loss_G=1.880, loss_D_real=0.477, loss_D_fake=0.758, loss_D_class=1.100, loss_D=2.330]\rEpoch 3:  82%| | 8433/10313 [36:53<-2:46:23, -0.43it/s, loss=2.12, v_num=., loss_G_fake=0.643, loss_G_class=1.100, loss_G_ssim=0.138, loss_G=1.880, loss_D_real=0.477, loss_D_fake=0.758, loss_D_class=1.100, loss_D=2.330]\rEpoch 3:  82%| | 8433/10313 [36:53<-2:46:23, -0.43it/s, loss=2.11, v_num=., loss_G_fake=0.643, loss_G_class=1.100, loss_G_ssim=0.107, loss_G=1.850, loss_D_real=0.470, loss_D_fake=0.716, loss_D_class=1.110, loss_D=2.290]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 02:16:20 (running for 00:40:11.86)<br>Memory usage on this node: 6.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.5918898582458496 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">   ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:1455</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 191.25</td><td style=\"text-align: right;\">  0.59189</td><td style=\"text-align: right;\">0.51623</td><td style=\"text-align: right;\">                   3</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3:  91%| | 9370/10313 [40:56<-129:18:01, -0.00it/s, loss=2.09, v_num=., loss_G_fake=0.618, loss_G_class=1.010, loss_G_ssim=0.197, loss_G=1.830, loss_D_real=0.444, loss_D_fake=0.791, loss_D_class=1.060, loss_D=2.300]\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \n",
            "Validation:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100%|| 10307/10313 [41:52<00:16,  2.70s/it, loss=2.09, v_num=., loss_G_fake=0.618, loss_G_class=1.010, loss_G_ssim=0.197, loss_G=1.830, loss_D_real=0.444, loss_D_fake=0.791, loss_D_class=1.060, loss_D=2.300]\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \n",
            "Validation DataLoader 0: 100%|| 937/938 [00:55<00:00, 16.83it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|| 937/938 [00:55<00:00, 16.83it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \n",
            "Epoch 3: 100%|| 10313/10313 [41:53<00:00,  2.68s/it, loss=2.09, v_num=., loss_G_fake=0.618, loss_G_class=1.010, loss_G_ssim=0.197, loss_G=1.830, loss_D_real=0.444, loss_D_fake=0.791, loss_D_class=1.060, loss_D=2.300]\n",
            "Result for train_LensGAN128_52f0b_00000:\n",
            "  FID_F: 74.625\n",
            "  FID_J: 86.125\n",
            "  ap_F: 0.1975068897008896\n",
            "  ap_J: 0.42189523577690125\n",
            "  auroc_F: 0.07554253935813904\n",
            "  auroc_J: 0.35721075534820557\n",
            "  date: 2022-05-24_02-18-43\n",
            "  done: false\n",
            "  experiment_id: 152d034e835a4eb783ed5470faa95a27\n",
            "  hostname: c8992defe8a4\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3261\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 2545.7579555511475\n",
            "  time_this_iter_s: 2545.7579555511475\n",
            "  time_total_s: 6293.884830951691\n",
            "  timestamp: 1653358723\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 4\n",
            "  trial_id: 52f0b_00000\n",
            "  warmup_time: 1.2876198291778564\n",
            "  \n",
            "Epoch 3: 100%|| 10313/10313 [42:04<00:00,  2.69s/it, loss=2.11, v_num=., loss_G_fake=0.686, loss_G_class=1.080, loss_G_ssim=0.195, loss_G=1.960, loss_D_real=0.478, loss_D_fake=0.695, loss_D_class=1.100, loss_D=2.280]\n",
            "Epoch 3: 100%|| 10313/10313 [42:04<00:00,  2.69s/it, loss=2.11, v_num=., loss_G_fake=0.686, loss_G_class=1.080, loss_G_ssim=0.195, loss_G=1.960, loss_D_real=0.478, loss_D_fake=0.695, loss_D_class=1.100, loss_D=2.280]\n",
            "Epoch 4:   0%|          | 0/10313 [00:00<00:00, -30154601.23it/s, loss=2.11, v_num=., loss_G_fake=0.686, loss_G_class=1.080, loss_G_ssim=0.195, loss_G=1.960, loss_D_real=0.478, loss_D_fake=0.695, loss_D_class=1.100, loss_D=2.280] \n",
            "Epoch 4:   0%|          | 0/10313 [00:10<-1:59:48, -854.32it/s, loss=2.11, v_num=., loss_G_fake=0.686, loss_G_class=1.080, loss_G_ssim=0.195, loss_G=1.960, loss_D_real=0.478, loss_D_fake=0.695, loss_D_class=1.100, loss_D=2.280]  \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 02:21:24 (running for 00:45:15.68)<br>Memory usage on this node: 6.2/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.07554253935813904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 74.625</td><td style=\"text-align: right;\">0.0755425</td><td style=\"text-align: right;\">0.197507</td><td style=\"text-align: right;\">                   4</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 4:   9%|         | 937/10313 [03:57<-1:55:37, -35.57it/s, loss=2.11, v_num=., loss_G_fake=0.686, loss_G_class=1.080, loss_G_ssim=0.195, loss_G=1.960, loss_D_real=0.478, loss_D_fake=0.695, loss_D_class=1.100, loss_D=2.280]\rEpoch 4:   9%|         | 937/10313 [03:57<-1:55:37, -35.57it/s, loss=2.11, v_num=., loss_G_fake=0.686, loss_G_class=1.080, loss_G_ssim=0.195, loss_G=1.960, loss_D_real=0.478, loss_D_fake=0.695, loss_D_class=1.100, loss_D=2.280]\rEpoch 4:   9%|         | 937/10313 [03:57<-1:55:37, -35.57it/s, loss=2.07, v_num=., loss_G_fake=0.586, loss_G_class=1.130, loss_G_ssim=0.172, loss_G=1.890, loss_D_real=0.381, loss_D_fake=0.881, loss_D_class=1.170, loss_D=2.430]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 02:26:25 (running for 00:50:16.67)<br>Memory usage on this node: 6.2/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.07554253935813904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 74.625</td><td style=\"text-align: right;\">0.0755425</td><td style=\"text-align: right;\">0.197507</td><td style=\"text-align: right;\">                   4</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4:  18%|        | 1874/10313 [08:01<-1:50:59, -15.58it/s, loss=2.1, v_num=., loss_G_fake=0.652, loss_G_class=1.110, loss_G_ssim=0.114, loss_G=1.880, loss_D_real=0.421, loss_D_fake=0.776, loss_D_class=1.130, loss_D=2.320] \n",
            "Epoch 4:  27%|       | 2811/10313 [12:06<-1:46:10, -9.04it/s, loss=2.07, v_num=., loss_G_fake=0.609, loss_G_class=1.110, loss_G_ssim=0.177, loss_G=1.900, loss_D_real=0.312, loss_D_fake=0.883, loss_D_class=1.110, loss_D=2.310]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 02:31:26 (running for 00:55:17.69)<br>Memory usage on this node: 6.3/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.07554253935813904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 74.625</td><td style=\"text-align: right;\">0.0755425</td><td style=\"text-align: right;\">0.197507</td><td style=\"text-align: right;\">                   4</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 4:  36%|      | 3748/10313 [16:00<-1:41:20, -5.86it/s, loss=2.07, v_num=., loss_G_fake=0.609, loss_G_class=1.110, loss_G_ssim=0.177, loss_G=1.900, loss_D_real=0.312, loss_D_fake=0.883, loss_D_class=1.110, loss_D=2.310]\rEpoch 4:  36%|      | 3748/10313 [16:00<-1:41:20, -5.86it/s, loss=2.07, v_num=., loss_G_fake=0.609, loss_G_class=1.110, loss_G_ssim=0.177, loss_G=1.900, loss_D_real=0.312, loss_D_fake=0.883, loss_D_class=1.110, loss_D=2.310]\rEpoch 4:  36%|      | 3748/10313 [16:00<-1:41:20, -5.86it/s, loss=2.07, v_num=., loss_G_fake=0.669, loss_G_class=1.100, loss_G_ssim=0.111, loss_G=1.880, loss_D_real=0.371, loss_D_fake=0.740, loss_D_class=1.100, loss_D=2.210]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 02:36:27 (running for 01:00:18.69)<br>Memory usage on this node: 6.3/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.07554253935813904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 74.625</td><td style=\"text-align: right;\">0.0755425</td><td style=\"text-align: right;\">0.197507</td><td style=\"text-align: right;\">                   4</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 4:  45%|     | 4685/10313 [20:05<-1:35:54, -3.89it/s, loss=2.07, v_num=., loss_G_fake=0.669, loss_G_class=1.100, loss_G_ssim=0.111, loss_G=1.880, loss_D_real=0.371, loss_D_fake=0.740, loss_D_class=1.100, loss_D=2.210]\rEpoch 4:  45%|     | 4685/10313 [20:05<-1:35:54, -3.89it/s, loss=2.07, v_num=., loss_G_fake=0.669, loss_G_class=1.100, loss_G_ssim=0.111, loss_G=1.880, loss_D_real=0.371, loss_D_fake=0.740, loss_D_class=1.100, loss_D=2.210]\rEpoch 4:  45%|     | 4685/10313 [20:05<-1:35:54, -3.89it/s, loss=2.06, v_num=., loss_G_fake=0.607, loss_G_class=1.080, loss_G_ssim=0.0902, loss_G=1.780, loss_D_real=0.389, loss_D_fake=0.809, loss_D_class=1.100, loss_D=2.300]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 02:41:28 (running for 01:05:19.74)<br>Memory usage on this node: 6.3/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.07554253935813904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 74.625</td><td style=\"text-align: right;\">0.0755425</td><td style=\"text-align: right;\">0.197507</td><td style=\"text-align: right;\">                   4</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 4:  55%|    | 5622/10313 [24:10<-1:29:48, -2.59it/s, loss=2.06, v_num=., loss_G_fake=0.607, loss_G_class=1.080, loss_G_ssim=0.0902, loss_G=1.780, loss_D_real=0.389, loss_D_fake=0.809, loss_D_class=1.100, loss_D=2.300]\rEpoch 4:  55%|    | 5622/10313 [24:10<-1:29:48, -2.59it/s, loss=2.06, v_num=., loss_G_fake=0.607, loss_G_class=1.080, loss_G_ssim=0.0902, loss_G=1.780, loss_D_real=0.389, loss_D_fake=0.809, loss_D_class=1.100, loss_D=2.300]\rEpoch 4:  55%|    | 5622/10313 [24:10<-1:29:48, -2.59it/s, loss=2.05, v_num=., loss_G_fake=0.554, loss_G_class=1.090, loss_G_ssim=0.158, loss_G=1.800, loss_D_real=0.320, loss_D_fake=0.914, loss_D_class=1.110, loss_D=2.350] \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 02:46:29 (running for 01:10:20.82)<br>Memory usage on this node: 6.3/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.07554253935813904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 74.625</td><td style=\"text-align: right;\">0.0755425</td><td style=\"text-align: right;\">0.197507</td><td style=\"text-align: right;\">                   4</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4:  64%|   | 6559/10313 [28:15<-1:22:20, -1.66it/s, loss=2.12, v_num=., loss_G_fake=0.741, loss_G_class=1.070, loss_G_ssim=0.0995, loss_G=1.910, loss_D_real=0.509, loss_D_fake=0.675, loss_D_class=1.140, loss_D=2.320]\n",
            "Epoch 4:  73%|  | 7496/10313 [32:09<-1:11:47, -0.97it/s, loss=2.12, v_num=., loss_G_fake=0.665, loss_G_class=1.070, loss_G_ssim=0.128, loss_G=1.870, loss_D_real=0.502, loss_D_fake=0.758, loss_D_class=1.090, loss_D=2.350] \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 02:51:30 (running for 01:15:21.95)<br>Memory usage on this node: 5.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.07554253935813904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 74.625</td><td style=\"text-align: right;\">0.0755425</td><td style=\"text-align: right;\">0.197507</td><td style=\"text-align: right;\">                   4</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 4:  82%| | 8433/10313 [36:14<-2:47:41, -0.43it/s, loss=2.12, v_num=., loss_G_fake=0.665, loss_G_class=1.070, loss_G_ssim=0.128, loss_G=1.870, loss_D_real=0.502, loss_D_fake=0.758, loss_D_class=1.090, loss_D=2.350]\rEpoch 4:  82%| | 8433/10313 [36:14<-2:47:41, -0.43it/s, loss=2.12, v_num=., loss_G_fake=0.665, loss_G_class=1.070, loss_G_ssim=0.128, loss_G=1.870, loss_D_real=0.502, loss_D_fake=0.758, loss_D_class=1.090, loss_D=2.350]\rEpoch 4:  82%| | 8433/10313 [36:14<-2:47:41, -0.43it/s, loss=2.04, v_num=., loss_G_fake=0.693, loss_G_class=1.070, loss_G_ssim=0.177, loss_G=1.940, loss_D_real=0.323, loss_D_fake=0.706, loss_D_class=1.090, loss_D=2.120]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 02:56:31 (running for 01:20:23.07)<br>Memory usage on this node: 5.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.07554253935813904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\"> 74.625</td><td style=\"text-align: right;\">0.0755425</td><td style=\"text-align: right;\">0.197507</td><td style=\"text-align: right;\">                   4</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4:  91%| | 9370/10313 [40:19<-127:15:30, -0.00it/s, loss=2.13, v_num=., loss_G_fake=0.705, loss_G_class=1.070, loss_G_ssim=0.237, loss_G=2.010, loss_D_real=0.397, loss_D_fake=0.670, loss_D_class=1.090, loss_D=2.160]\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \n",
            "Validation:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100%|| 10307/10313 [41:18<00:15,  2.66s/it, loss=2.13, v_num=., loss_G_fake=0.705, loss_G_class=1.070, loss_G_ssim=0.237, loss_G=2.010, loss_D_real=0.397, loss_D_fake=0.670, loss_D_class=1.090, loss_D=2.160]\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \n",
            "Validation DataLoader 0: 100%|| 937/938 [00:58<00:00, 15.94it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|| 937/938 [00:58<00:00, 15.94it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \n",
            "Epoch 4: 100%|| 10313/10313 [41:18<00:00,  2.64s/it, loss=2.13, v_num=., loss_G_fake=0.705, loss_G_class=1.070, loss_G_ssim=0.237, loss_G=2.010, loss_D_real=0.397, loss_D_fake=0.670, loss_D_class=1.090, loss_D=2.160]\n",
            "Result for train_LensGAN128_52f0b_00000:\n",
            "  FID_F: 39.5\n",
            "  FID_J: 50.25\n",
            "  ap_F: 0.5661324858665466\n",
            "  ap_J: 0.46938619017601013\n",
            "  auroc_F: 0.6746148467063904\n",
            "  auroc_J: 0.46964430809020996\n",
            "  date: 2022-05-24_03-00-15\n",
            "  done: false\n",
            "  experiment_id: 152d034e835a4eb783ed5470faa95a27\n",
            "  hostname: c8992defe8a4\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3261\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 5037.820427656174\n",
            "  time_this_iter_s: 2492.0624721050262\n",
            "  time_total_s: 8785.947303056717\n",
            "  timestamp: 1653361215\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 5\n",
            "  trial_id: 52f0b_00000\n",
            "  warmup_time: 1.2876198291778564\n",
            "  \n",
            "Epoch 4: 100%|| 10313/10313 [41:30<00:00,  2.66s/it, loss=2.13, v_num=., loss_G_fake=0.507, loss_G_class=1.070, loss_G_ssim=0.227, loss_G=1.800, loss_D_real=0.381, loss_D_fake=1.040, loss_D_class=1.090, loss_D=2.510]\n",
            "Epoch 4: 100%|| 10313/10313 [41:30<00:00,  2.66s/it, loss=2.13, v_num=., loss_G_fake=0.507, loss_G_class=1.070, loss_G_ssim=0.227, loss_G=1.800, loss_D_real=0.381, loss_D_fake=1.040, loss_D_class=1.090, loss_D=2.510]\n",
            "Epoch 4: 100%|| 10313/10313 [41:31<00:00,  2.66s/it, loss=2.13, v_num=., loss_G_fake=0.507, loss_G_class=1.070, loss_G_ssim=0.227, loss_G=1.800, loss_D_real=0.381, loss_D_fake=1.040, loss_D_class=1.090, loss_D=2.510]\n",
            "Epoch 5:   0%|          | 0/10313 [00:00<00:00, -32987919.46it/s, loss=2.13, v_num=., loss_G_fake=0.507, loss_G_class=1.070, loss_G_ssim=0.227, loss_G=1.800, loss_D_real=0.381, loss_D_fake=1.040, loss_D_class=1.090, loss_D=2.510] \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 03:01:36 (running for 01:25:27.99)<br>Memory usage on this node: 5.8/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.6746148467063904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   39.5</td><td style=\"text-align: right;\"> 0.674615</td><td style=\"text-align: right;\">0.566132</td><td style=\"text-align: right;\">                   5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 5:   9%|         | 937/10313 [03:58<-1:55:35, -35.36it/s, loss=2.13, v_num=., loss_G_fake=0.507, loss_G_class=1.070, loss_G_ssim=0.227, loss_G=1.800, loss_D_real=0.381, loss_D_fake=1.040, loss_D_class=1.090, loss_D=2.510] \rEpoch 5:   9%|         | 937/10313 [03:58<-1:55:35, -35.36it/s, loss=2.13, v_num=., loss_G_fake=0.507, loss_G_class=1.070, loss_G_ssim=0.227, loss_G=1.800, loss_D_real=0.381, loss_D_fake=1.040, loss_D_class=1.090, loss_D=2.510]\rEpoch 5:   9%|         | 937/10313 [03:58<-1:55:35, -35.36it/s, loss=2.07, v_num=., loss_G_fake=0.637, loss_G_class=1.070, loss_G_ssim=0.189, loss_G=1.900, loss_D_real=0.391, loss_D_fake=0.751, loss_D_class=1.090, loss_D=2.240]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 03:06:37 (running for 01:30:29.19)<br>Memory usage on this node: 5.8/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.6746148467063904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   39.5</td><td style=\"text-align: right;\"> 0.674615</td><td style=\"text-align: right;\">0.566132</td><td style=\"text-align: right;\">                   5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 5:  18%|        | 1874/10313 [08:04<-1:50:56, -15.48it/s, loss=2.07, v_num=., loss_G_fake=0.637, loss_G_class=1.070, loss_G_ssim=0.189, loss_G=1.900, loss_D_real=0.391, loss_D_fake=0.751, loss_D_class=1.090, loss_D=2.240]\rEpoch 5:  18%|        | 1874/10313 [08:04<-1:50:56, -15.48it/s, loss=2.07, v_num=., loss_G_fake=0.637, loss_G_class=1.070, loss_G_ssim=0.189, loss_G=1.900, loss_D_real=0.391, loss_D_fake=0.751, loss_D_class=1.090, loss_D=2.240]\rEpoch 5:  18%|        | 1874/10313 [08:04<-1:50:56, -15.48it/s, loss=2.11, v_num=., loss_G_fake=0.661, loss_G_class=1.020, loss_G_ssim=0.171, loss_G=1.860, loss_D_real=0.502, loss_D_fake=0.713, loss_D_class=1.110, loss_D=2.320]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 03:11:38 (running for 01:35:30.36)<br>Memory usage on this node: 5.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.6746148467063904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   39.5</td><td style=\"text-align: right;\"> 0.674615</td><td style=\"text-align: right;\">0.566132</td><td style=\"text-align: right;\">                   5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5:  27%|       | 2811/10313 [12:08<-1:46:08, -9.01it/s, loss=2.06, v_num=., loss_G_fake=0.652, loss_G_class=1.070, loss_G_ssim=0.127, loss_G=1.850, loss_D_real=0.407, loss_D_fake=0.717, loss_D_class=1.080, loss_D=2.200]\n",
            "Epoch 5:  36%|      | 3748/10313 [16:02<-1:41:17, -5.85it/s, loss=2.02, v_num=., loss_G_fake=0.600, loss_G_class=1.030, loss_G_ssim=0.128, loss_G=1.760, loss_D_real=0.360, loss_D_fake=0.847, loss_D_class=1.100, loss_D=2.310]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 03:16:40 (running for 01:40:31.59)<br>Memory usage on this node: 5.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.6746148467063904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   39.5</td><td style=\"text-align: right;\"> 0.674615</td><td style=\"text-align: right;\">0.566132</td><td style=\"text-align: right;\">                   5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 5:  45%|     | 4685/10313 [20:05<-1:35:53, -3.89it/s, loss=2.02, v_num=., loss_G_fake=0.600, loss_G_class=1.030, loss_G_ssim=0.128, loss_G=1.760, loss_D_real=0.360, loss_D_fake=0.847, loss_D_class=1.100, loss_D=2.310]\rEpoch 5:  45%|     | 4685/10313 [20:05<-1:35:53, -3.89it/s, loss=2.02, v_num=., loss_G_fake=0.600, loss_G_class=1.030, loss_G_ssim=0.128, loss_G=1.760, loss_D_real=0.360, loss_D_fake=0.847, loss_D_class=1.100, loss_D=2.310]\rEpoch 5:  45%|     | 4685/10313 [20:05<-1:35:53, -3.89it/s, loss=2.05, v_num=., loss_G_fake=0.688, loss_G_class=1.080, loss_G_ssim=0.144, loss_G=1.910, loss_D_real=0.434, loss_D_fake=0.706, loss_D_class=1.120, loss_D=2.260]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 03:21:41 (running for 01:45:32.82)<br>Memory usage on this node: 5.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.6746148467063904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   39.5</td><td style=\"text-align: right;\"> 0.674615</td><td style=\"text-align: right;\">0.566132</td><td style=\"text-align: right;\">                   5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 5:  55%|    | 5622/10313 [24:09<-1:29:49, -2.59it/s, loss=2.05, v_num=., loss_G_fake=0.688, loss_G_class=1.080, loss_G_ssim=0.144, loss_G=1.910, loss_D_real=0.434, loss_D_fake=0.706, loss_D_class=1.120, loss_D=2.260]\rEpoch 5:  55%|    | 5622/10313 [24:09<-1:29:49, -2.59it/s, loss=2.05, v_num=., loss_G_fake=0.688, loss_G_class=1.080, loss_G_ssim=0.144, loss_G=1.910, loss_D_real=0.434, loss_D_fake=0.706, loss_D_class=1.120, loss_D=2.260]\rEpoch 5:  55%|    | 5622/10313 [24:09<-1:29:49, -2.59it/s, loss=2.04, v_num=., loss_G_fake=0.622, loss_G_class=0.963, loss_G_ssim=0.122, loss_G=1.710, loss_D_real=0.416, loss_D_fake=0.797, loss_D_class=1.110, loss_D=2.330]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 03:26:42 (running for 01:50:34.11)<br>Memory usage on this node: 5.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.6746148467063904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   39.5</td><td style=\"text-align: right;\"> 0.674615</td><td style=\"text-align: right;\">0.566132</td><td style=\"text-align: right;\">                   5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 5:  64%|   | 6559/10313 [28:14<-1:22:22, -1.66it/s, loss=2.04, v_num=., loss_G_fake=0.622, loss_G_class=0.963, loss_G_ssim=0.122, loss_G=1.710, loss_D_real=0.416, loss_D_fake=0.797, loss_D_class=1.110, loss_D=2.330]\rEpoch 5:  64%|   | 6559/10313 [28:14<-1:22:22, -1.66it/s, loss=2.04, v_num=., loss_G_fake=0.622, loss_G_class=0.963, loss_G_ssim=0.122, loss_G=1.710, loss_D_real=0.416, loss_D_fake=0.797, loss_D_class=1.110, loss_D=2.330]\rEpoch 5:  64%|   | 6559/10313 [28:14<-1:22:22, -1.66it/s, loss=2, v_num=., loss_G_fake=0.583, loss_G_class=0.981, loss_G_ssim=0.101, loss_G=1.660, loss_D_real=0.400, loss_D_fake=0.871, loss_D_class=1.110, loss_D=2.390]   \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 03:31:43 (running for 01:55:35.30)<br>Memory usage on this node: 5.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.6746148467063904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   39.5</td><td style=\"text-align: right;\"> 0.674615</td><td style=\"text-align: right;\">0.566132</td><td style=\"text-align: right;\">                   5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5:  73%|  | 7496/10313 [32:08<-1:11:49, -0.97it/s, loss=2, v_num=., loss_G_fake=0.637, loss_G_class=0.957, loss_G_ssim=0.110, loss_G=1.700, loss_D_real=0.439, loss_D_fake=0.767, loss_D_class=1.110, loss_D=2.320]\n",
            "Epoch 5:  82%| | 8433/10313 [36:12<-2:47:45, -0.43it/s, loss=2, v_num=., loss_G_fake=0.620, loss_G_class=0.845, loss_G_ssim=0.176, loss_G=1.640, loss_D_real=0.363, loss_D_fake=0.837, loss_D_class=1.090, loss_D=2.290]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 03:36:45 (running for 02:00:36.59)<br>Memory usage on this node: 5.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.6746148467063904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   39.5</td><td style=\"text-align: right;\"> 0.674615</td><td style=\"text-align: right;\">0.566132</td><td style=\"text-align: right;\">                   5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5:  91%| | 9370/10313 [40:16<-127:23:02, -0.00it/s, loss=1.96, v_num=., loss_G_fake=0.638, loss_G_class=0.897, loss_G_ssim=0.131, loss_G=1.670, loss_D_real=0.357, loss_D_fake=0.814, loss_D_class=1.100, loss_D=2.270]\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \n",
            "Validation:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: 100%|| 10307/10313 [41:17<00:15,  2.66s/it, loss=1.96, v_num=., loss_G_fake=0.638, loss_G_class=0.897, loss_G_ssim=0.131, loss_G=1.670, loss_D_real=0.357, loss_D_fake=0.814, loss_D_class=1.100, loss_D=2.270]\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \n",
            "Validation DataLoader 0: 100%|| 937/938 [00:59<00:00, 15.62it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|| 937/938 [00:59<00:00, 15.62it/s]\u001b[A\n",
            "Epoch 5: 100%|| 10313/10313 [41:17<00:00,  2.64s/it, loss=1.96, v_num=., loss_G_fake=0.638, loss_G_class=0.897, loss_G_ssim=0.131, loss_G=1.670, loss_D_real=0.357, loss_D_fake=0.814, loss_D_class=1.100, loss_D=2.270]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 03:41:46 (running for 02:05:37.87)<br>Memory usage on this node: 6.0/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.6746148467063904 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   39.5</td><td style=\"text-align: right;\"> 0.674615</td><td style=\"text-align: right;\">0.566132</td><td style=\"text-align: right;\">                   5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 5: 100%|| 10313/10313 [41:28<00:00,  2.65s/it, loss=1.96, v_num=., loss_G_fake=0.638, loss_G_class=0.897, loss_G_ssim=0.131, loss_G=1.670, loss_D_real=0.357, loss_D_fake=0.814, loss_D_class=1.100, loss_D=2.270]\n",
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rValidation DataLoader 0: 100%|| 938/938 [01:11<00:00, 15.62it/s]\u001b[A\n",
            "Result for train_LensGAN128_52f0b_00000:\n",
            "  FID_F: 70.3125\n",
            "  FID_J: 68.25\n",
            "  ap_F: 0.32872846722602844\n",
            "  ap_J: 0.23333387076854706\n",
            "  auroc_F: 0.43105876445770264\n",
            "  auroc_J: 0.21448326110839844\n",
            "  date: 2022-05-24_03-41-46\n",
            "  done: false\n",
            "  experiment_id: 152d034e835a4eb783ed5470faa95a27\n",
            "  hostname: c8992defe8a4\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3261\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 7529.109290599823\n",
            "  time_this_iter_s: 2491.2888629436493\n",
            "  time_total_s: 11277.236166000366\n",
            "  timestamp: 1653363706\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 6\n",
            "  trial_id: 52f0b_00000\n",
            "  warmup_time: 1.2876198291778564\n",
            "  \n",
            "Epoch 5: 100%|| 10313/10313 [41:28<00:00,  2.65s/it, loss=1.97, v_num=., loss_G_fake=0.698, loss_G_class=0.911, loss_G_ssim=0.207, loss_G=1.820, loss_D_real=0.366, loss_D_fake=0.738, loss_D_class=1.110, loss_D=2.210]\n",
            "Epoch 5: 100%|| 10313/10313 [41:28<00:00,  2.65s/it, loss=1.97, v_num=., loss_G_fake=0.698, loss_G_class=0.911, loss_G_ssim=0.207, loss_G=1.820, loss_D_real=0.366, loss_D_fake=0.738, loss_D_class=1.110, loss_D=2.210]\n",
            "Epoch 6:   0%|          | 0/10313 [00:00<00:00, -31010725.55it/s, loss=1.97, v_num=., loss_G_fake=0.698, loss_G_class=0.911, loss_G_ssim=0.207, loss_G=1.820, loss_D_real=0.366, loss_D_fake=0.738, loss_D_class=1.110, loss_D=2.210]\n",
            "Epoch 6:   9%|         | 937/10313 [03:57<-1:55:36, -35.46it/s, loss=1.99, v_num=., loss_G_fake=0.563, loss_G_class=0.958, loss_G_ssim=0.209, loss_G=1.730, loss_D_real=0.364, loss_D_fake=0.908, loss_D_class=1.090, loss_D=2.370]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 03:46:48 (running for 02:10:39.80)<br>Memory usage on this node: 5.8/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.43105876445770264 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">70.3125</td><td style=\"text-align: right;\"> 0.431059</td><td style=\"text-align: right;\">0.328728</td><td style=\"text-align: right;\">                   6</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 6:  18%|        | 1874/10313 [08:03<-1:50:57, -15.52it/s, loss=1.99, v_num=., loss_G_fake=0.563, loss_G_class=0.958, loss_G_ssim=0.209, loss_G=1.730, loss_D_real=0.364, loss_D_fake=0.908, loss_D_class=1.090, loss_D=2.370]\rEpoch 6:  18%|        | 1874/10313 [08:03<-1:50:57, -15.52it/s, loss=1.99, v_num=., loss_G_fake=0.563, loss_G_class=0.958, loss_G_ssim=0.209, loss_G=1.730, loss_D_real=0.364, loss_D_fake=0.908, loss_D_class=1.090, loss_D=2.370]\rEpoch 6:  18%|        | 1874/10313 [08:03<-1:50:57, -15.52it/s, loss=2.02, v_num=., loss_G_fake=0.590, loss_G_class=0.934, loss_G_ssim=0.146, loss_G=1.670, loss_D_real=0.440, loss_D_fake=0.861, loss_D_class=1.100, loss_D=2.410]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-24 03:51:49 (running for 02:15:41.13)<br>Memory usage on this node: 5.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.42 GiB heap, 0.0/3.71 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 52f0b_00000 with auroc_F=0.43105876445770264 and parameters={'lr': -3, 'n_fmaps': 128, 'bs': 3}<br>Result logdir: /content/drive/MyDrive/Logs/F/LensGAN128/pgan_variable_ssim_dropout_emb_lr3_128<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  FID_F</th><th style=\"text-align: right;\">  auroc_F</th><th style=\"text-align: right;\">    ap_F</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_52f0b_00000</td><td>RUNNING </td><td>172.28.0.2:3261</td><td style=\"text-align: right;\">  -3</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">70.3125</td><td style=\"text-align: right;\"> 0.431059</td><td style=\"text-align: right;\">0.328728</td><td style=\"text-align: right;\">                   6</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_LensGAN128 pid=3261)\u001b[0m \rEpoch 6:  27%|       | 2811/10313 [12:07<-1:46:09, -9.02it/s, loss=2.02, v_num=., loss_G_fake=0.590, loss_G_class=0.934, loss_G_ssim=0.146, loss_G=1.670, loss_D_real=0.440, loss_D_fake=0.861, loss_D_class=1.100, loss_D=2.410] \rEpoch 6:  27%|       | 2811/10313 [12:07<-1:46:09, -9.02it/s, loss=2.02, v_num=., loss_G_fake=0.590, loss_G_class=0.934, loss_G_ssim=0.146, loss_G=1.670, loss_D_real=0.440, loss_D_fake=0.861, loss_D_class=1.100, loss_D=2.410]\rEpoch 6:  27%|       | 2811/10313 [12:07<-1:46:09, -9.02it/s, loss=2, v_num=., loss_G_fake=0.655, loss_G_class=0.850, loss_G_ssim=0.148, loss_G=1.650, loss_D_real=0.527, loss_D_fake=0.751, loss_D_class=1.110, loss_D=2.390]   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %reload_ext tensorboard\n",
        "!tensorboard --logdir=./drive/MyDrive/Logs/F/LensGAN128/test"
      ],
      "metadata": {
        "id": "JTNg2xz4S8zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive."
      ],
      "metadata": {
        "id": "ATpDlPfvsa5q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvjkvb7Rcnaa"
      },
      "source": [
        "## VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTr9yVSdcx2x"
      },
      "source": [
        "def train_mnist(config, checkpoint=None, num_steps=10000, num_gpus=torch.cuda.device_count()):\n",
        "    dm = npyImageData(config, 128)                                              # Specify image width here    \n",
        "    model = LensVAE(config)\n",
        "    trainer = pl.Trainer(val_check_interval=0.10, max_steps=num_steps, gpus=num_gpus,\n",
        "                         logger=TensorBoardLogger(save_dir=os.path.join('drive/MyDrive/Logs/', 'F/LensVAE'), \n",
        "                                                  name='delete', sub_dir='_'.join('{}_{}'.format(*i) for i in config.items())), \n",
        "                         callbacks=[\n",
        "                                    ModelCheckpoint(monitor='train_loss', \n",
        "                                                    verbose=True, save_last=True, save_top_k=5, \n",
        "                                                    mode='min', auto_insert_metric_name=False, \n",
        "                                                    every_n_train_steps=int(7500//int(2**np.rint(config['bs'])))),\n",
        "                                    ModuleDataMonitor(True), \n",
        "                                    ],\n",
        "                         benchmark=True, precision=16)\n",
        "\n",
        "    trainer.fit(model, dm, ckpt_path=checkpoint)\n",
        "# __lightning_end__\n",
        "\n",
        "# __no_tune_train_begin__\n",
        "def train_mnist_no_tune(*args, **kwargs):\n",
        "    config={'input_height': 128,\n",
        "            'latent_dim': 100,\n",
        "            'lr': 1e-3,\n",
        "            'bs': 3,\n",
        "            }\n",
        "    train_mnist(config, *args, **kwargs)\n",
        "# __no_tune_train_end__\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    # os.environ[\"PL_FAULT_TOLERANT_TRAINING\"] = \"1\"\n",
        "    if args.smoke_test:\n",
        "        train_mnist_no_tune()\n",
        "    else:\n",
        "        # pbt scheduler\n",
        "        train_mnist_no_tune()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btkO_vqvN5Yi"
      },
      "source": [
        "## Stage 2\n",
        "Here we tune hyperparameters as we train our modified DCGAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0efCKmqQkp3"
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_Stage2(config, checkpoint_dir=None, num_epochs=10, num_gpus=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    kwargs = {\n",
        "        # 'limit_train_batches' : 0.05,\n",
        "        # 'limit_val_batches' : 0.05,\n",
        "        'progress_bar_refresh_rate' : int(8250//config['batch_size']),\n",
        "        'max_epochs' : num_epochs,\n",
        "        'prepare_data_per_node' : False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        'gpus' : int(num_gpus),\n",
        "        'logger' : TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        'callbacks' : [\n",
        "            TuneReportCheckpointCallback(\n",
        "                {\n",
        "                    'loss_G': 'Stage2/G/train/loss', \n",
        "                    'loss_D': 'Stage2/D/train/loss', \n",
        "                    # Switch up the auroc vlues when training on different dataset -----------------------------------------------\n",
        "                    'auroc': 'Stage2/ResNet(F)/val/auroc', \n",
        "                    'auroc_cross': 'Stage2/ResNet(J)/val/auroc',\n",
        "                },\n",
        "            ),\n",
        "        ],\n",
        "        # 'stochastic_weight_avg' : True,\n",
        "        # works with only one optimizer\n",
        "        # 'benchmark' : True,\n",
        "    }\n",
        "    \n",
        "    dm = npyImageData(config)                                              # Specify image width here    \n",
        "    if checkpoint_dir is not None:\n",
        "        kwargs['resume_from_checkpoint'] = os.path.join(checkpoint_dir, 'checkpoint')\n",
        "        # model = Stage2.load_from_checkpoint(kwargs['resume_from_checkpoint'], config=config)\n",
        "    # else:\n",
        "        # model = Stage2(config)\n",
        "    model = Stage2(config)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "\n",
        "# # # __tune_asha_begin__\n",
        "# def tune_Stage2_asha(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "#     # print(os.cpu_count(), torch.cuda.device_count())\n",
        "#     analysis = tune.run(\n",
        "#         tune.with_parameters(\n",
        "#             train_Stage2,\n",
        "#             num_epochs=num_epochs,\n",
        "#             num_gpus=gpus_per_trial\n",
        "#         ),\n",
        "#         # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "#         name='Stage2/pbt/J',\n",
        "#         metric='auroc',\n",
        "#         mode='max',\n",
        "#         config={'learning_rate': 1e-4,\n",
        "#                 'n_fmaps': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "#                 'batch_size': 8,\n",
        "#                 },\n",
        "#         # config={'learning_rate': 0.01,\n",
        "#         #         'n_fmaps': 32,\n",
        "#         #         'batch_size': 32,\n",
        "#         #         },\n",
        "#         # stop=TrialPlateauStopper('loss_G'),\n",
        "#         resources_per_trial={'cpu': os.cpu_count(),\n",
        "#                              'gpu': gpus_per_trial,\n",
        "#                             },\n",
        "#         local_dir='./drive/MyDrive/Logs',\n",
        "#         scheduler = ASHAScheduler(max_t=num_epochs, grace_period=2,  reduction_factor=2),\n",
        "#         progress_reporter=JupyterNotebookReporter(\n",
        "#             overwrite=True,\n",
        "#             parameter_columns=['learning_rate', 'n_fmaps', 'batch_size'],\n",
        "#             metric_columns=['loss_G', 'loss_D', 'auroc', 'auroc_cross', 'training_iteration'],\n",
        "#             sort_by_metric=True,\n",
        "#         ),\n",
        "#         fail_fast = True,\n",
        "#         # reuse_actors=True,\n",
        "#         # num_samples=num_samples,\n",
        "#         resume='PROMPT',\n",
        "# #         restore='/content/drive/MyDrive/Logs/delete/train_Stage2_e42ac_00025_25_batch_size=8,learning_rate=0.01,n_fmaps=8_2021-07-28_21-16-18/checkpoint_epoch=4-step=2339',\n",
        "#     )\n",
        "\n",
        "# #     print('Best hyperparameters found were: ', analysis.best_config)\n",
        "\n",
        "# # # __tune_asha_end__\n",
        "\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_Stage2_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_Stage2,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial\n",
        "        ),\n",
        "        # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "        name='Stage2/pbt/F',\n",
        "        metric='auroc',\n",
        "        mode='max',\n",
        "        config={'learning_rate': 1e-4,\n",
        "                'n_fmaps': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "                'res_depth': tune.choice([1, 2, 3, 4]),\n",
        "                'batch_size': 8,\n",
        "                },\n",
        "        # config={'learning_rate': 0.01,\n",
        "        #         'n_fmaps': 32,\n",
        "        #         'batch_size': 32,\n",
        "        #         },\n",
        "        # stop=TrialPlateauStopper('loss_G'),\n",
        "        resources_per_trial={'cpu': os.cpu_count(),\n",
        "                             'gpu': gpus_per_trial,\n",
        "                            },\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        scheduler = PopulationBasedTraining(time_attr='training_iteration',\n",
        "                                            quantile_fraction=0.5,\n",
        "                                            resample_probability=0.8,\n",
        "                                            perturbation_interval=1,\n",
        "                                            hyperparam_mutations={\n",
        "                                                'learning_rate': tune.loguniform(1e-7, 1e-1),\n",
        "                                                'batch_size': [8, 16, 32, 64, 128],\n",
        "                                            },\n",
        "                                            ),\n",
        "        progress_reporter=JupyterNotebookReporter(\n",
        "            overwrite=False,\n",
        "            parameter_columns=['learning_rate', 'n_fmaps', 'res_depth', 'batch_size'],\n",
        "            metric_columns=['loss_G', 'loss_D', 'auroc', 'auroc_cross', 'training_iteration'],\n",
        "            sort_by_metric=True,\n",
        "        ),\n",
        "        fail_fast = True,\n",
        "        # reuse_actors=True,\n",
        "        # num_samples=num_samples,\n",
        "        resume='PROMPT',\n",
        "    )\n",
        "\n",
        "    print('Best hyperparameters found were: ', analysis.best_config)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_Stage2_asha(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "        tune_Stage2_pbt(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # ASHA scheduler\n",
        "        # tune_Stage2_asha(num_samples=1, num_epochs=10, gpus_per_trial=torch.cuda.device_count())\n",
        "        # Population based training\n",
        "        tune_Stage2_pbt(num_samples=1, num_epochs=30, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}