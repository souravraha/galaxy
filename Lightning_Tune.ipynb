{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lightning_Tune.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WK9GeW6miiXr",
        "ASOiXXn-36Wf",
        "FbXpnU7Y4Cr9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravraha/galaxy/blob/temp/Lightning_Tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDsadYRa5Rh5"
      },
      "source": [
        "# Mount Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF5oJHq0_WxS"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDzU0Yty6Qsw"
      },
      "source": [
        "# Prerequisites/ shell commands"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI_RfiMRk5j_"
      },
      "source": [
        "## Install/uninstall packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMwknUIDcTW1"
      },
      "source": [
        "# If you are running on Google Colab, uncomment below to install the necessary dependencies \n",
        "# before beginning the exercise.\n",
        "\n",
        "print('Setting up colab environment')\n",
        "# !pip uninstall -y -q pyarrow\n",
        "!pip install -q lightning-bolts GPy\n",
        "!pip install -q ray[debug] ray[default]\n",
        "!pip install -U -q ray[tune]\n",
        "# !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "# # A hack to force the runtime to restart, needed to include the above dependencies.\n",
        "# print('Done installing! Restarting via forced crash (this is not an issue).')\n",
        "# import os\n",
        "# os._exit(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK9GeW6miiXr"
      },
      "source": [
        "## Download and extract data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdfevhA2fGYr"
      },
      "source": [
        "Here choose the model you wish to use for training/testing. Don't forget to make modifications in the following sections:\n",
        "\n",
        "1.   GLOBAL in class definition of npyImageData.\n",
        "2.   correct assignment of metric keys while defining the training wrapper for Tune.\n",
        "3.   name of the experiment initiated/resumed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZUIrgOfbwPe"
      },
      "source": [
        "# 'a': 1Cjcw2EWorhdhJSGoWOdxsEUDxvl943dt, 'b': 15yXXC4h5VsytP3Ak1jfUSjQhdgP2s23K, 'c': 1vuQ-pLzoKT4Hd_V7949r9eND9E2fB_u_,\n",
        "# 'd': , 'e': 1wFuasvb7PthxXtMUlsD13uzYHWlWt06H, 'f': 17l6H61tLAu26zGuei38r_T5ssjbYUeaJ, \n",
        "# 'g': 1SxQVosWeEjY3Pyn8LRXA11rLnZ9HK_7B, 'h': 1Atau0RH4oyLAiYReW-G9a8l9pUNltglF, 'i': 15lEgsR1p00KSHieaT9a1nkbJ86pDxwgp, \n",
        "# 'j': 1m0EQUbqZZeyl76XsQIKWU5Qd7jGmmWhB, 'k': , 'l': 1meTDi4aeWfdChOiXeLtUOGhjVDVu000e\n",
        "\n",
        "# fake data\n",
        "# 'fpgan': 1-4o0yqSBA9WSY9gTYamIez_RAekwDsHV\n",
        "\n",
        "!rm -rf images/\n",
        "!gdown --id 1m0EQUbqZZeyl76XsQIKWU5Qd7jGmmWhB -O - --quiet | tar --skip-old-files -zxf -\n",
        "# !rm ./model_f.tgz\n",
        "\n",
        "# def prepare_data(data_dir: str = '/content'):\n",
        "#     with FileLock(os.path.expanduser(data_dir+'.lock')):\n",
        "#         gdown.download('https://drive.google.com/uc?id=17l6H61tLAu26zGuei38r_T5ssjbYUeaJ', data_dir+'/model_j.tgz', quiet=True)\n",
        "        \n",
        "#         temp = tarfile.open(data_dir+'/model_j.tgz', 'r|gz')\n",
        "#         temp.extractall()\n",
        "#         temp.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB3f7W9_kazP"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR6G_K6bWVqd"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "# from pathlib import Path\n",
        "from itertools import cycle\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "# ------------------------------------\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "# ------------------------------------\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torchvision import transforms, datasets\n",
        "# ------------------------------------\n",
        "import torchmetrics as tm\n",
        "# ------------------------------------\n",
        "import pytorch_lightning as pl\n",
        "from pl_bolts.models.gans import DCGAN\n",
        "from pl_bolts.callbacks import ModuleDataMonitor\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pl_bolts.models.self_supervised.resnets import BasicBlock\n",
        "# from pytorch_lightning.utilities.cloud_io import load as pl_load\n",
        "from drive.MyDrive.ml.Callbacks.confused_logits import ConfusedLogitCallback\n",
        "# ------------------------------------\n",
        "from ray import tune\n",
        "# from ray.tune.stopper import TrialPlateauStopper\n",
        "from ray.tune import CLIReporter, JupyterNotebookReporter\n",
        "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
        "# from ray.tune.schedulers.pb2 import PB2\n",
        "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
        "# ------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hczXOvdE54S"
      },
      "source": [
        "# Class definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snbv_zoNiWfW"
      },
      "source": [
        "## DataModule\n",
        "This creates dataloaders which need to be supplied to train, validate or test the module we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yItuGxXmXzGr"
      },
      "source": [
        "class npyImageData(pl.LightningDataModule):\n",
        "    def __init__(self, config, img_width: int = 150, data_dir: str = '/content/images/'):\n",
        "        super().__init__()\n",
        "        # This method is not implemented\n",
        "        # self.save_hyperparameters()\n",
        "        self.bs = config['bs']\n",
        "        self.data_dir = os.path.expanduser(data_dir)\n",
        "        \n",
        "        # Change the source file containing mean and stdv when changing dataset ------------------------------------------------------\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            # F : [mean=71.75926373866668, std=96.139484964214, min=5.0, max=966.0]\n",
        "            # J : [mean=50.271541595458984, std=94.8838882446289, min=0, max=1007.0]\n",
        "            transforms.Normalize(mean=(0,), std=(1007,)),\n",
        "            transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "            # this shift-scales the pixel values -> [-1, 1]\n",
        "            transforms.Resize(img_width, transforms.InterpolationMode.NEAREST),\n",
        "        ])\n",
        "\n",
        "    @staticmethod\n",
        "    def npy_loader(path):\n",
        "        # s=np.load(path).astype('float',copy=False)\n",
        "        return torch.from_numpy(np.load(path)).unsqueeze(0).float()\n",
        "        # Convert to tenssor first, and then to float, otherwise final dtype \n",
        "        # would be float64, which would raise errors in conv layers      ###### type as\n",
        "\n",
        "    def setup(self, stage: str = None):\n",
        "        if stage in ('fit', None):\n",
        "            self.train_set = datasets.DatasetFolder(os.path.join(self.data_dir,'train'), \n",
        "                self.npy_loader, ('.npy'), self.transform,)\n",
        "            # self.train_set, self.val_set = random_split(self.full_set, [60000, 15000])            \n",
        "            self.val_set = datasets.DatasetFolder(os.path.join(self.data_dir,'val'),  \n",
        "                self.npy_loader, ('.npy'), self.transform,)\n",
        "            self.dims = tuple(self.train_set[0][0].shape)\n",
        "\n",
        "        if stage in ('test', None):\n",
        "            self.test_set = datasets.DatasetFolder(os.path.join(self.data_dir,'val'),  \n",
        "                self.npy_loader, ('.npy'), self.transform,)\n",
        "            self.dims = getattr(self, 'dims', self.test_set[0][0].shape)\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_set, self.bs, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_set, self.bs, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_set, self.bs, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C3gKSFKKDaY"
      },
      "source": [
        "dm = npyImageData({'lr': 0.001, 'bs': 8})\n",
        "# model = LensResnet.load_from_checkpoint(os.path.join(BEST_F_RESNET, 'checkpoint'), config={'lr': 0.001, 'bs': 8})\n",
        "# trainer = pl.Trainer(gpus=1)\n",
        "# trainer.predict(model, dm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0bm1afc11hN"
      },
      "source": [
        "## ResNet\n",
        "We modify a ResNet slightly for our purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRVE-YyyWNUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b0f17a-5a54-4bab-af1d-da02d044445d"
      },
      "source": [
        "m = LensResnet({'lr': 1e-3})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojZ0yT4z168p"
      },
      "source": [
        "PRE_F_RESNET = '/content/drive/MyDrive/Logs/F/LensResnet/PRETRAINED.pth'\n",
        "PRE_J_RESNET = '/content/drive/MyDrive/Logs/J/LensResnet/PRETRAINED.pth'\n",
        "\n",
        "class LensResnet(pl.LightningModule):\n",
        "    def __init__(self, config, image_channels: int = 1, num_classes: int = 3, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "        self.lr = config['lr']\n",
        "\n",
        "        # --------------------------------------------------------------------------------------------------\n",
        "        self.backbone = torch.load(PRE_J_RESNET, map_location=self.device)\n",
        "        # self.backbone = resnet18(num_classes=self.hparams.num_classes)\n",
        "        # self.backbone.conv1 = nn.LazyConv2d(64, 7, 2, 3, bias=False)\n",
        "        \n",
        "        self.train_metrics = tm.MetricCollection([tm.AUROC(self.hparams.num_classes, average='weighted'),],\n",
        "            prefix='LensResnet/train/'\n",
        "        )\n",
        "        self.val_metrics = tm.MetricCollection([tm.AUROC(self.hparams.num_classes, average=None),\n",
        "                                                tm.ROC(self.hparams.num_classes),],\n",
        "        )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.backbone.parameters(), self.lr)\n",
        "\n",
        "    def forward(self, x, prob=False):\n",
        "        logits = self.backbone(x)\n",
        "        return logits.softmax(1) if prob else logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        self.last_logits = self(imgs)\n",
        "        loss = F.cross_entropy(self.last_logits, labels)\n",
        "        self.log('LensResnet/train/loss', loss)\n",
        "        #  keep only scalars here, for no errors\n",
        "        \n",
        "        preds = self.last_logits.softmax(1)\n",
        "        self.train_metrics.update(preds, labels)\n",
        "        try:\n",
        "            self.log_dict(self.train_metrics.compute(), prog_bar=True)\n",
        "        except Exception as f:\n",
        "            print(f)\n",
        "        finally:            \n",
        "            # self.train_metrics.reset()\n",
        "            # self.log_dict automatically resets at the end of epoch\n",
        "            return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        logits = self(imgs)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        self.log('LensResnet/val/loss', loss)\n",
        "        #  keep only scalars here, for no errors\n",
        "        \n",
        "        preds = logits.softmax(1)\n",
        "        self.val_metrics.update(preds, labels)\n",
        "\n",
        "    def validation_epoch_end(self, Listofdicts):\n",
        "        # prediction, target = torch.cat([x['pred'] for x in Listofdicts]), torch.cat([x['target'] for x in Listofdicts])\n",
        "        # aurocTensor = tm.functional.auroc(prediction, target, num_classes=self.hparams.num_classes, average=None)\n",
        "        try:\n",
        "            scoresDict = self.val_metrics.compute()\n",
        "        except Exception as f:\n",
        "            # print(f)\n",
        "            print(torch.unique(torch.stack(self.val_metrics.AUROC.target)).tolist())\n",
        "        else:\n",
        "            self.log('LensResnet/val/auroc', scoresDict['AUROC'].min(), prog_bar=True)\n",
        "            fprList, tprList, _ = scoresDict['ROC']  # tm.functional.roc(prediction, target, num_classes=self.hparams.num_classes)\n",
        "            \n",
        "            f = plt.figure()\n",
        "            colors = cycle(['red', 'blue', 'green'])\n",
        "            for i, color in zip(range(self.hparams.num_classes), colors):\n",
        "                plt.plot(fprList[i].cpu(), tprList[i].cpu(), color=color,\n",
        "                        label='ROC curve of class {0} (area = {1:0.4f})'\n",
        "                        ''.format(i, scoresDict['AUROC'][i]))\n",
        "            plt.plot([0, 1], [0, 1], 'k--')\n",
        "            plt.xlim([0.0, 1.0])\n",
        "            plt.ylim([0.0, 1.05])\n",
        "            plt.xlabel('False Positive Rate')\n",
        "            plt.ylabel('True Positive Rate')\n",
        "            plt.title('One vs. all ROC curve')\n",
        "            plt.legend(loc='lower right')\n",
        "\n",
        "            self.logger.experiment.add_figure('LensResnet/val/ROC', f)\n",
        "            f.savefig(str(self.trainer.log_dir) + '/ROC_step_{:05d}.pdf'.format(self.global_step))\n",
        "        finally:\n",
        "            self.val_metrics.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc0oRARcKBv3"
      },
      "source": [
        "## LensGAN128\n",
        "Here we subclass a DCGAN to create our low resolution GAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9biIaX6MJuO"
      },
      "source": [
        "m = LensGAN128({'lr':0.001, 'n_fmaps': 128, 'bs': 8})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kclAeom914wK"
      },
      "source": [
        "BEST_F_RESNET = '/content/drive/MyDrive/Logs/F/LensResnet/pbt_tanh/train_LensResnet_eb619_00000_0_2021-09-02_19-42-34/checkpoint_epoch=2-step=28124'\n",
        "BEST_J_RESNET = '/content/drive/MyDrive/Logs/J/LensResnet/pbt_tanh_fine/train_LensResnet_93609_00000_0_2021-09-02_21-06-00/checkpoint_epoch=2-step=28124'\n",
        "\n",
        "def post_plotting(ax):\n",
        "    ax.plot([0, 1], [0, 1], 'k--')\n",
        "    ax.legend(loc='lower right')\n",
        "\n",
        "class LensGAN128(DCGAN):\n",
        "    def __init__(self, config, num_classes: int = 3, **kwargs):\n",
        "        super().__init__(feature_maps_gen=config['n_fmaps'], feature_maps_disc=config['n_fmaps'], \n",
        "                         learning_rate=config['lr'], **kwargs)\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "\n",
        "        # Batch-norm needs depends upon out channels of the previous layer\n",
        "        first = self.generator._make_gen_block(1, self.hparams.feature_maps_gen * 16)\n",
        "        # Accepts inputs of any channels\n",
        "        first[0] = nn.LazyConvTranspose2d(self.hparams.feature_maps_gen * 16, kernel_size=4, stride=1, padding=0)\n",
        "        # Turn this into the second layer\n",
        "        self.generator.gen[0] = self.generator._make_gen_block(self.hparams.feature_maps_gen * 16, self.hparams.feature_maps_gen * 8)\n",
        "        self.generator.gen = nn.Sequential(first, *list(self.generator.gen))\n",
        "        \n",
        "        # Turn this into the penultimate layer\n",
        "        self.discriminator.disc[-1] = self.discriminator._make_disc_block(self.hparams.feature_maps_disc * 8, self.hparams.feature_maps_disc * 16)\n",
        "        self.discriminator.disc = nn.Sequential(*list(self.discriminator.disc), nn.LazyConv2d(1, kernel_size=4, stride=1, padding=0, bias=False))\n",
        "        # # Necessary if using ACGAN, else could be appended to disc module\n",
        "        # self.discriminator.add_module('critic', nn.LazyConv2d(1, kernel_size=4, stride=1, padding=0, bias=False))\n",
        "        # # Remove if ACGAN not needed \n",
        "        # self.discriminator.add_module('aux', nn.Sequential(nn.Flatten(), nn.LazyLinear(self.hparams.num_classes)))\n",
        "        # self.discriminator.forward = self.discriminator_forward\n",
        "\n",
        "        for i in range(5):\n",
        "        #     # Necessary for implementing gradient penalty, else remove\n",
        "            self.discriminator.disc[i][1] = nn.Identity()\n",
        "        #     # Remove if LeakyRelu not needed in generator\n",
        "        #     self.generator.gen[i][-1] = self.discriminator.disc[i][-1]\n",
        "        #     # Implement dropouts\n",
        "        #     self.generator.gen[i] = nn.Sequential(*list(self.generator.gen[i]), nn.Dropout())\n",
        "        #     self.discriminator.disc[i] = nn.Sequential(*list(self.discriminator.disc[i]), nn.Dropout())\n",
        "\n",
        "        # Not needed in WGAN architectures\n",
        "        # self.criterion = nn.MSELoss()\n",
        "\n",
        "        temp = LensResnet.load_from_checkpoint(os.path.join(BEST_F_RESNET, 'checkpoint'))\n",
        "        temp.freeze()\n",
        "        self.modelF = temp.backbone     # torch.load(PRE_F_RESNET, map_location=self.device).eval())\n",
        "        # Proper way to copy the last layer\n",
        "        self.lastF = self.modelF.fc\n",
        "        self.modelF.fc = nn.Identity()\n",
        "        \n",
        "        temp = LensResnet.load_from_checkpoint(os.path.join(BEST_J_RESNET, 'checkpoint'))\n",
        "        temp.freeze()\n",
        "        self.modelJ = temp.backbone     # torch.load(PRE_J_RESNET, map_location=self.device).eval())\n",
        "        # Proper way to copy the last layer\n",
        "        self.lastJ = self.modelJ.fc\n",
        "        self.modelJ.fc = nn.Identity()\n",
        "\n",
        "        self.imgMetrics = tm.MetricCollection(\n",
        "            {\n",
        "                'FID_F' : tm.FID(self.modelF),\n",
        "                'FID_J' : tm.FID(self.modelJ),\n",
        "            },\n",
        "            prefix='LensGAN128/val/',\n",
        "        )\n",
        "    # # Not needed if not using ACGAN\n",
        "    # def discriminator_forward(self, x):\n",
        "    #     out5 = self.discriminator.disc(x)\n",
        "    #     return self.discriminator.critic(out5).squeeze(), self.discriminator.aux(out5)\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        inp = torch.cat((F.one_hot(labels, self.hparams.num_classes), noise), 1)\n",
        "        return super().forward(inp)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        real, self.labels = batch\n",
        "        fake = self._get_fake_data(self.labels).type_as(real)\n",
        "\n",
        "        # Train discriminator\n",
        "        result = None\n",
        "        if optimizer_idx == 0:\n",
        "            result = self._disc_step(real, fake.detach(), labels)\n",
        "\n",
        "        # Train generator\n",
        "        if optimizer_idx == 1:\n",
        "            result = self._gen_step(fake, labels)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _disc_step(self, real, fake, labels):\n",
        "        # # Not needed if using gradient penalty\n",
        "        # for p in self.discriminator.parameters():\n",
        "        #     p.data.clamp_(-0.01, 0.01)\n",
        "        disc_loss = self._get_disc_loss(real, fake, labels)\n",
        "        self.log('LensGAN128/D/train/loss', disc_loss)\n",
        "        return disc_loss\n",
        "\n",
        "    def _gen_step(self, fake, labels):\n",
        "        gen_loss = self._get_gen_loss(fake, labels)\n",
        "        self.log('LensGAN128/G/train/loss', gen_loss)\n",
        "        return gen_loss\n",
        "\n",
        "    def _get_disc_loss(self, real, fake, labels):\n",
        "        # Train with real\n",
        "        realCritic_pred = self.discriminator(real)\n",
        "        # realCritic_pred , realAux_pred = self.discriminator(real)\n",
        "        real_loss = realCritic_pred.mean()\n",
        "        # real_gt = torch.ones_like(realCritic_pred)\n",
        "        # real_loss = self.criterion(realCritic_pred, real_gt)\n",
        "\n",
        "        # Train with fake\n",
        "        fakeCritic_pred = self.discriminator(fake)\n",
        "        # fakeCritic_pred, fakeAux_pred = self.discriminator(fake)\n",
        "        fake_loss = fakeCritic_pred.mean()\n",
        "        # fake_gt = torch.zeros_like(fakeCritic_pred)\n",
        "        # fake_loss = self.criterion(fakeCritic_pred, fake_gt)\n",
        "\n",
        "        # Classifier loss\n",
        "        # class_loss = nn.CrossEntropyLoss()(realAux_pred, self.labels) + nn.CrossEntropyLoss()(fakeAux_pred, self.labels)\n",
        "\n",
        "        # Compute gradient penalty\n",
        "        gp = self._gradient_penalty(real, fake)\n",
        "\n",
        "        disc_loss = real_loss + fake_loss + 10 * gp \n",
        "        # + class_loss \n",
        "\n",
        "        return disc_loss\n",
        "\n",
        "    def _get_gen_loss(self, fake, labels):\n",
        "        # Train with fake\n",
        "        fakeCritic_pred = self.discriminator(fake)\n",
        "        # fakeCritic_pred, fakeAux_pred = self.discriminator(fake)\n",
        "        gen_loss = fakeCritic_pred.mean()\n",
        "        # fake_gt = torch.ones_like(fakeCritic_pred)\n",
        "        # gen_loss = self.criterion(fakeCritic_pred, fake_gt)\n",
        "\n",
        "        # Classifier loss\n",
        "        # class_loss = nn.CrossEntropyLoss()(fakeAux_pred, self.labels)\n",
        "\n",
        "        return gen_loss \n",
        "        # + class_loss\n",
        "\n",
        "    def _get_fake_data(self, labels):\n",
        "        batch_size = len(labels)\n",
        "        noise = self._get_noise(batch_size, self.hparams.latent_dim)\n",
        "        fake = self(noise, labels)\n",
        "\n",
        "        return fake\n",
        "\n",
        "    def _gradient_penalty(self, real, fake):\n",
        "        \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
        "        # Random weight term for interpolation between real and fake samples\n",
        "        alpha = torch.rand(len(real), 1, 1, 1)\n",
        "        # Get random interpolation between real and fake samples\n",
        "        mix = torch.lerp(real, fake, alpha.type_as(real)).requires_grad_(True)\n",
        "        d_mix = self.discriminator(mix)\n",
        "        # Get gradient w.r.t. mix\n",
        "        gradients = torch.autograd.grad(\n",
        "            outputs=d_mix,\n",
        "            inputs=mix,\n",
        "            grad_outputs=torch.ones_like(d_mix),\n",
        "            create_graph=True,\n",
        "            retain_graph=True,\n",
        "            only_inputs=True,\n",
        "        )[0]\n",
        "        gradients = gradients.view(len(mix), -1)\n",
        "        gp = ((gradients.norm(2, dim=1) - 1) ** 2)\n",
        "        return gp.mean()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs128, labels = batch\n",
        "        self.imgMetrics.update(F.interpolate(imgs128, 150), real=True)\n",
        "\n",
        "        fake = F.interpolate(self._get_fake_data(labels), 150).type_as(imgs128)\n",
        "        self.imgMetrics.update(fake, real=False)\n",
        "        # np.savez_compressed(self.trainer.log_dir + '/samples_{:05d}'.format(self.global_step + batch_idx),\n",
        "        #                     x = fake.cpu(), y = labels.cpu())\n",
        "        return {\n",
        "            'predF': self.lastF(self.modelF(fake)).softmax(1), \n",
        "            'predJ': self.lastJ(self.modelJ(fake)).softmax(1), \n",
        "            'target': labels\n",
        "        }\n",
        "\n",
        "    def validation_epoch_end(self, ListofDicts):\n",
        "        fid = self.imgMetrics.compute()\n",
        "        self.log_dict(fid)\n",
        "\n",
        "        target = torch.cat([x['target'] for x in ListofDicts])\n",
        "        if len(torch.unique(target)) == self.hparams.num_classes:\n",
        "            fig, ax = plt.subplots(1,2, \n",
        "                subplot_kw={'xlim': [0,1], 'xlabel': 'False Positive Rate', 'ylim': [0,1.05], \n",
        "                            'ylabel': 'True Positive Rate',\n",
        "                },\n",
        "                figsize=[11, 5],\n",
        "            )\n",
        "            for j, src in enumerate(['F', 'J']):\n",
        "                prediction = torch.cat([x['pred' + src] for x in ListofDicts])\n",
        "                aurocTensor = tm.functional.auroc(prediction, target, num_classes=self.hparams.num_classes, average=None)\n",
        "                self.log('LensGAN128/LensResnet(' + src + ')/val/auroc', aurocTensor.min())\n",
        "                fprList, tprList, _ = tm.functional.roc(prediction, target, num_classes=self.hparams.num_classes)\n",
        "                \n",
        "                colors = cycle(['red', 'blue', 'green'])\n",
        "                for i, color in zip(range(self.hparams.num_classes), colors):\n",
        "                    ax[j].plot(fprList[i].cpu(), tprList[i].cpu(), color=color,\n",
        "                            label='ROC curve of class {0} (area = {1:0.4f})'\n",
        "                            ''.format(i, aurocTensor[i]))\n",
        "                post_plotting(ax[j])\n",
        "                ax[j].set_title('One vs. all ROC curve (FID : {:0.2f})'.format(fid['LensGAN128/val/FID_'+ src]))\n",
        "        \n",
        "            fig.tight_layout()\n",
        "            self.logger.experiment.add_figure('LensGAN128/LensResnet/val/ROC', fig)\n",
        "            fig.savefig(str(self.trainer.log_dir) + '/ROC_step_{:05d}.pdf'.format(self.global_step))\n",
        "        else:\n",
        "            print('Only these labels were encountered : ', torch.unique(target).tolist())\n",
        "\n",
        "        # Save samples\n",
        "        labels = torch.arange(self.hparams.num_classes, device=self.device)\n",
        "        imgs = self._get_fake_data(labels)\n",
        "\n",
        "        while len(labels) > 0:\n",
        "            x, y = self.trainer.datamodule.val_set[np.random.randint(0, len(self.trainer.datamodule.val_set))]\n",
        "            if y == labels[0]:\n",
        "                imgs = torch.cat((imgs, x.unsqueeze(0).type_as(imgs)))\n",
        "                labels = labels[1:]\n",
        "\n",
        "        save_image(F.interpolate(imgs, 150), \n",
        "                str(self.trainer.log_dir) + '/Fake_step_{:05d}.pdf'.format(self.global_step), \n",
        "                #  kwargs for make_grid\n",
        "                nrow=self.hparams.num_classes, normalize=True, value_range=(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u1b8lr2puNw"
      },
      "source": [
        "## Stage 2\n",
        "Here we subclass a DCGAN to create our high resolution GAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMwzBib_zulo"
      },
      "source": [
        "class Generator2(nn.Module):\n",
        "    def __init__(self, ngf: int = 128, image_channels: int = 1, res_depth: int = 6):\n",
        "        super().__init__()\n",
        "\n",
        "        ker, strd = 4, 2\n",
        "        pad = int((ker - 2)/2)\n",
        "        res_ker, res_strd, res_pad = 3, 1, 1\n",
        "        \n",
        "        # 64 -> 32\n",
        "        self.preprocessing = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, ngf, ker, strd, pad, bias=False),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        # residuals\n",
        "        layer = []\n",
        "        for _ in range(res_depth):\n",
        "            layer.append(BasicBlock(ngf, ngf))\n",
        "        self.residual = nn.Sequential(*layer)\n",
        "        \n",
        "        self.ending_residual = nn.Sequential(\n",
        "            nn.Conv2d(ngf, ngf, res_ker, res_strd, res_pad, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        # at this part, add the residual inputs from after the preprocessing\n",
        "\n",
        "        image_width = 150 # upscaling should be factor of 2 increase\n",
        "        mode = 'nearest' # upscaling method is nearest-neighbour\n",
        "        self.main = nn.Sequential(\n",
        "            # 32 -> 75\n",
        "            nn.Upsample(image_width//2, mode=mode),\n",
        "            nn.Conv2d(ngf, ngf*4, res_ker, res_strd, res_pad, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(True),\n",
        "            # 75 -> 150\n",
        "            nn.Upsample(image_width, mode=mode),\n",
        "            nn.Conv2d(ngf*4, image_channels, res_ker, res_strd, res_pad, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, in_x):\n",
        "        x_p = self.preprocessing(in_x)\n",
        "        x_r = x_p\n",
        "        x_r = self.residual(x_r)\n",
        "        x_r = self.ending_residual(x_r)\n",
        "        # large residual connections\n",
        "        x_f = x_r + x_p\n",
        "        return self.main(x_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snK9DNDARgi7"
      },
      "source": [
        "BEST_F_LensGAN128 = '/content/drive/MyDrive/Logs/F/LensGAN128/pbt_tanh_1/train_LensGAN128_90727_00001_1_n_fmaps=16_2021-08-30_08-02-05/checkpoint_epoch=4-step=1988/'\n",
        "BEST_J_LensGAN128 ='/content/drive/MyDrive/Logs/J/LensGAN128/pbt_tanh/train_LensGAN128_28c03_00003_3_n_fmaps=64_2021-08-31_20-45-44/checkpoint_epoch=2-step=1403/'\n",
        "\n",
        "class Stage2(DCGAN):\n",
        "    def __init__(self, config, num_classes: int = 3, **kwargs):\n",
        "        super().__init__(feature_maps_gen=config['n_fmaps'], feature_maps_disc=config['n_fmaps'], learning_rate=config['learning_rate'])\n",
        "        self.save_hyperparameters(ignore=config)\n",
        "\n",
        "        self.generator = Generator2(self.hparams.feature_maps_gen, self.hparams.image_channels, config['res_depth'])\n",
        "\n",
        "        # These are better as attributes, instead of being returned by a method\n",
        "        self.modelF = getattr(self, 'modelF', LensResnet.load_from_checkpoint(os.path.join(BEST_RESNET_F, 'checkpoint')).eval())\n",
        "        self.modelJ = getattr(self, 'modelJ', LensResnet.load_from_checkpoint(os.path.join(BEST_RESNET_J, 'checkpoint')).eval())\n",
        "        # Workaround:\n",
        "        self.lowres = getattr(self, 'lowres', LensGAN128.load_from_checkpoint(os.path.join(BEST_LensGAN128_F, 'checkpoint')).eval())\n",
        "        \n",
        "        metrics = tm.MetricCollection(\n",
        "            [\n",
        "             tm.AUROC(num_classes=self.hparams.num_classes, compute_on_step=False, average=None), \n",
        "             tm.ROC(num_classes=self.hparams.num_classes, compute_on_step=False),\n",
        "            ]\n",
        "        )\n",
        "        self.metricsF = metrics.clone()\n",
        "        self.metricsJ = metrics.clone()\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.generator(noise)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        real, self.labels = batch\n",
        "\n",
        "        # Train discriminator\n",
        "        result = None\n",
        "        if optimizer_idx == 0:\n",
        "            result = self._disc_step(real)\n",
        "\n",
        "        # Train generator\n",
        "        if optimizer_idx == 1:\n",
        "            result = self._gen_step(real)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _disc_step(self, real):\n",
        "        disc_loss = self._get_disc_loss(real)\n",
        "        self.log('Stage2/D/train/loss', disc_loss, on_epoch=True)\n",
        "        return disc_loss\n",
        "\n",
        "    def _gen_step(self, real):\n",
        "        gen_loss = self._get_gen_loss(real)\n",
        "        self.log('Stage2/G/train/loss', gen_loss, on_epoch=True)\n",
        "        return gen_loss\n",
        "\n",
        "    def _get_gen_loss(self, real: torch.Tensor) -> torch.Tensor:\n",
        "        # Train with fake\n",
        "        fake_pred = self._get_fake_pred(real)\n",
        "        fake_gt = torch.ones_like(fake_pred)\n",
        "        gen_loss = self.criterion(fake_pred, fake_gt)\n",
        "\n",
        "        # class_pred =  self._get_class_pred(len(real))\n",
        "        # gen_loss += F.cross_entropy(class_pred, self.labels)\n",
        "\n",
        "        return gen_loss\n",
        "\n",
        "    def _get_class_pred(self, batch_size) -> torch.Tensor:\n",
        "        # ----------------------------------------------------------------------------------------------------------------\n",
        "        return self.modelF.backbone(self(self._get_noise(batch_size, self.hparams.latent_dim)))\n",
        "\n",
        "    def _get_noise(self, n_samples: int, latent_dim: int, labels = None):\n",
        "        # can't use self in function definition\n",
        "        if labels is None:\n",
        "            labels = self.labels\n",
        "            # getattr(self, 'labels', torch.randint(self.hparams.num_classes, (n_samples,), device=self.device))  # last dimension is the hidden dimension\n",
        "        return self.lowres(super()._get_noise(n_samples, latent_dim), labels)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        out = self(self._get_noise(labels.shape[0], self.hparams.latent_dim, labels))\n",
        "        self.metricsF.update(self.modelF(out), labels)\n",
        "        self.metricsJ.update(self.modelJ(out), labels)\n",
        "        # out = Fig.interpolate(out_64, 150)\n",
        "\n",
        "    def validation_epoch_end(self, listofDicts):\n",
        "        fig, ax = plt.subplots(1,2, \n",
        "            subplot_kw={'xlim': [0,1], 'xlabel': 'False Positive Rate', 'ylim': [0,1.05], \n",
        "                        'ylabel': 'True Positive Rate',\n",
        "            },\n",
        "            figsize=[11, 5],\n",
        "        )\n",
        "        for j, letter in enumerate(['F', 'J']):\n",
        "            output = getattr(self, 'metrics' + letter).compute()\n",
        "            self.log('Stage2/ResNet(' + letter + ')/val/auroc', output['AUROC'].min())\n",
        "            fprList, tprList, _ = output['ROC']\n",
        "            \n",
        "            colors = cycle(['red', 'blue', 'green'])\n",
        "            for i, color in zip(range(self.hparams.num_classes), colors):\n",
        "                ax[j].plot(fprList[i].cpu(), tprList[i].cpu(), color=color,\n",
        "                        label='ROC curve of class {0} (area = {1:0.4f})'\n",
        "                        ''.format(i, output['AUROC'][i]))\n",
        "            post_plotting(ax[j])\n",
        "            ax[j].set_title('One vs. all ROC curve (' + letter + ')')\n",
        "        \n",
        "        fig.tight_layout()\n",
        "        self.logger.experiment.add_figure('Stage2/ResNet/val/ROC', fig)\n",
        "        fig.savefig(str(self.trainer.log_dir) + '/ROC_step_{:05d}.pdf'.format(self.global_step))\n",
        "\n",
        "        labels = torch.arange(self.hparams.num_classes, device=self.device)\n",
        "        save_image(self(self._get_noise(labels.shape[0], self.hparams.latent_dim, labels)), \n",
        "                   str(self.trainer.log_dir) + '/Fake_step_{:05d}.pdf'.format(self.global_step), \n",
        "                  #  kwargs for make_grid\n",
        "                   normalize=True, value_range=(-1,1))\n",
        "\n",
        "    def on_fit_end(self):\n",
        "        delattr(self, 'modelF')\n",
        "        delattr(self, 'modelJ')\n",
        "        delattr(self, 'labels')\n",
        "        delattr(self, 'lowres')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0XraYESGws1"
      },
      "source": [
        "# Tune Hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbXpnU7Y4Cr9"
      },
      "source": [
        "## ResNet\n",
        "Here we tune hyperparameters as we train our modified ResNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otF0QlxlGsZs"
      },
      "source": [
        "%rm -rf /content/drive/MyDrive/Logs/fakeF/PGAN/LensResnet/pbt_tanh_validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOMd0E5Q9mkw"
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_LensResnet(config, checkpoint_dir=None, num_epochs=10, num_gpus=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    kwargs = {\n",
        "        # 'limit_train_batches' : 0.005,\n",
        "        # 'limit_val_batches' : 0.005,\n",
        "        'progress_bar_refresh_rate' : int(8250//config['bs']),\n",
        "        'max_epochs' : num_epochs,\n",
        "        'prepare_data_per_node' : False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        'gpus' : int(num_gpus),\n",
        "        'logger' : TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        'callbacks' : [\n",
        "            TuneReportCheckpointCallback(\n",
        "                {\n",
        "                    'loss': 'LensResnet/val/loss', \n",
        "                    'auroc': 'LensResnet/val/auroc', \n",
        "                },\n",
        "            ),\n",
        "            ModuleDataMonitor(['backbone.layer2', 'backbone.layer4', 'backbone.fc']),\n",
        "            ConfusedLogitCallback(5),\n",
        "        ],\n",
        "        'stochastic_weight_avg' : True,\n",
        "        # works with only one optimizer\n",
        "        'benchmark' : True,\n",
        "        'precision' : 16,     # can't use on cpu\n",
        "        # 'track_grad_norm': 2,\n",
        "        # 'gradient_clip_val' : 0.5, \n",
        "        # 'gradient_clip_algorithm' : 'value',\n",
        "    }\n",
        "    \n",
        "    dm = npyImageData(config)                                              # Specify image width here    \n",
        "    if checkpoint_dir is not None:\n",
        "        kwargs['resume_from_checkpoint'] = os.path.join(checkpoint_dir, 'checkpoint')\n",
        "        # model = LensResnet.load_from_checkpoint(kwargs['resume_from_checkpoint'], config=config)\n",
        "    # else:\n",
        "\n",
        "    model = LensResnet(config)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_LensResnet_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_LensResnet,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial\n",
        "        ),\n",
        "        # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "        name='J/LensResnet/pbt_tanh_fine',\n",
        "        metric='loss',\n",
        "        mode='min',\n",
        "        # stop=TrialPlateauStopper('auroc'),\n",
        "        resources_per_trial={'cpu': os.cpu_count(), 'gpu': gpus_per_trial},\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        # config={'lr': tune.choice([1e-4, 1e-3, 1e-5, 1e-2, 1e-6, 1e-1, 1e-7]),\n",
        "        #         'bs': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "        #         },\n",
        "        # scheduler = pbtScheduler(max_t=num_epochs, grace_period=2, reduction_factor=2),\n",
        "        # Can't use RB2 as it requires mutations to be continuous\n",
        "        config={'lr': 1e-5,\n",
        "                'bs': 8,\n",
        "                # RuntimeError: stack expects each tensor to be equal size, but got [128] at entry 0 and [120] at entry 585\n",
        "                },\n",
        "        scheduler = PopulationBasedTraining(time_attr='training_iteration', quantile_fraction=0.4,\n",
        "                                            resample_probability=0.2,  perturbation_interval=1,\n",
        "                                            hyperparam_mutations={\n",
        "                                                'lr': tune.loguniform(1e-6, 1e-4),\n",
        "                                                'bs': [8, 16, 32, 64, 128],\n",
        "                                            },\n",
        "        ),\n",
        "        progress_reporter=JupyterNotebookReporter(\n",
        "            overwrite=False,\n",
        "            parameter_columns=['lr', 'bs'],\n",
        "            metric_columns=['loss', 'auroc', 'training_iteration'],\n",
        "        ),\n",
        "        fail_fast = True,\n",
        "        # reuse_actors=True,\n",
        "        num_samples=num_samples,\n",
        "        # resume='PROMPT',\n",
        "    )\n",
        "    BEST_J_RESNET = analysis.best_checkpoint\n",
        "    print('Best checkpoint path found is: ', BEST_J_RESNET)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_LensResnet_pbt(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # pbt scheduler\n",
        "        tune_LensResnet_pbt(num_samples=1, num_epochs=5, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPxU2-AggCrI"
      },
      "source": [
        "## LensGAN128\n",
        "Here we tune hyperparameters as we train our modified DCGAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr0jbpHhgs79"
      },
      "source": [
        "%rm -rf drive/MyDrive/Logs/J/LensGAN128/onehot_wgan_gp/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz_mb3SxcDnF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "998a2e28-5612-4e65-cea8-4280f6de5ac6"
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_LensGAN128(config, checkpoint_dir=None, num_epochs=10, num_gpus=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    kwargs = {\n",
        "        'limit_train_batches' : 0.05,\n",
        "        'limit_val_batches' : 0.05,\n",
        "        'progress_bar_refresh_rate' : int(8250 * 0.05//config['bs']),\n",
        "        'max_epochs' : num_epochs,\n",
        "        'prepare_data_per_node' : False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        'gpus' : int(num_gpus),\n",
        "        'logger' : TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        'callbacks' : [\n",
        "            TuneReportCheckpointCallback(\n",
        "                {\n",
        "                    'loss_G': 'LensGAN128/G/train/loss', \n",
        "                    'loss_D': 'LensGAN128/D/train/loss', \n",
        "                    # Switch up the FID vlues when training on different dataset -----------------------------------------------\n",
        "                    'FID': 'LensGAN128/val/FID_J', \n",
        "                    'FID_cross': 'LensGAN128/val/FID_F',\n",
        "                    'auroc': 'LensGAN128/LensResnet(J)/val/auroc',\n",
        "                    'auroc_cross': 'LensGAN128/LensResnet(F)/val/auroc',\n",
        "                },\n",
        "            ),\n",
        "            ModuleDataMonitor(True),\n",
        "        ],\n",
        "        # 'stochastic_weight_avg' : True,\n",
        "        # works with only one optimizer\n",
        "        'benchmark' : True,\n",
        "        'precision' : 16,\n",
        "        # 'gradient_clip_val' : 0.5, \n",
        "        # 'gradient_clip_algorithm' : 'value',\n",
        "    }\n",
        "    \n",
        "    dm = npyImageData(config, 128)                                              # Specify image width here    \n",
        "    if checkpoint_dir is not None:\n",
        "        kwargs['resume_from_checkpoint'] = os.path.join(checkpoint_dir, 'checkpoint')\n",
        "\n",
        "    model = LensGAN128(config)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_LensGAN128_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_LensGAN128,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial\n",
        "        ),\n",
        "        # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "        name='J/LensGAN128/onehot_wgan_gp',\n",
        "        metric='FID',\n",
        "        mode='min',\n",
        "        # stop=TrialPlateauStopper('FID'),\n",
        "        resources_per_trial={'cpu': os.cpu_count(), 'gpu': gpus_per_trial},\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        # config={'lr': tune.choice([1e-4, 1e-3, 1e-5, 1e-2, 1e-6, 1e-1, 1e-7]),\n",
        "        #         'bs': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "        #         },\n",
        "        # scheduler = pbtScheduler(max_t=num_epochs, grace_period=2, reduction_factor=2),\n",
        "        # Can't use RB2 as it requires mutations to be continuous\n",
        "        config={'lr': 1e-3,\n",
        "                'n_fmaps': tune.grid_search([8, 16, 32, 64]),\n",
        "                'bs': 8,\n",
        "                },\n",
        "        # config = {'lr': 2.340983544823817e-05, 'n_fmaps': 32, 'bs': 8},\n",
        "        scheduler = PopulationBasedTraining(time_attr='training_iteration', quantile_fraction=0.25,\n",
        "                                            resample_probability=0.25,  perturbation_interval=1,\n",
        "                                            hyperparam_mutations={\n",
        "                                                'lr': tune.loguniform(1e-5, 1e-3),\n",
        "                                                'bs': [8, 16, 32, 64, 128],\n",
        "                                            },\n",
        "        ),\n",
        "        progress_reporter=JupyterNotebookReporter(\n",
        "            overwrite=False,\n",
        "            parameter_columns=['lr', 'n_fmaps', 'bs'],\n",
        "            metric_columns=['loss_G', 'loss_D', 'FID', 'auroc', 'FID_cross', \n",
        "                            'auroc_cross', 'training_iteration'],\n",
        "        ),\n",
        "        fail_fast = True,\n",
        "        # reuse_actors=True,\n",
        "        num_samples=num_samples,\n",
        "        # resume='PROMPT',\n",
        "        # restore=BEST_J_LensGAN128,\n",
        "    )\n",
        "    # ---------------------------------------------------------------------------------------------\n",
        "\n",
        "    print('Best checkpoint path found is: ', analysis.best_checkpoint)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_LensGAN128_pbt(num_samples=1, num_epochs=5, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # pbt scheduler\n",
        "        tune_LensGAN128_pbt(num_samples=1, num_epochs=5, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 1.5/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.51 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /content/drive/MyDrive/Logs/J/LensGAN128/onehot_wgan_gp<br>Number of trials: 4/4 (3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_f4e30_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   8</td></tr>\n",
              "<tr><td>train_LensGAN128_f4e30_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   8</td></tr>\n",
              "<tr><td>train_LensGAN128_f4e30_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   8</td></tr>\n",
              "<tr><td>train_LensGAN128_f4e30_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   8</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m   warnings.warn('Lazy modules are a new feature under heavy development '\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `FID` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m Using native 16bit precision.\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m GPU available: True, used: True\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.51 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /content/drive/MyDrive/Logs/J/LensGAN128/onehot_wgan_gp<br>Number of trials: 4/4 (3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_f4e30_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   8</td></tr>\n",
              "<tr><td>train_LensGAN128_f4e30_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   8</td></tr>\n",
              "<tr><td>train_LensGAN128_f4e30_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   8</td></tr>\n",
              "<tr><td>train_LensGAN128_f4e30_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   8</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/memory.py:484: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m   | Name          | Type               | Params\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m 0 | generator     | DCGANGenerator     | 174 K \n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m 1 | discriminator | DCGANDiscriminator | 174 K \n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m 2 | criterion     | BCELoss            | 0     \n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m 3 | modelF        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m 4 | lastF         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m 5 | modelJ        | ResNet             | 11.2 M\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m 6 | lastJ         | Sequential         | 1.5 K \n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m 7 | imgMetrics    | MetricCollection   | 22.3 M\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m -----------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m 348 K     Trainable params\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m 22.3 M    Non-trainable params\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m 22.7 M    Total params\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m 90.770    Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:377: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m   f\"Your {mode}_dataloader has `shuffle=True`, it is best practice to turn\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/514 [00:00<00:00, 2750.36it/s]  \n",
            "Epoch 0:  10%|         | 51/514 [00:06<00:55,  8.30it/s, loss=-1.32e+03, v_num=.]\n",
            "Epoch 0:  20%|        | 102/514 [00:12<00:48,  8.48it/s, loss=-1.56e+03, v_num=.]\n",
            "Epoch 0:  30%|       | 153/514 [00:18<00:42,  8.44it/s, loss=-1.62e+03, v_num=.]\n",
            "Epoch 0:  40%|      | 204/514 [00:24<00:36,  8.49it/s, loss=-1.66e+03, v_num=.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-07 03:17:01,428\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:  50%|     | 255/514 [00:30<00:30,  8.49it/s, loss=-1.67e+03, v_num=.]\n",
            "Epoch 0:  60%|    | 306/514 [00:35<00:24,  8.53it/s, loss=-1.69e+03, v_num=.]\n",
            "Epoch 0:  69%|   | 357/514 [00:41<00:18,  8.55it/s, loss=-1.69e+03, v_num=.]\n",
            "Epoch 0:  79%|  | 408/514 [00:47<00:12,  8.58it/s, loss=-1.7e+03, v_num=.] \n",
            "Epoch 0:  89%| | 459/514 [00:53<00:06,  8.60it/s, loss=-1.7e+03, v_num=.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m [W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m \rEpoch 0:  99%|| 510/514 [00:54<00:00,  9.44it/s, loss=-1.7e+03, v_num=.]\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m \rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|          | 0/46 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m \n",
            "Validating: 100%|| 46/46 [00:04<00:00, 10.01it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=6163)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_LensGAN128_f4e30_00000:\n",
            "  FID: 51.09375\n",
            "  FID_cross: 93.25\n",
            "  auroc: 0.47888487577438354\n",
            "  auroc_cross: 0.46498656272888184\n",
            "  date: 2021-10-07_03-17-37\n",
            "  done: false\n",
            "  experiment_id: b2a1fd1b10b243faac23eac973b1d1b0\n",
            "  hostname: 5a76197f97ef\n",
            "  iterations_since_restore: 1\n",
            "  loss_D: -1727.3590087890625\n",
            "  loss_G: -1617.0\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6163\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 68.42646837234497\n",
            "  time_this_iter_s: 68.42646837234497\n",
            "  time_total_s: 68.42646837234497\n",
            "  timestamp: 1633576657\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: f4e30_00000\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.5/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.51 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: f4e30_00000 with FID=51.09375 and parameters={'lr': 0.001, 'n_fmaps': 8, 'bs': 8}<br>Result logdir: /content/drive/MyDrive/Logs/J/LensGAN128/onehot_wgan_gp<br>Number of trials: 4/4 (3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">    FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">  FID_cross</th><th style=\"text-align: right;\">  auroc_cross</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_f4e30_00000</td><td>RUNNING </td><td>172.28.0.2:6163</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   8</td><td style=\"text-align: right;\">   -1617</td><td style=\"text-align: right;\">-1727.36</td><td style=\"text-align: right;\">51.0938</td><td style=\"text-align: right;\">0.478885</td><td style=\"text-align: right;\">      93.25</td><td style=\"text-align: right;\">     0.464987</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_LensGAN128_f4e30_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   8</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "<tr><td>train_LensGAN128_f4e30_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   8</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "<tr><td>train_LensGAN128_f4e30_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   8</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.5/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.51 GiB heap, 0.0/3.75 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: f4e30_00000 with FID=51.09375 and parameters={'lr': 0.001, 'n_fmaps': 8, 'bs': 8}<br>Result logdir: /content/drive/MyDrive/Logs/J/LensGAN128/onehot_wgan_gp<br>Number of trials: 4/4 (3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  n_fmaps</th><th style=\"text-align: right;\">  bs</th><th style=\"text-align: right;\">  loss_G</th><th style=\"text-align: right;\">  loss_D</th><th style=\"text-align: right;\">    FID</th><th style=\"text-align: right;\">   auroc</th><th style=\"text-align: right;\">  FID_cross</th><th style=\"text-align: right;\">  auroc_cross</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_LensGAN128_f4e30_00000</td><td>RUNNING </td><td>172.28.0.2:6163</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">        8</td><td style=\"text-align: right;\">   8</td><td style=\"text-align: right;\">   -1617</td><td style=\"text-align: right;\">-1727.36</td><td style=\"text-align: right;\">51.0938</td><td style=\"text-align: right;\">0.478885</td><td style=\"text-align: right;\">      93.25</td><td style=\"text-align: right;\">     0.464987</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_LensGAN128_f4e30_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">   8</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "<tr><td>train_LensGAN128_f4e30_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">   8</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "<tr><td>train_LensGAN128_f4e30_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">   8</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                    </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-07 03:17:37,617\tERROR tune.py:557 -- Trials did not complete: [train_LensGAN128_f4e30_00000, train_LensGAN128_f4e30_00001, train_LensGAN128_f4e30_00002, train_LensGAN128_f4e30_00003]\n",
            "2021-10-07 03:17:37,620\tINFO tune.py:561 -- Total run time: 71.40 seconds (71.09 seconds for the tuning loop).\n",
            "2021-10-07 03:17:37,623\tWARNING tune.py:566 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n",
            "2021-10-07 03:17:37,649\tERROR experiment_analysis.py:306 -- No checkpoints have been found for trial train_LensGAN128_f4e30_00000.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best checkpoint path found is:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQJPa94b10ka"
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btkO_vqvN5Yi"
      },
      "source": [
        "## Stage 2\n",
        "Here we tune hyperparameters as we train our modified DCGAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0efCKmqQkp3"
      },
      "source": [
        "# __tune_train_checkpoint_begin\n",
        "def train_Stage2(config, checkpoint_dir=None, num_epochs=10, num_gpus=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    kwargs = {\n",
        "        # 'limit_train_batches' : 0.05,\n",
        "        # 'limit_val_batches' : 0.05,\n",
        "        'progress_bar_refresh_rate' : int(8250//config['batch_size']),\n",
        "        'max_epochs' : num_epochs,\n",
        "        'prepare_data_per_node' : False,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        'gpus' : int(num_gpus),\n",
        "        'logger' : TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
        "        'callbacks' : [\n",
        "            TuneReportCheckpointCallback(\n",
        "                {\n",
        "                    'loss_G': 'Stage2/G/train/loss', \n",
        "                    'loss_D': 'Stage2/D/train/loss', \n",
        "                    # Switch up the auroc vlues when training on different dataset -----------------------------------------------\n",
        "                    'auroc': 'Stage2/ResNet(F)/val/auroc', \n",
        "                    'auroc_cross': 'Stage2/ResNet(J)/val/auroc',\n",
        "                },\n",
        "            ),\n",
        "        ],\n",
        "        # 'stochastic_weight_avg' : True,\n",
        "        # works with only one optimizer\n",
        "        # 'benchmark' : True,\n",
        "    }\n",
        "    \n",
        "    dm = npyImageData(config)                                              # Specify image width here    \n",
        "    if checkpoint_dir is not None:\n",
        "        kwargs['resume_from_checkpoint'] = os.path.join(checkpoint_dir, 'checkpoint')\n",
        "        # model = Stage2.load_from_checkpoint(kwargs['resume_from_checkpoint'], config=config)\n",
        "    # else:\n",
        "        # model = Stage2(config)\n",
        "    model = Stage2(config)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "\n",
        "# # # __tune_asha_begin__\n",
        "# def tune_Stage2_asha(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "#     # print(os.cpu_count(), torch.cuda.device_count())\n",
        "#     analysis = tune.run(\n",
        "#         tune.with_parameters(\n",
        "#             train_Stage2,\n",
        "#             num_epochs=num_epochs,\n",
        "#             num_gpus=gpus_per_trial\n",
        "#         ),\n",
        "#         # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "#         name='Stage2/pbt/J',\n",
        "#         metric='auroc',\n",
        "#         mode='max',\n",
        "#         config={'learning_rate': 1e-4,\n",
        "#                 'n_fmaps': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "#                 'batch_size': 8,\n",
        "#                 },\n",
        "#         # config={'learning_rate': 0.01,\n",
        "#         #         'n_fmaps': 32,\n",
        "#         #         'batch_size': 32,\n",
        "#         #         },\n",
        "#         # stop=TrialPlateauStopper('loss_G'),\n",
        "#         resources_per_trial={'cpu': os.cpu_count(),\n",
        "#                              'gpu': gpus_per_trial,\n",
        "#                             },\n",
        "#         local_dir='./drive/MyDrive/Logs',\n",
        "#         scheduler = ASHAScheduler(max_t=num_epochs, grace_period=2,  reduction_factor=2),\n",
        "#         progress_reporter=JupyterNotebookReporter(\n",
        "#             overwrite=True,\n",
        "#             parameter_columns=['learning_rate', 'n_fmaps', 'batch_size'],\n",
        "#             metric_columns=['loss_G', 'loss_D', 'auroc', 'auroc_cross', 'training_iteration'],\n",
        "#             sort_by_metric=True,\n",
        "#         ),\n",
        "#         fail_fast = True,\n",
        "#         # reuse_actors=True,\n",
        "#         # num_samples=num_samples,\n",
        "#         resume='PROMPT',\n",
        "# #         restore='/content/drive/MyDrive/Logs/delete/train_Stage2_e42ac_00025_25_batch_size=8,learning_rate=0.01,n_fmaps=8_2021-07-28_21-16-18/checkpoint_epoch=4-step=2339',\n",
        "#     )\n",
        "\n",
        "# #     print('Best hyperparameters found were: ', analysis.best_config)\n",
        "\n",
        "# # # __tune_asha_end__\n",
        "\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_Stage2_pbt(num_samples=10, num_epochs=10, gpus_per_trial=torch.cuda.device_count()):\n",
        "    # print(os.cpu_count(), torch.cuda.device_count())\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_Stage2,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial\n",
        "        ),\n",
        "        # Change the folder name when changing dataset--------------------------------------------------------------------------\n",
        "        name='Stage2/pbt/F',\n",
        "        metric='auroc',\n",
        "        mode='max',\n",
        "        config={'learning_rate': 1e-4,\n",
        "                'n_fmaps': tune.grid_search([8, 16, 32, 64, 128]),\n",
        "                'res_depth': tune.choice([1, 2, 3, 4]),\n",
        "                'batch_size': 8,\n",
        "                },\n",
        "        # config={'learning_rate': 0.01,\n",
        "        #         'n_fmaps': 32,\n",
        "        #         'batch_size': 32,\n",
        "        #         },\n",
        "        # stop=TrialPlateauStopper('loss_G'),\n",
        "        resources_per_trial={'cpu': os.cpu_count(),\n",
        "                             'gpu': gpus_per_trial,\n",
        "                            },\n",
        "        local_dir='./drive/MyDrive/Logs',\n",
        "        scheduler = PopulationBasedTraining(time_attr='training_iteration',\n",
        "                                            quantile_fraction=0.5,\n",
        "                                            resample_probability=0.8,\n",
        "                                            perturbation_interval=1,\n",
        "                                            hyperparam_mutations={\n",
        "                                                'learning_rate': tune.loguniform(1e-7, 1e-1),\n",
        "                                                'batch_size': [8, 16, 32, 64, 128],\n",
        "                                            },\n",
        "                                            ),\n",
        "        progress_reporter=JupyterNotebookReporter(\n",
        "            overwrite=False,\n",
        "            parameter_columns=['learning_rate', 'n_fmaps', 'res_depth', 'batch_size'],\n",
        "            metric_columns=['loss_G', 'loss_D', 'auroc', 'auroc_cross', 'training_iteration'],\n",
        "            sort_by_metric=True,\n",
        "        ),\n",
        "        fail_fast = True,\n",
        "        # reuse_actors=True,\n",
        "        # num_samples=num_samples,\n",
        "        resume='PROMPT',\n",
        "    )\n",
        "\n",
        "    print('Best hyperparameters found were: ', analysis.best_config)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--smoke-test', action='store_true', help='Finish quickly for testing')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_Stage2_asha(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "        tune_Stage2_pbt(num_samples=1, num_epochs=6, gpus_per_trial=torch.cuda.device_count())\n",
        "    else:\n",
        "        # ASHA scheduler\n",
        "        # tune_Stage2_asha(num_samples=1, num_epochs=10, gpus_per_trial=torch.cuda.device_count())\n",
        "        # Population based training\n",
        "        tune_Stage2_pbt(num_samples=1, num_epochs=30, gpus_per_trial=torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}